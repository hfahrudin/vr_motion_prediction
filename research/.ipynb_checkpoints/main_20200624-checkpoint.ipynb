{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "from scipy import signal\n",
    "import skinematics as skin\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "#from scipy import signal\n",
    "from taskcaller import taskcaller\n",
    "from taskcaller_train1 import taskcaller_train1\n",
    "import random\n",
    "# modularized library import\n",
    "from train_test_split_k import train_test_split_k\n",
    "from rms import rms    \n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from maml import *\n",
    "\n",
    "from math import pi\n",
    "from math import cos\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.10 |Anaconda, Inc.| (default, May  7 2020, 19:46:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Tensorflow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "dtype=\"float64\"\n",
    "tf.keras.backend.set_floatx(dtype)\n",
    "print('Python version: ', sys.version)\n",
    "print('Tensorflow version: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/trainingtask1.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask2.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask3.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask4.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask5.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask6.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask7.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask8.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask9.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n",
      "../dataset/trainingtask9.csv loaded...\n",
      "\n",
      "Anticipation time: 300ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S=30\n",
    "# np.random.seed(S)\n",
    "# random.seed(S)\n",
    "# tf.random.set_seed(S)\n",
    "\n",
    "system_rate = 60\n",
    "k_train = 100\n",
    "x_train1, t_train1, x_val1, t_val1,input_nm, target_nm, data_length, DELAY_SIZE, train_eule_data, anticipation_size, train_time_data = taskcaller_train1('../dataset/trainingtask1.csv', system_rate, k_train)\n",
    "x_train2, t_train2, x_val2, t_val2,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask2.csv', system_rate, k_train)\n",
    "x_train3, t_train3, x_val3, t_val3,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask3.csv', system_rate, k_train)\n",
    "x_train4, t_train4, x_val4, t_val4, _, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask4.csv', system_rate, k_train)\n",
    "x_train5, t_train5, x_val5, t_val5,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask5.csv', system_rate, k_train)\n",
    "x_train6, t_train6, x_val6, t_val6,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask6.csv', system_rate, k_train)\n",
    "x_train7, t_train7, x_val7, t_val7,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask7.csv', system_rate, k_train)\n",
    "x_train8, t_train8, x_val8, t_val8,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask8.csv', system_rate, k_train)\n",
    "x_train9, t_train9, x_val9, t_val9,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask9.csv', system_rate, k_train)\n",
    "x_train10, t_train10, x_val10, t_val10,_, _, _, _, _, _, _ = taskcaller_train1('../dataset/trainingtask9.csv', system_rate, k_train)\n",
    "#x_seq10, t_seq10, _, _,_, _, _, _, _, _, _ = taskcaller('trainingtask10.csv', system_rate, k)\n",
    "\n",
    "\n",
    "traintaskx = [x_train1 , x_train2 , x_train3 , x_train4,x_train5,x_train6,x_train7,x_train8,x_train9,x_train10]\n",
    "traintaskt = [t_train1 , t_train2 , t_train3 , t_train4,t_train5,t_train6,t_train7, t_train8, t_train9,t_train10]\n",
    "\n",
    "valtaskx = [x_val1,x_val2,x_val3,x_val4,x_val5,x_val6,x_val7,x_val8,x_val9,x_val10]\n",
    "valtaskt = [t_val1,t_val2,t_val3,t_val4,t_val5,t_val6,t_val7,t_val8,t_val9,t_val10]\n",
    "\n",
    "numberoftask = len(traintaskx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml1 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml3 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml4 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml5 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftml6 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(DELAY_SIZE, input_nm)),\n",
    "        tf.keras.layers.Conv1D(27, DELAY_SIZE, activation=tf.nn.relu, input_shape=(DELAY_SIZE, input_nm), use_bias=True, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(9, activation=tf.nn.relu, use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(target_nm, activation='linear', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_procedure(model,dtx, dty, lr = 0.001, grad_step =10):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    all_loss = []\n",
    "    for step in range (grad_step):\n",
    "        total_loss = 0\n",
    "        for i in range(len(dtx)):\n",
    "            with tf.GradientTape() as update:\n",
    "                _,loss = model_func(model, dtx[i], dty[i])\n",
    "            gradient = update.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "            total_loss+=loss\n",
    "        all_loss.append(total_loss/len(dtx))\n",
    "        print('Step{} : loss = {}'.format(step,total_loss/len(dtx)))\n",
    "    return model, all_loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task  0\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.810670852661133\n",
      "Step 1 : loss = 6.773885726928711\n",
      "Step 2 : loss = 6.735965728759766\n",
      "Step 3 : loss = 6.696957588195801\n",
      "Step 4 : loss = 6.655305862426758\n",
      "Step 5 : loss = 6.6118268966674805\n",
      "Step 6 : loss = 6.566450119018555\n",
      "Step 7 : loss = 6.521307468414307\n",
      "Step 8 : loss = 6.476248264312744\n",
      "Step 9 : loss = 6.431954860687256\n",
      "Update Procedure\n",
      "Step0 : loss = 6.392580032348633\n",
      "Step1 : loss = 6.350712299346924\n",
      "Step2 : loss = 6.309236526489258\n",
      "Step3 : loss = 6.268543720245361\n",
      "Step4 : loss = 6.230539321899414\n",
      "Step5 : loss = 6.198197841644287\n",
      "Step6 : loss = 6.168838977813721\n",
      "Step7 : loss = 6.141132831573486\n",
      "Step8 : loss = 6.1147050857543945\n",
      "Step9 : loss = 6.088872909545898\n",
      "Data stream Batch- 0 : loss = 4.61669659614563\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.484909296035767\n",
      "Step 1 : loss = 6.4554970264434814\n",
      "Step 2 : loss = 6.427245378494263\n",
      "Step 3 : loss = 6.399701118469238\n",
      "Step 4 : loss = 6.373001575469971\n",
      "Step 5 : loss = 6.346532821655273\n",
      "Step 6 : loss = 6.32036566734314\n",
      "Step 7 : loss = 6.2940263748168945\n",
      "Step 8 : loss = 6.2673609256744385\n",
      "Step 9 : loss = 6.240318298339844\n",
      "Update Procedure\n",
      "Step0 : loss = 6.204886436462402\n",
      "Step1 : loss = 6.150747299194336\n",
      "Step2 : loss = 6.0955727100372314\n",
      "Step3 : loss = 6.0381855964660645\n",
      "Step4 : loss = 5.977780818939209\n",
      "Step5 : loss = 5.913500547409058\n",
      "Step6 : loss = 5.844405651092529\n",
      "Step7 : loss = 5.770382404327393\n",
      "Step8 : loss = 5.69155478477478\n",
      "Step9 : loss = 5.6081178188323975\n",
      "Data stream Batch- 1 : loss = 4.345250606536865\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.388307332992554\n",
      "Step 1 : loss = 6.346615632375081\n",
      "Step 2 : loss = 6.3045713901519775\n",
      "Step 3 : loss = 6.26275372505188\n",
      "Step 4 : loss = 6.221741199493408\n",
      "Step 5 : loss = 6.181277275085449\n",
      "Step 6 : loss = 6.140838066736857\n",
      "Step 7 : loss = 6.100867668787639\n",
      "Step 8 : loss = 6.060509443283081\n",
      "Step 9 : loss = 6.020506938298543\n",
      "Update Procedure\n",
      "Step0 : loss = 7.71384859085083\n",
      "Step1 : loss = 7.591485182444255\n",
      "Step2 : loss = 7.476923783620198\n",
      "Step3 : loss = 7.36190398534139\n",
      "Step4 : loss = 7.257285753885905\n",
      "Step5 : loss = 7.158346811930339\n",
      "Step6 : loss = 7.066728909810384\n",
      "Step7 : loss = 6.983047167460124\n",
      "Step8 : loss = 6.902130603790283\n",
      "Step9 : loss = 6.821032206217448\n",
      "Data stream Batch- 2 : loss = 3.83447265625\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 2.6662331620852155\n",
      "Step 1 : loss = 2.6448663870493574\n",
      "Step 2 : loss = 2.6236150066057844\n",
      "Step 3 : loss = 2.6022981007893877\n",
      "Step 4 : loss = 2.5811439156532288\n",
      "Step 5 : loss = 2.563026388486226\n",
      "Step 6 : loss = 2.5466968218485517\n",
      "Step 7 : loss = 2.531223088502884\n",
      "Step 8 : loss = 2.516423175732295\n",
      "Step 9 : loss = 2.5027055144309998\n",
      "Update Procedure\n",
      "Step0 : loss = 6.082667112350464\n",
      "Step1 : loss = 6.000763356685638\n",
      "Step2 : loss = 5.939652264118195\n",
      "Step3 : loss = 5.881267845630646\n",
      "Step4 : loss = 5.822918891906738\n",
      "Step5 : loss = 5.765893459320068\n",
      "Step6 : loss = 5.7095359563827515\n",
      "Step7 : loss = 5.654670298099518\n",
      "Step8 : loss = 5.600505948066711\n",
      "Step9 : loss = 5.546175956726074\n",
      "Data stream Batch- 3 : loss = 3.582269549369812\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 2.0698401927948\n",
      "Step 1 : loss = 2.0567921658356987\n",
      "Step 2 : loss = 2.0436723490556084\n",
      "Step 3 : loss = 2.0303965846697487\n",
      "Step 4 : loss = 2.017057750622431\n",
      "Step 5 : loss = 2.0036264856656394\n",
      "Step 6 : loss = 1.9901273548603058\n",
      "Step 7 : loss = 1.9765271743138633\n",
      "Step 8 : loss = 1.9626941184202829\n",
      "Step 9 : loss = 1.9476127008597053\n",
      "Update Procedure\n",
      "Step0 : loss = 5.91643762588501\n",
      "Step1 : loss = 5.8380084991455075\n",
      "Step2 : loss = 5.776787900924683\n",
      "Step3 : loss = 5.717312812805176\n",
      "Step4 : loss = 5.658985376358032\n",
      "Step5 : loss = 5.598471164703369\n",
      "Step6 : loss = 5.535591173171997\n",
      "Step7 : loss = 5.471937084197998\n",
      "Step8 : loss = 5.41455307006836\n",
      "Step9 : loss = 5.36189284324646\n",
      "Data stream Batch- 4 : loss = 3.4542644023895264\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.5975305729442173\n",
      "Step 1 : loss = 1.5874075144529343\n",
      "Step 2 : loss = 1.5770803007814618\n",
      "Step 3 : loss = 1.5665972633494272\n",
      "Step 4 : loss = 1.5559604972600936\n",
      "Step 5 : loss = 1.5451493720213572\n",
      "Step 6 : loss = 1.5340579509735106\n",
      "Step 7 : loss = 1.5228618108563954\n",
      "Step 8 : loss = 1.5115091608630287\n",
      "Step 9 : loss = 1.5000581443309784\n",
      "Update Procedure\n",
      "Step0 : loss = 5.670469522476196\n",
      "Step1 : loss = 5.572065989176433\n",
      "Step2 : loss = 5.507764617602031\n",
      "Step3 : loss = 5.439712405204773\n",
      "Step4 : loss = 5.37262499332428\n",
      "Step5 : loss = 5.303630153338115\n",
      "Step6 : loss = 5.2323252360026045\n",
      "Step7 : loss = 5.159625212351481\n",
      "Step8 : loss = 5.086179097493489\n",
      "Step9 : loss = 5.0102711121241255\n",
      "Data stream Batch- 5 : loss = 3.290403127670288\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7594043112463422\n",
      "Step 1 : loss = 0.7473606089750925\n",
      "Step 2 : loss = 0.7352547297402034\n",
      "Step 3 : loss = 0.7231365716173536\n",
      "Step 4 : loss = 0.71094120565861\n",
      "Step 5 : loss = 0.6986567193080508\n",
      "Step 6 : loss = 0.6862444353009026\n",
      "Step 7 : loss = 0.6737283588874908\n",
      "Step 8 : loss = 0.6610435790012753\n",
      "Step 9 : loss = 0.6482992034582864\n",
      "Update Procedure\n",
      "Step0 : loss = 4.7356129714420865\n",
      "Step1 : loss = 4.596453121730259\n",
      "Step2 : loss = 4.491400991167341\n",
      "Step3 : loss = 4.3903956072671075\n",
      "Step4 : loss = 4.285540342330933\n",
      "Step5 : loss = 4.178239958626883\n",
      "Step6 : loss = 4.067206859588623\n",
      "Step7 : loss = 3.953730991908482\n",
      "Step8 : loss = 3.8400214399610246\n",
      "Step9 : loss = 3.7270635877336775\n",
      "Data stream Batch- 6 : loss = 3.0640867948532104\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.27713533583732824\n",
      "Step 1 : loss = 0.26787410334698736\n",
      "Step 2 : loss = 0.2587029786691779\n",
      "Step 3 : loss = 0.24955972571458135\n",
      "Step 4 : loss = 0.24037298884183642\n",
      "Step 5 : loss = 0.23122419277945208\n",
      "Step 6 : loss = 0.222319269073861\n",
      "Step 7 : loss = 0.2137120203129829\n",
      "Step 8 : loss = 0.2052765797587141\n",
      "Step 9 : loss = 0.19724453704224693\n",
      "Update Procedure\n",
      "Step0 : loss = 3.440840020775795\n",
      "Step1 : loss = 3.22479847073555\n",
      "Step2 : loss = 3.105059415102005\n",
      "Step3 : loss = 2.9871102422475815\n",
      "Step4 : loss = 2.869721084833145\n",
      "Step5 : loss = 2.767647348344326\n",
      "Step6 : loss = 2.6801810562610626\n",
      "Step7 : loss = 2.5908712595701218\n",
      "Step8 : loss = 2.508860766887665\n",
      "Step9 : loss = 2.432040885090828\n",
      "Data stream Batch- 7 : loss = 2.4999409914016724\n",
      "Task  1\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.49958123018344247\n",
      "Step 1 : loss = 0.48056870947281516\n",
      "Step 2 : loss = 0.46417755633592606\n",
      "Step 3 : loss = 0.4482033823927244\n",
      "Step 4 : loss = 0.43279068668683374\n",
      "Step 5 : loss = 0.41770321875810623\n",
      "Step 6 : loss = 0.4027349973718325\n",
      "Step 7 : loss = 0.38878507167100906\n",
      "Step 8 : loss = 0.375270759065946\n",
      "Step 9 : loss = 0.3620051989952723\n",
      "Update Procedure\n",
      "Step0 : loss = 2.009018898010254\n",
      "Step1 : loss = 1.9224731922149658\n",
      "Step2 : loss = 1.8379850387573242\n",
      "Step3 : loss = 1.7565796375274658\n",
      "Step4 : loss = 1.679511547088623\n",
      "Step5 : loss = 1.605796217918396\n",
      "Step6 : loss = 1.5350512266159058\n",
      "Step7 : loss = 1.4694992303848267\n",
      "Step8 : loss = 1.4102373123168945\n",
      "Step9 : loss = 1.3548378944396973\n",
      "Data stream Batch- 0 : loss = 9.617619514465332\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.41268747548262275\n",
      "Step 1 : loss = 0.3892994473377863\n",
      "Step 2 : loss = 0.36848203341166175\n",
      "Step 3 : loss = 0.3499652221798897\n",
      "Step 4 : loss = 0.3332266782720884\n",
      "Step 5 : loss = 0.319009800752004\n",
      "Step 6 : loss = 0.30727015932401025\n",
      "Step 7 : loss = 0.2968648051222166\n",
      "Step 8 : loss = 0.2887157772978147\n",
      "Step 9 : loss = 0.28164809197187424\n",
      "Update Procedure\n",
      "Step0 : loss = 4.18243134021759\n",
      "Step1 : loss = 3.9454047679901123\n",
      "Step2 : loss = 3.733102858066559\n",
      "Step3 : loss = 3.5408501029014587\n",
      "Step4 : loss = 3.368303120136261\n",
      "Step5 : loss = 3.217878818511963\n",
      "Step6 : loss = 3.0887675285339355\n",
      "Step7 : loss = 2.9801412224769592\n",
      "Step8 : loss = 2.8836721181869507\n",
      "Step9 : loss = 2.798945903778076\n",
      "Data stream Batch- 1 : loss = 10.032385349273682\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5053292661905289\n",
      "Step 1 : loss = 0.47241224845250446\n",
      "Step 2 : loss = 0.4405921200911204\n",
      "Step 3 : loss = 0.41177046298980713\n",
      "Step 4 : loss = 0.3852892766396204\n",
      "Step 5 : loss = 0.3606448074181875\n",
      "Step 6 : loss = 0.3388838817675909\n",
      "Step 7 : loss = 0.31962832560141885\n",
      "Step 8 : loss = 0.30272120237350464\n",
      "Step 9 : loss = 0.2890394826730093\n",
      "Update Procedure\n",
      "Step0 : loss = 3.5855987469355264\n",
      "Step1 : loss = 3.299776832262675\n",
      "Step2 : loss = 3.080799420674642\n",
      "Step3 : loss = 2.9144652684529624\n",
      "Step4 : loss = 2.7943037350972495\n",
      "Step5 : loss = 2.6977848211924234\n",
      "Step6 : loss = 2.609251101811727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step7 : loss = 2.5315969785054526\n",
      "Step8 : loss = 2.46441117922465\n",
      "Step9 : loss = 2.404223918914795\n",
      "Data stream Batch- 2 : loss = 10.29932451248169\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5800730139017105\n",
      "Step 1 : loss = 0.5476374526818593\n",
      "Step 2 : loss = 0.5174478590488434\n",
      "Step 3 : loss = 0.48988984525203705\n",
      "Step 4 : loss = 0.4648490349451701\n",
      "Step 5 : loss = 0.44191522399584454\n",
      "Step 6 : loss = 0.42067281405131024\n",
      "Step 7 : loss = 0.4012666940689087\n",
      "Step 8 : loss = 0.38289221624533337\n",
      "Step 9 : loss = 0.3648512611786524\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5513456761837006\n",
      "Step1 : loss = 2.330638438463211\n",
      "Step2 : loss = 2.221342086791992\n",
      "Step3 : loss = 2.135747104883194\n",
      "Step4 : loss = 2.066897362470627\n",
      "Step5 : loss = 2.0155364871025085\n",
      "Step6 : loss = 1.9762220978736877\n",
      "Step7 : loss = 1.9428215026855469\n",
      "Step8 : loss = 1.915718913078308\n",
      "Step9 : loss = 1.893188089132309\n",
      "Data stream Batch- 3 : loss = 10.40909194946289\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6056091537078221\n",
      "Step 1 : loss = 0.5710412313540776\n",
      "Step 2 : loss = 0.5398418853680294\n",
      "Step 3 : loss = 0.5142841637134552\n",
      "Step 4 : loss = 0.4924507985512416\n",
      "Step 5 : loss = 0.4729616741339366\n",
      "Step 6 : loss = 0.4542921880880992\n",
      "Step 7 : loss = 0.43630393346150714\n",
      "Step 8 : loss = 0.4185788879791896\n",
      "Step 9 : loss = 0.40155990421772003\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3317275285720824\n",
      "Step1 : loss = 2.113375496864319\n",
      "Step2 : loss = 2.018173265457153\n",
      "Step3 : loss = 1.9520437002182007\n",
      "Step4 : loss = 1.9116844415664673\n",
      "Step5 : loss = 1.883885955810547\n",
      "Step6 : loss = 1.8603270292282104\n",
      "Step7 : loss = 1.8413425445556642\n",
      "Step8 : loss = 1.817472553253174\n",
      "Step9 : loss = 1.7956536531448364\n",
      "Data stream Batch- 4 : loss = 10.475715160369873\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6225694566965103\n",
      "Step 1 : loss = 0.5885628213485081\n",
      "Step 2 : loss = 0.5575693696737289\n",
      "Step 3 : loss = 0.5305803666512172\n",
      "Step 4 : loss = 0.5077867458264034\n",
      "Step 5 : loss = 0.48672257363796234\n",
      "Step 6 : loss = 0.4670565028985341\n",
      "Step 7 : loss = 0.4490799307823181\n",
      "Step 8 : loss = 0.4318026900291443\n",
      "Step 9 : loss = 0.4145699739456177\n",
      "Update Procedure\n",
      "Step0 : loss = 3.8933071891466775\n",
      "Step1 : loss = 3.7379563252131143\n",
      "Step2 : loss = 3.652892013390859\n",
      "Step3 : loss = 3.603873292605082\n",
      "Step4 : loss = 3.5655993620554605\n",
      "Step5 : loss = 3.5348828633626304\n",
      "Step6 : loss = 3.4995588858922324\n",
      "Step7 : loss = 3.4632743994394937\n",
      "Step8 : loss = 3.427062690258026\n",
      "Step9 : loss = 3.3888870676358542\n",
      "Data stream Batch- 5 : loss = 9.401050090789795\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4504786978165309\n",
      "Step 1 : loss = 0.4254120389620463\n",
      "Step 2 : loss = 0.40439223249753314\n",
      "Step 3 : loss = 0.38616854449113214\n",
      "Step 4 : loss = 0.37058863043785095\n",
      "Step 5 : loss = 0.35621771216392517\n",
      "Step 6 : loss = 0.3432770172754923\n",
      "Step 7 : loss = 0.33271507670482003\n",
      "Step 8 : loss = 0.32303527990976966\n",
      "Step 9 : loss = 0.3141274700562159\n",
      "Update Procedure\n",
      "Step0 : loss = 4.631464668682644\n",
      "Step1 : loss = 4.45371629510607\n",
      "Step2 : loss = 4.34052928856441\n",
      "Step3 : loss = 4.245890072413853\n",
      "Step4 : loss = 4.166938151632037\n",
      "Step5 : loss = 4.08084067276546\n",
      "Step6 : loss = 3.986399701663426\n",
      "Step7 : loss = 3.8834865263530185\n",
      "Step8 : loss = 3.7739735330854143\n",
      "Step9 : loss = 3.655306441443307\n",
      "Data stream Batch- 6 : loss = 6.912503004074097\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4554102023442586\n",
      "Step 1 : loss = 0.42342020074526465\n",
      "Step 2 : loss = 0.3934031675259272\n",
      "Step 3 : loss = 0.3691921830177307\n",
      "Step 4 : loss = 0.3506499081850052\n",
      "Step 5 : loss = 0.3357121547063192\n",
      "Step 6 : loss = 0.3218782295783361\n",
      "Step 7 : loss = 0.3086069573958715\n",
      "Step 8 : loss = 0.2958657816052437\n",
      "Step 9 : loss = 0.2849410672982534\n",
      "Update Procedure\n",
      "Step0 : loss = 4.374116495251656\n",
      "Step1 : loss = 4.156893819570541\n",
      "Step2 : loss = 3.956415757536888\n",
      "Step3 : loss = 3.776839926838875\n",
      "Step4 : loss = 3.5844628363847733\n",
      "Step5 : loss = 3.4072841852903366\n",
      "Step6 : loss = 3.2207070887088776\n",
      "Step7 : loss = 3.0208821892738342\n",
      "Step8 : loss = 2.812698759138584\n",
      "Step9 : loss = 2.592492252588272\n",
      "Data stream Batch- 7 : loss = 3.2657063007354736\n",
      "Task  2\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5616797894919439\n",
      "Step 1 : loss = 0.5420450021350195\n",
      "Step 2 : loss = 0.522697936433057\n",
      "Step 3 : loss = 0.5026299475706996\n",
      "Step 4 : loss = 0.48242755146135413\n",
      "Step 5 : loss = 0.4620890165664374\n",
      "Step 6 : loss = 0.44162474253939255\n",
      "Step 7 : loss = 0.42101056039451606\n",
      "Step 8 : loss = 0.4004952519097262\n",
      "Step 9 : loss = 0.37935666278418567\n",
      "Update Procedure\n",
      "Step0 : loss = 4.655698776245117\n",
      "Step1 : loss = 4.245882511138916\n",
      "Step2 : loss = 3.847745895385742\n",
      "Step3 : loss = 3.464188814163208\n",
      "Step4 : loss = 3.090745449066162\n",
      "Step5 : loss = 2.7221426963806152\n",
      "Step6 : loss = 2.3592689037323\n",
      "Step7 : loss = 2.0057168006896973\n",
      "Step8 : loss = 1.6918748617172241\n",
      "Step9 : loss = 1.4864356517791748\n",
      "Data stream Batch- 0 : loss = 4.107835531234741\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.46833185157960366\n",
      "Step 1 : loss = 0.44715782716456387\n",
      "Step 2 : loss = 0.42604621687223987\n",
      "Step 3 : loss = 0.40478931938608487\n",
      "Step 4 : loss = 0.38305602406580297\n",
      "Step 5 : loss = 0.36104786407261613\n",
      "Step 6 : loss = 0.3391123530854072\n",
      "Step 7 : loss = 0.3169949032070618\n",
      "Step 8 : loss = 0.29465161832788633\n",
      "Step 9 : loss = 0.2722011323426924\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9986013174057007\n",
      "Step1 : loss = 3.2285622358322144\n",
      "Step2 : loss = 2.65056312084198\n",
      "Step3 : loss = 2.2914753556251526\n",
      "Step4 : loss = 2.1313535571098328\n",
      "Step5 : loss = 2.0253008604049683\n",
      "Step6 : loss = 1.935772180557251\n",
      "Step7 : loss = 1.8498440980911255\n",
      "Step8 : loss = 1.7555904984474182\n",
      "Step9 : loss = 1.6609100103378296\n",
      "Data stream Batch- 1 : loss = 4.13208794593811\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.40200647038245013\n",
      "Step 1 : loss = 0.3794145814897049\n",
      "Step 2 : loss = 0.3582308163363782\n",
      "Step 3 : loss = 0.33701777399059324\n",
      "Step 4 : loss = 0.3156222612818792\n",
      "Step 5 : loss = 0.2941344989315858\n",
      "Step 6 : loss = 0.27261132306700187\n",
      "Step 7 : loss = 0.2517878716929801\n",
      "Step 8 : loss = 0.231637932833225\n",
      "Step 9 : loss = 0.2120588956992068\n",
      "Update Procedure\n",
      "Step0 : loss = 2.767518719037374\n",
      "Step1 : loss = 2.1153441270192466\n",
      "Step2 : loss = 1.7024250030517578\n",
      "Step3 : loss = 1.430790901184082\n",
      "Step4 : loss = 1.326506535212199\n",
      "Step5 : loss = 1.291984220345815\n",
      "Step6 : loss = 1.1945679386456807\n",
      "Step7 : loss = 1.0597426891326904\n",
      "Step8 : loss = 0.989280899365743\n",
      "Step9 : loss = 0.9890965421994528\n",
      "Data stream Batch- 2 : loss = 4.196960926055908\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.35066724361053536\n",
      "Step 1 : loss = 0.32586718394701913\n",
      "Step 2 : loss = 0.30104495511641577\n",
      "Step 3 : loss = 0.2765406524999038\n",
      "Step 4 : loss = 0.25362778824887106\n",
      "Step 5 : loss = 0.2321851385905156\n",
      "Step 6 : loss = 0.2132328546029471\n",
      "Step 7 : loss = 0.19715573130441563\n",
      "Step 8 : loss = 0.18284723644869194\n",
      "Step 9 : loss = 0.16987298756896976\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5086747109889984\n",
      "Step1 : loss = 1.5605236887931824\n",
      "Step2 : loss = 1.3174341320991516\n",
      "Step3 : loss = 1.4085463881492615\n",
      "Step4 : loss = 1.3250345885753632\n",
      "Step5 : loss = 1.2020685970783234\n",
      "Step6 : loss = 1.1666370332241058\n",
      "Step7 : loss = 1.1456481963396072\n",
      "Step8 : loss = 1.0943397283554077\n",
      "Step9 : loss = 1.0614875257015228\n",
      "Data stream Batch- 3 : loss = 4.230635643005371\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.27446631124864024\n",
      "Step 1 : loss = 0.2513877738296749\n",
      "Step 2 : loss = 0.22930478168917554\n",
      "Step 3 : loss = 0.20963390378192776\n",
      "Step 4 : loss = 0.1931959733573927\n",
      "Step 5 : loss = 0.17975276001389065\n",
      "Step 6 : loss = 0.16727080079948617\n",
      "Step 7 : loss = 0.1555465815145345\n",
      "Step 8 : loss = 0.14369835825193497\n",
      "Step 9 : loss = 0.13206346195841592\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3024417638778685\n",
      "Step1 : loss = 1.786906349658966\n",
      "Step2 : loss = 1.6165995955467225\n",
      "Step3 : loss = 1.4750181555747985\n",
      "Step4 : loss = 1.376932144165039\n",
      "Step5 : loss = 1.306407594680786\n",
      "Step6 : loss = 1.2270645141601562\n",
      "Step7 : loss = 1.161315131187439\n",
      "Step8 : loss = 1.1134364247322082\n",
      "Step9 : loss = 1.079103171825409\n",
      "Data stream Batch- 4 : loss = 4.241165637969971\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2493856656439011\n",
      "Step 1 : loss = 0.2261732701034773\n",
      "Step 2 : loss = 0.2039440863218809\n",
      "Step 3 : loss = 0.18424956139236215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 : loss = 0.16798303142663032\n",
      "Step 5 : loss = 0.15488919137962281\n",
      "Step 6 : loss = 0.14332262949338034\n",
      "Step 7 : loss = 0.13204269879867161\n",
      "Step 8 : loss = 0.12122735229158213\n",
      "Step 9 : loss = 0.1113760170186796\n",
      "Update Procedure\n",
      "Step0 : loss = 2.348814090092977\n",
      "Step1 : loss = 1.8646593987941742\n",
      "Step2 : loss = 1.778808703025182\n",
      "Step3 : loss = 1.6821180979410808\n",
      "Step4 : loss = 1.6546971201896667\n",
      "Step5 : loss = 1.624734212954839\n",
      "Step6 : loss = 1.5857230226198833\n",
      "Step7 : loss = 1.5557885468006134\n",
      "Step8 : loss = 1.5241558452447255\n",
      "Step9 : loss = 1.4951659341653187\n",
      "Data stream Batch- 5 : loss = 3.672901153564453\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.20697492277101864\n",
      "Step 1 : loss = 0.18549738986388084\n",
      "Step 2 : loss = 0.16591953761461709\n",
      "Step 3 : loss = 0.14943400976795052\n",
      "Step 4 : loss = 0.13530775398489028\n",
      "Step 5 : loss = 0.12384352409650409\n",
      "Step 6 : loss = 0.11479164846241474\n",
      "Step 7 : loss = 0.10648618352318567\n",
      "Step 8 : loss = 0.09865325923772558\n",
      "Step 9 : loss = 0.09134361479904443\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3853154352733066\n",
      "Step1 : loss = 2.0747475964682445\n",
      "Step2 : loss = 1.937883504799434\n",
      "Step3 : loss = 1.8697479026658195\n",
      "Step4 : loss = 1.8112327456474304\n",
      "Step5 : loss = 1.751483372279576\n",
      "Step6 : loss = 1.6954078333718436\n",
      "Step7 : loss = 1.6352415680885315\n",
      "Step8 : loss = 1.5781928982053484\n",
      "Step9 : loss = 1.5209565673555647\n",
      "Data stream Batch- 6 : loss = 2.5888689756393433\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1589122802610435\n",
      "Step 1 : loss = 0.14102405840087504\n",
      "Step 2 : loss = 0.1259509697793022\n",
      "Step 3 : loss = 0.1140583365475611\n",
      "Step 4 : loss = 0.10503804544726061\n",
      "Step 5 : loss = 0.09751411518821168\n",
      "Step 6 : loss = 0.09076372560054537\n",
      "Step 7 : loss = 0.08574938600262005\n",
      "Step 8 : loss = 0.08197808715086136\n",
      "Step 9 : loss = 0.07990511116527377\n",
      "Update Procedure\n",
      "Step0 : loss = 2.006307750940323\n",
      "Step1 : loss = 1.786960355937481\n",
      "Step2 : loss = 1.603464037179947\n",
      "Step3 : loss = 1.5130810141563416\n",
      "Step4 : loss = 1.3980482146143913\n",
      "Step5 : loss = 1.3052441403269768\n",
      "Step6 : loss = 1.2095208764076233\n",
      "Step7 : loss = 1.115810714662075\n",
      "Step8 : loss = 1.018012374639511\n",
      "Step9 : loss = 0.9299239441752434\n",
      "Data stream Batch- 7 : loss = 0.9733498692512512\n",
      "Task  3\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.08029749810466687\n",
      "Step 1 : loss = 0.07579987597842962\n",
      "Step 2 : loss = 0.07152926068026551\n",
      "Step 3 : loss = 0.06760877092943443\n",
      "Step 4 : loss = 0.06396283328826764\n",
      "Step 5 : loss = 0.060571004350928104\n",
      "Step 6 : loss = 0.05741531770681824\n",
      "Step 7 : loss = 0.05442656061556447\n",
      "Step 8 : loss = 0.05171491950252859\n",
      "Step 9 : loss = 0.049456983093078936\n",
      "Update Procedure\n",
      "Step0 : loss = 9.446905136108398\n",
      "Step1 : loss = 9.271598815917969\n",
      "Step2 : loss = 9.10830307006836\n",
      "Step3 : loss = 8.950028419494629\n",
      "Step4 : loss = 8.800423622131348\n",
      "Step5 : loss = 8.65483283996582\n",
      "Step6 : loss = 8.51281452178955\n",
      "Step7 : loss = 8.371881484985352\n",
      "Step8 : loss = 8.233073234558105\n",
      "Step9 : loss = 8.095789909362793\n",
      "Data stream Batch- 0 : loss = 6.242702007293701\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.048974142003257226\n",
      "Step 1 : loss = 0.04760044056363533\n",
      "Step 2 : loss = 0.04629237466587972\n",
      "Step 3 : loss = 0.04515804287722897\n",
      "Step 4 : loss = 0.04446457484823969\n",
      "Step 5 : loss = 0.04381782442812853\n",
      "Step 6 : loss = 0.043169513378141205\n",
      "Step 7 : loss = 0.04294684873348234\n",
      "Step 8 : loss = 0.04257046291437447\n",
      "Step 9 : loss = 0.04221246143755541\n",
      "Update Procedure\n",
      "Step0 : loss = 9.03255844116211\n",
      "Step1 : loss = 8.609063625335693\n",
      "Step2 : loss = 8.207273721694946\n",
      "Step3 : loss = 7.817836046218872\n",
      "Step4 : loss = 7.454850912094116\n",
      "Step5 : loss = 7.125752687454224\n",
      "Step6 : loss = 6.87171196937561\n",
      "Step7 : loss = 6.666561126708984\n",
      "Step8 : loss = 6.480140686035156\n",
      "Step9 : loss = 6.313690662384033\n",
      "Data stream Batch- 1 : loss = 5.072940826416016\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.05320777701711821\n",
      "Step 1 : loss = 0.049256405829077476\n",
      "Step 2 : loss = 0.047324277390024594\n",
      "Step 3 : loss = 0.04557608946597926\n",
      "Step 4 : loss = 0.044189557530540935\n",
      "Step 5 : loss = 0.04278391306102012\n",
      "Step 6 : loss = 0.04188690281055321\n",
      "Step 7 : loss = 0.04129805263514246\n",
      "Step 8 : loss = 0.04082383061550148\n",
      "Step 9 : loss = 0.040560057582498685\n",
      "Update Procedure\n",
      "Step0 : loss = 5.374022881189982\n",
      "Step1 : loss = 4.9909437497456866\n",
      "Step2 : loss = 4.663281440734863\n",
      "Step3 : loss = 4.390950997670491\n",
      "Step4 : loss = 4.209075411160787\n",
      "Step5 : loss = 4.132394591967265\n",
      "Step6 : loss = 4.1028023560841875\n",
      "Step7 : loss = 4.081827481587728\n",
      "Step8 : loss = 4.05537223815918\n",
      "Step9 : loss = 4.019600868225098\n",
      "Data stream Batch- 2 : loss = 4.211606979370117\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.055768931594301324\n",
      "Step 1 : loss = 0.05113671179959035\n",
      "Step 2 : loss = 0.04863332305525575\n",
      "Step 3 : loss = 0.046511768385441465\n",
      "Step 4 : loss = 0.04457454448148385\n",
      "Step 5 : loss = 0.04279071721945688\n",
      "Step 6 : loss = 0.041445362682399386\n",
      "Step 7 : loss = 0.04030207247670803\n",
      "Step 8 : loss = 0.039780661405839544\n",
      "Step 9 : loss = 0.038880945224575046\n",
      "Update Procedure\n",
      "Step0 : loss = 3.2117437571287155\n",
      "Step1 : loss = 3.0958523750305176\n",
      "Step2 : loss = 3.0536204650998116\n",
      "Step3 : loss = 3.0100468173623085\n",
      "Step4 : loss = 2.970204122364521\n",
      "Step5 : loss = 2.9313266202807426\n",
      "Step6 : loss = 2.894346110522747\n",
      "Step7 : loss = 2.8622023835778236\n",
      "Step8 : loss = 2.833451561629772\n",
      "Step9 : loss = 2.8043668940663338\n",
      "Data stream Batch- 3 : loss = 4.15328574180603\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.06197953380588176\n",
      "Step 1 : loss = 0.05421315746639011\n",
      "Step 2 : loss = 0.04754547941418721\n",
      "Step 3 : loss = 0.04265073456357763\n",
      "Step 4 : loss = 0.04095089086882451\n",
      "Step 5 : loss = 0.039904517906459484\n",
      "Step 6 : loss = 0.03890264206466642\n",
      "Step 7 : loss = 0.03856678257404828\n",
      "Step 8 : loss = 0.038190290335517574\n",
      "Step 9 : loss = 0.037954274984706764\n",
      "Update Procedure\n",
      "Step0 : loss = 3.0799095928668976\n",
      "Step1 : loss = 2.9612812876701353\n",
      "Step2 : loss = 2.9191474616527557\n",
      "Step3 : loss = 2.8586399078369142\n",
      "Step4 : loss = 2.8228145599365235\n",
      "Step5 : loss = 2.7690717041492463\n",
      "Step6 : loss = 2.7392849385738374\n",
      "Step7 : loss = 2.70534343123436\n",
      "Step8 : loss = 2.6753792583942415\n",
      "Step9 : loss = 2.644710421562195\n",
      "Data stream Batch- 4 : loss = 3.9183205366134644\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.0597875848523938\n",
      "Step 1 : loss = 0.05245358329870268\n",
      "Step 2 : loss = 0.04651885275861623\n",
      "Step 3 : loss = 0.042029297524533764\n",
      "Step 4 : loss = 0.03925838956877949\n",
      "Step 5 : loss = 0.03781911645329757\n",
      "Step 6 : loss = 0.03755131670288698\n",
      "Step 7 : loss = 0.0370903304754999\n",
      "Step 8 : loss = 0.03695498136381026\n",
      "Step 9 : loss = 0.03680467230345221\n",
      "Update Procedure\n",
      "Step0 : loss = 3.159926727414131\n",
      "Step1 : loss = 3.0819008549054465\n",
      "Step2 : loss = 3.0121018985907235\n",
      "Step3 : loss = 2.948983614643415\n",
      "Step4 : loss = 2.891841476162275\n",
      "Step5 : loss = 2.8481323222319284\n",
      "Step6 : loss = 2.8097078601519265\n",
      "Step7 : loss = 2.7716858088970184\n",
      "Step8 : loss = 2.7338122030099234\n",
      "Step9 : loss = 2.6979273756345115\n",
      "Data stream Batch- 5 : loss = 3.101195275783539\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.07986978752835465\n",
      "Step 1 : loss = 0.07169521029808316\n",
      "Step 2 : loss = 0.0653854376300045\n",
      "Step 3 : loss = 0.06010971576513052\n",
      "Step 4 : loss = 0.055128008878018\n",
      "Step 5 : loss = 0.05050663478119639\n",
      "Step 6 : loss = 0.04634909765269533\n",
      "Step 7 : loss = 0.04263543559183414\n",
      "Step 8 : loss = 0.04025022778726035\n",
      "Step 9 : loss = 0.038723551502859846\n",
      "Update Procedure\n",
      "Step0 : loss = 3.449999306883131\n",
      "Step1 : loss = 3.3440848333495006\n",
      "Step2 : loss = 3.227250805922917\n",
      "Step3 : loss = 3.1265596619674136\n",
      "Step4 : loss = 3.0426310896873474\n",
      "Step5 : loss = 2.969972218785967\n",
      "Step6 : loss = 2.9092020222118924\n",
      "Step7 : loss = 2.8473195476191386\n",
      "Step8 : loss = 2.7881219514778683\n",
      "Step9 : loss = 2.7291274666786194\n",
      "Data stream Batch- 6 : loss = 2.5833545923233032\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.12324958837770572\n",
      "Step 1 : loss = 0.11348164142205468\n",
      "Step 2 : loss = 0.10367555124371741\n",
      "Step 3 : loss = 0.09402590964615405\n",
      "Step 4 : loss = 0.08467290588422854\n",
      "Step 5 : loss = 0.07684691627019294\n",
      "Step 6 : loss = 0.07088618217438228\n",
      "Step 7 : loss = 0.06511985782216127\n",
      "Step 8 : loss = 0.059756195239972\n",
      "Step 9 : loss = 0.05492617748445485\n",
      "Update Procedure\n",
      "Step0 : loss = 3.2662084698677063\n",
      "Step1 : loss = 3.100311517715454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step2 : loss = 2.9503397345542908\n",
      "Step3 : loss = 2.8464847281575203\n",
      "Step4 : loss = 2.719575498253107\n",
      "Step5 : loss = 2.6190132796764374\n",
      "Step6 : loss = 2.5230781883001328\n",
      "Step7 : loss = 2.431711718440056\n",
      "Step8 : loss = 2.3539354987442493\n",
      "Step9 : loss = 2.289645478129387\n",
      "Data stream Batch- 7 : loss = 2.468234360218048\n",
      "Task  4\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1697694180643955\n",
      "Step 1 : loss = 0.16698262502722835\n",
      "Step 2 : loss = 0.16431068948455335\n",
      "Step 3 : loss = 0.16158916372674353\n",
      "Step 4 : loss = 0.1588305552310764\n",
      "Step 5 : loss = 0.15603479763183134\n",
      "Step 6 : loss = 0.15321213778491166\n",
      "Step 7 : loss = 0.1506421406009394\n",
      "Step 8 : loss = 0.14885598431292776\n",
      "Step 9 : loss = 0.14735095028620748\n",
      "Update Procedure\n",
      "Step0 : loss = 5.687490463256836\n",
      "Step1 : loss = 5.495182037353516\n",
      "Step2 : loss = 5.317735195159912\n",
      "Step3 : loss = 5.156877517700195\n",
      "Step4 : loss = 5.011363983154297\n",
      "Step5 : loss = 4.865053176879883\n",
      "Step6 : loss = 4.717466354370117\n",
      "Step7 : loss = 4.569167613983154\n",
      "Step8 : loss = 4.4208664894104\n",
      "Step9 : loss = 4.273296356201172\n",
      "Data stream Batch- 0 : loss = 5.346702337265015\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1508983503040476\n",
      "Step 1 : loss = 0.14796496635833134\n",
      "Step 2 : loss = 0.14511397664231349\n",
      "Step 3 : loss = 0.14238690143026747\n",
      "Step 4 : loss = 0.13941715180803843\n",
      "Step 5 : loss = 0.1364570305016203\n",
      "Step 6 : loss = 0.13356434733468722\n",
      "Step 7 : loss = 0.13086179174876222\n",
      "Step 8 : loss = 0.12889176366180388\n",
      "Step 9 : loss = 0.12730882635793414\n",
      "Update Procedure\n",
      "Step0 : loss = 6.572299957275391\n",
      "Step1 : loss = 6.185570240020752\n",
      "Step2 : loss = 5.836436033248901\n",
      "Step3 : loss = 5.499165058135986\n",
      "Step4 : loss = 5.173250436782837\n",
      "Step5 : loss = 4.85867440700531\n",
      "Step6 : loss = 4.55478572845459\n",
      "Step7 : loss = 4.260325908660889\n",
      "Step8 : loss = 3.974492073059082\n",
      "Step9 : loss = 3.7000911235809326\n",
      "Data stream Batch- 1 : loss = 5.09539794921875\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.16101770424408268\n",
      "Step 1 : loss = 0.15519416399123262\n",
      "Step 2 : loss = 0.14954627465101117\n",
      "Step 3 : loss = 0.1440999945383689\n",
      "Step 4 : loss = 0.13889175522174374\n",
      "Step 5 : loss = 0.13388878801854573\n",
      "Step 6 : loss = 0.12920863829697635\n",
      "Step 7 : loss = 0.1253449100608326\n",
      "Step 8 : loss = 0.12173189141051613\n",
      "Step 9 : loss = 0.11845938911483722\n",
      "Update Procedure\n",
      "Step0 : loss = 4.839886665344238\n",
      "Step1 : loss = 4.240918477376302\n",
      "Step2 : loss = 3.7980123360951743\n",
      "Step3 : loss = 3.46897029876709\n",
      "Step4 : loss = 3.222414573033651\n",
      "Step5 : loss = 3.0147319634755454\n",
      "Step6 : loss = 2.8315038283665976\n",
      "Step7 : loss = 2.673179785410563\n",
      "Step8 : loss = 2.53966756661733\n",
      "Step9 : loss = 2.430162866910299\n",
      "Data stream Batch- 2 : loss = 4.769092082977295\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.16522283687778094\n",
      "Step 1 : loss = 0.15864485330776765\n",
      "Step 2 : loss = 0.15250496779409703\n",
      "Step 3 : loss = 0.14666218784853577\n",
      "Step 4 : loss = 0.14109272091103772\n",
      "Step 5 : loss = 0.13569586746421455\n",
      "Step 6 : loss = 0.1303973410823204\n",
      "Step 7 : loss = 0.12522386047665177\n",
      "Step 8 : loss = 0.12067238187336918\n",
      "Step 9 : loss = 0.11642176812251202\n",
      "Update Procedure\n",
      "Step0 : loss = 4.916817009449005\n",
      "Step1 : loss = 4.640894562005997\n",
      "Step2 : loss = 4.511972188949585\n",
      "Step3 : loss = 4.4035603404045105\n",
      "Step4 : loss = 4.301157757639885\n",
      "Step5 : loss = 4.202947527170181\n",
      "Step6 : loss = 4.111084386706352\n",
      "Step7 : loss = 4.025017440319061\n",
      "Step8 : loss = 3.9435589611530304\n",
      "Step9 : loss = 3.862783119082451\n",
      "Data stream Batch- 3 : loss = 4.675121068954468\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.15089080467739913\n",
      "Step 1 : loss = 0.14664928675902064\n",
      "Step 2 : loss = 0.14287866822726142\n",
      "Step 3 : loss = 0.13931712435312305\n",
      "Step 4 : loss = 0.1357377953594203\n",
      "Step 5 : loss = 0.132427740601678\n",
      "Step 6 : loss = 0.1288935255227934\n",
      "Step 7 : loss = 0.12566879527476385\n",
      "Step 8 : loss = 0.12213698294337086\n",
      "Step 9 : loss = 0.11918670611920083\n",
      "Update Procedure\n",
      "Step0 : loss = 6.2196238994598385\n",
      "Step1 : loss = 5.945238661766052\n",
      "Step2 : loss = 5.788766133785248\n",
      "Step3 : loss = 5.666672420501709\n",
      "Step4 : loss = 5.548359000682831\n",
      "Step5 : loss = 5.42632936835289\n",
      "Step6 : loss = 5.305649369955063\n",
      "Step7 : loss = 5.186057472229004\n",
      "Step8 : loss = 5.064238101243973\n",
      "Step9 : loss = 4.9406932413578035\n",
      "Data stream Batch- 4 : loss = 4.493380546569824\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.22765639594784554\n",
      "Step 1 : loss = 0.22070073851329938\n",
      "Step 2 : loss = 0.21381897381948126\n",
      "Step 3 : loss = 0.20683946897752248\n",
      "Step 4 : loss = 0.19999415820120583\n",
      "Step 5 : loss = 0.19281076406546468\n",
      "Step 6 : loss = 0.1853998475480185\n",
      "Step 7 : loss = 0.1781500589264871\n",
      "Step 8 : loss = 0.17093330371571244\n",
      "Step 9 : loss = 0.16396755349926756\n",
      "Update Procedure\n",
      "Step0 : loss = 5.154149035612742\n",
      "Step1 : loss = 4.867560038963954\n",
      "Step2 : loss = 4.710283448298772\n",
      "Step3 : loss = 4.582226822773616\n",
      "Step4 : loss = 4.475210189819336\n",
      "Step5 : loss = 4.380712613463402\n",
      "Step6 : loss = 4.287289083003998\n",
      "Step7 : loss = 4.1996336082617445\n",
      "Step8 : loss = 4.117826918760936\n",
      "Step9 : loss = 4.035578062136968\n",
      "Data stream Batch- 5 : loss = 3.5132681131362915\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.25919482679453015\n",
      "Step 1 : loss = 0.25067521068035703\n",
      "Step 2 : loss = 0.24203338316471207\n",
      "Step 3 : loss = 0.23377229321270018\n",
      "Step 4 : loss = 0.22576905969375732\n",
      "Step 5 : loss = 0.21793093845130157\n",
      "Step 6 : loss = 0.21013734027820946\n",
      "Step 7 : loss = 0.2025246863177232\n",
      "Step 8 : loss = 0.19490716854282067\n",
      "Step 9 : loss = 0.18825079472754722\n",
      "Update Procedure\n",
      "Step0 : loss = 4.146410635539463\n",
      "Step1 : loss = 3.80753698519298\n",
      "Step2 : loss = 3.675082700593131\n",
      "Step3 : loss = 3.5776786463601247\n",
      "Step4 : loss = 3.4712676405906677\n",
      "Step5 : loss = 3.366286975996835\n",
      "Step6 : loss = 3.267911893980844\n",
      "Step7 : loss = 3.1714856156281064\n",
      "Step8 : loss = 3.078263593571527\n",
      "Step9 : loss = 2.9886364340782166\n",
      "Data stream Batch- 6 : loss = 2.336515784263611\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2809716374604845\n",
      "Step 1 : loss = 0.27197184117479617\n",
      "Step 2 : loss = 0.26302960345896964\n",
      "Step 3 : loss = 0.25402215869778283\n",
      "Step 4 : loss = 0.24515987080248217\n",
      "Step 5 : loss = 0.23633306540782628\n",
      "Step 6 : loss = 0.2279693216557701\n",
      "Step 7 : loss = 0.22096914051896405\n",
      "Step 8 : loss = 0.21445074248749185\n",
      "Step 9 : loss = 0.2080633731848646\n",
      "Update Procedure\n",
      "Step0 : loss = 3.1016265749931335\n",
      "Step1 : loss = 2.7756526432931423\n",
      "Step2 : loss = 2.6431548334658146\n",
      "Step3 : loss = 2.5560217052698135\n",
      "Step4 : loss = 2.4604524187743664\n",
      "Step5 : loss = 2.3875581808388233\n",
      "Step6 : loss = 2.324005149304867\n",
      "Step7 : loss = 2.27667348831892\n",
      "Step8 : loss = 2.230545789003372\n",
      "Step9 : loss = 2.1887933015823364\n",
      "Data stream Batch- 7 : loss = 1.5442513227462769\n",
      "Task  5\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.029924351874889076\n",
      "Step 1 : loss = 0.028403414923298932\n",
      "Step 2 : loss = 0.026944242599635293\n",
      "Step 3 : loss = 0.02553760994382103\n",
      "Step 4 : loss = 0.024173647963534196\n",
      "Step 5 : loss = 0.022951204818182257\n",
      "Step 6 : loss = 0.02193031616758776\n",
      "Step 7 : loss = 0.021327095166873276\n",
      "Step 8 : loss = 0.021159980658715098\n",
      "Step 9 : loss = 0.020824867688291473\n",
      "Update Procedure\n",
      "Step0 : loss = 5.467230319976807\n",
      "Step1 : loss = 5.3285932540893555\n",
      "Step2 : loss = 5.190769672393799\n",
      "Step3 : loss = 5.053542613983154\n",
      "Step4 : loss = 4.915226936340332\n",
      "Step5 : loss = 4.776078224182129\n",
      "Step6 : loss = 4.638935089111328\n",
      "Step7 : loss = 4.511420726776123\n",
      "Step8 : loss = 4.399410247802734\n",
      "Step9 : loss = 4.327942848205566\n",
      "Data stream Batch- 0 : loss = 5.913533687591553\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.03135473774828417\n",
      "Step 1 : loss = 0.02790223655077379\n",
      "Step 2 : loss = 0.02514323099318892\n",
      "Step 3 : loss = 0.023257986937499985\n",
      "Step 4 : loss = 0.02188542542072244\n",
      "Step 5 : loss = 0.020904540701622606\n",
      "Step 6 : loss = 0.020324068800186813\n",
      "Step 7 : loss = 0.01995229416885451\n",
      "Step 8 : loss = 0.019597516227724536\n",
      "Step 9 : loss = 0.019589945303541828\n",
      "Update Procedure\n",
      "Step0 : loss = 4.634355306625366\n",
      "Step1 : loss = 4.540442228317261\n",
      "Step2 : loss = 4.43414831161499\n",
      "Step3 : loss = 4.337944746017456\n",
      "Step4 : loss = 4.229331731796265\n",
      "Step5 : loss = 4.123063087463379\n",
      "Step6 : loss = 4.022114634513855\n",
      "Step7 : loss = 3.9187395572662354\n",
      "Step8 : loss = 3.817638397216797\n",
      "Step9 : loss = 3.71509051322937\n",
      "Data stream Batch- 1 : loss = 5.74575662612915\n",
      "Meta Update\n",
      "Training is starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 0.03588664661973967\n",
      "Step 1 : loss = 0.0320491291559097\n",
      "Step 2 : loss = 0.02879446683382463\n",
      "Step 3 : loss = 0.026557564484807755\n",
      "Step 4 : loss = 0.02512616200264816\n",
      "Step 5 : loss = 0.023785119255693245\n",
      "Step 6 : loss = 0.02257307296995086\n",
      "Step 7 : loss = 0.02147472153858453\n",
      "Step 8 : loss = 0.02085469242323651\n",
      "Step 9 : loss = 0.020452215870219462\n",
      "Update Procedure\n",
      "Step0 : loss = 3.8962289492289224\n",
      "Step1 : loss = 3.722971518834432\n",
      "Step2 : loss = 3.5800727208455405\n",
      "Step3 : loss = 3.4628761609395347\n",
      "Step4 : loss = 3.3510982195536294\n",
      "Step5 : loss = 3.250601053237915\n",
      "Step6 : loss = 3.1569766998291016\n",
      "Step7 : loss = 3.067044496536255\n",
      "Step8 : loss = 2.983359972635905\n",
      "Step9 : loss = 2.9060526688893638\n",
      "Data stream Batch- 2 : loss = 5.5160839557647705\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.03649885493168619\n",
      "Step 1 : loss = 0.032529252345800355\n",
      "Step 2 : loss = 0.029284513642547798\n",
      "Step 3 : loss = 0.027136094154000572\n",
      "Step 4 : loss = 0.025519070331665776\n",
      "Step 5 : loss = 0.024826977576522684\n",
      "Step 6 : loss = 0.023773975786333855\n",
      "Step 7 : loss = 0.023460211726517563\n",
      "Step 8 : loss = 0.02263912389254227\n",
      "Step 9 : loss = 0.022654206557876984\n",
      "Update Procedure\n",
      "Step0 : loss = 2.8806645274162292\n",
      "Step1 : loss = 2.7209832072257996\n",
      "Step2 : loss = 2.6453660130500793\n",
      "Step3 : loss = 2.5738366544246674\n",
      "Step4 : loss = 2.5101612508296967\n",
      "Step5 : loss = 2.446706533432007\n",
      "Step6 : loss = 2.386569917201996\n",
      "Step7 : loss = 2.328634023666382\n",
      "Step8 : loss = 2.2713960111141205\n",
      "Step9 : loss = 2.2129958271980286\n",
      "Data stream Batch- 3 : loss = 5.181263208389282\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.0384626394989387\n",
      "Step 1 : loss = 0.03613265541568924\n",
      "Step 2 : loss = 0.03391923270480302\n",
      "Step 3 : loss = 0.03180755279778618\n",
      "Step 4 : loss = 0.02959524471309407\n",
      "Step 5 : loss = 0.027634617682891622\n",
      "Step 6 : loss = 0.025999619267676428\n",
      "Step 7 : loss = 0.02472913373191603\n",
      "Step 8 : loss = 0.023640373533551102\n",
      "Step 9 : loss = 0.02311532489795451\n",
      "Update Procedure\n",
      "Step0 : loss = 2.264480781555176\n",
      "Step1 : loss = 2.1650262594223024\n",
      "Step2 : loss = 2.100651669502258\n",
      "Step3 : loss = 2.0504546642303465\n",
      "Step4 : loss = 2.002182865142822\n",
      "Step5 : loss = 1.9412141799926759\n",
      "Step6 : loss = 1.8995963096618653\n",
      "Step7 : loss = 1.8428449153900146\n",
      "Step8 : loss = 1.7841198444366455\n",
      "Step9 : loss = 1.7359683990478516\n",
      "Data stream Batch- 4 : loss = 4.827873945236206\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.0430980800589318\n",
      "Step 1 : loss = 0.04008037436827745\n",
      "Step 2 : loss = 0.037185493288670254\n",
      "Step 3 : loss = 0.03442402584141756\n",
      "Step 4 : loss = 0.0318737384202681\n",
      "Step 5 : loss = 0.029550132109586614\n",
      "Step 6 : loss = 0.027429441960684774\n",
      "Step 7 : loss = 0.025559788077687596\n",
      "Step 8 : loss = 0.024281607298194532\n",
      "Step 9 : loss = 0.022884340917017045\n",
      "Update Procedure\n",
      "Step0 : loss = 2.374618629614512\n",
      "Step1 : loss = 2.278954883416494\n",
      "Step2 : loss = 2.1019879380861917\n",
      "Step3 : loss = 2.0435702403386435\n",
      "Step4 : loss = 1.9653177857398987\n",
      "Step5 : loss = 1.9044397274653118\n",
      "Step6 : loss = 1.8447555502255757\n",
      "Step7 : loss = 1.7805190483729045\n",
      "Step8 : loss = 1.7231159806251526\n",
      "Step9 : loss = 1.6642699639002483\n",
      "Data stream Batch- 5 : loss = 4.201063871383667\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.05598993992985921\n",
      "Step 1 : loss = 0.05154560566943138\n",
      "Step 2 : loss = 0.04724893840944376\n",
      "Step 3 : loss = 0.04325392534137821\n",
      "Step 4 : loss = 0.04013168635015006\n",
      "Step 5 : loss = 0.03733331725202517\n",
      "Step 6 : loss = 0.034829670024047354\n",
      "Step 7 : loss = 0.032747404619289835\n",
      "Step 8 : loss = 0.031109073991075403\n",
      "Step 9 : loss = 0.029456704086126162\n",
      "Update Procedure\n",
      "Step0 : loss = 1.886636802128383\n",
      "Step1 : loss = 1.7754986030714852\n",
      "Step2 : loss = 1.7255474925041199\n",
      "Step3 : loss = 1.6558259981019157\n",
      "Step4 : loss = 1.593450895377568\n",
      "Step5 : loss = 1.570611753634044\n",
      "Step6 : loss = 1.5363962735448564\n",
      "Step7 : loss = 1.5003298563616616\n",
      "Step8 : loss = 1.4840259764875685\n",
      "Step9 : loss = 1.4602380863257818\n",
      "Data stream Batch- 6 : loss = 3.8404126167297363\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.050136611840133204\n",
      "Step 1 : loss = 0.04732526516008568\n",
      "Step 2 : loss = 0.044670308661302935\n",
      "Step 3 : loss = 0.04231160204909725\n",
      "Step 4 : loss = 0.03978498982629328\n",
      "Step 5 : loss = 0.03764999071300821\n",
      "Step 6 : loss = 0.03559612855672395\n",
      "Step 7 : loss = 0.03372744711965428\n",
      "Step 8 : loss = 0.031943115835356806\n",
      "Step 9 : loss = 0.029919577845001943\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8186648339033127\n",
      "Step1 : loss = 1.7492756396532059\n",
      "Step2 : loss = 1.6572145111858845\n",
      "Step3 : loss = 1.5923928171396255\n",
      "Step4 : loss = 1.5394717045128345\n",
      "Step5 : loss = 1.5160262621939182\n",
      "Step6 : loss = 1.4694169908761978\n",
      "Step7 : loss = 1.3890123516321182\n",
      "Step8 : loss = 1.3421495221555233\n",
      "Step9 : loss = 1.2895203903317451\n",
      "Data stream Batch- 7 : loss = 3.24247407913208\n",
      "Task  6\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.09690811491589378\n",
      "Step 1 : loss = 0.0937013489458347\n",
      "Step 2 : loss = 0.09099472974497415\n",
      "Step 3 : loss = 0.08846070719050121\n",
      "Step 4 : loss = 0.08612864554596798\n",
      "Step 5 : loss = 0.0838954392200247\n",
      "Step 6 : loss = 0.08236258478570303\n",
      "Step 7 : loss = 0.07979464625160983\n",
      "Step 8 : loss = 0.07851169756574147\n",
      "Step 9 : loss = 0.07583370741911086\n",
      "Update Procedure\n",
      "Step0 : loss = 4.3934712409973145\n",
      "Step1 : loss = 4.314417362213135\n",
      "Step2 : loss = 4.235156536102295\n",
      "Step3 : loss = 4.155585765838623\n",
      "Step4 : loss = 4.075613021850586\n",
      "Step5 : loss = 3.995436191558838\n",
      "Step6 : loss = 3.9151480197906494\n",
      "Step7 : loss = 3.834714651107788\n",
      "Step8 : loss = 3.75423526763916\n",
      "Step9 : loss = 3.673687219619751\n",
      "Data stream Batch- 0 : loss = 11.974241256713867\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1110524904241546\n",
      "Step 1 : loss = 0.10524929583981997\n",
      "Step 2 : loss = 0.09955240111918755\n",
      "Step 3 : loss = 0.0939862322022988\n",
      "Step 4 : loss = 0.08864926414789487\n",
      "Step 5 : loss = 0.08409839092418503\n",
      "Step 6 : loss = 0.08006714822440343\n",
      "Step 7 : loss = 0.07637043364177991\n",
      "Step 8 : loss = 0.07297343927022264\n",
      "Step 9 : loss = 0.0697943147069516\n",
      "Update Procedure\n",
      "Step0 : loss = 4.714703321456909\n",
      "Step1 : loss = 4.558139324188232\n",
      "Step2 : loss = 4.40129280090332\n",
      "Step3 : loss = 4.24312686920166\n",
      "Step4 : loss = 4.083509683609009\n",
      "Step5 : loss = 3.9224348068237305\n",
      "Step6 : loss = 3.7595614194869995\n",
      "Step7 : loss = 3.5945096015930176\n",
      "Step8 : loss = 3.4269641637802124\n",
      "Step9 : loss = 3.25666606426239\n",
      "Data stream Batch- 1 : loss = 10.901050090789795\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13487778596340164\n",
      "Step 1 : loss = 0.12779107706569184\n",
      "Step 2 : loss = 0.12079331871211053\n",
      "Step 3 : loss = 0.1139068083335596\n",
      "Step 4 : loss = 0.10717444097689445\n",
      "Step 5 : loss = 0.10091457499640032\n",
      "Step 6 : loss = 0.09518559275442046\n",
      "Step 7 : loss = 0.09018280703290003\n",
      "Step 8 : loss = 0.08576908275822372\n",
      "Step 9 : loss = 0.08199468482510139\n",
      "Update Procedure\n",
      "Step0 : loss = 4.4498012860616045\n",
      "Step1 : loss = 4.219293276468913\n",
      "Step2 : loss = 3.9891185760498047\n",
      "Step3 : loss = 3.7625632286071777\n",
      "Step4 : loss = 3.5395752588907876\n",
      "Step5 : loss = 3.3310205936431885\n",
      "Step6 : loss = 3.139803489049276\n",
      "Step7 : loss = 2.95851993560791\n",
      "Step8 : loss = 2.7864805459976196\n",
      "Step9 : loss = 2.626984397570292\n",
      "Data stream Batch- 2 : loss = 9.625916004180908\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.17230681175983464\n",
      "Step 1 : loss = 0.1640918741616822\n",
      "Step 2 : loss = 0.1559247975938524\n",
      "Step 3 : loss = 0.1480016401087188\n",
      "Step 4 : loss = 0.14030884490881904\n",
      "Step 5 : loss = 0.13304896396675653\n",
      "Step 6 : loss = 0.1262575212556354\n",
      "Step 7 : loss = 0.12033009690474195\n",
      "Step 8 : loss = 0.11573476186438246\n",
      "Step 9 : loss = 0.11173616422624423\n",
      "Update Procedure\n",
      "Step0 : loss = 3.1759214997291565\n",
      "Step1 : loss = 2.909833014011383\n",
      "Step2 : loss = 2.666920244693756\n",
      "Step3 : loss = 2.444963216781616\n",
      "Step4 : loss = 2.2288753390312195\n",
      "Step5 : loss = 2.0385598838329315\n",
      "Step6 : loss = 1.864518940448761\n",
      "Step7 : loss = 1.6958240568637848\n",
      "Step8 : loss = 1.5275244116783142\n",
      "Step9 : loss = 1.3740327209234238\n",
      "Data stream Batch- 3 : loss = 7.852306604385376\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.17702121885833433\n",
      "Step 1 : loss = 0.17034947254131758\n",
      "Step 2 : loss = 0.16444763509495677\n",
      "Step 3 : loss = 0.15886698794037304\n",
      "Step 4 : loss = 0.15347793549612898\n",
      "Step 5 : loss = 0.14860674524825498\n",
      "Step 6 : loss = 0.143933802431603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 : loss = 0.13940287426406642\n",
      "Step 8 : loss = 0.13521194299069583\n",
      "Step 9 : loss = 0.13127353251156634\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7663178086280822\n",
      "Step1 : loss = 1.460644042491913\n",
      "Step2 : loss = 1.2637912273406982\n",
      "Step3 : loss = 1.1289691209793091\n",
      "Step4 : loss = 1.0045263648033143\n",
      "Step5 : loss = 0.902712607383728\n",
      "Step6 : loss = 0.8124988436698913\n",
      "Step7 : loss = 0.7149025917053222\n",
      "Step8 : loss = 0.6204235196113587\n",
      "Step9 : loss = 0.53073091506958\n",
      "Data stream Batch- 4 : loss = 5.6271584033966064\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.16128400604146795\n",
      "Step 1 : loss = 0.15366722784512107\n",
      "Step 2 : loss = 0.14616903196624093\n",
      "Step 3 : loss = 0.13876439441543817\n",
      "Step 4 : loss = 0.13147492248102405\n",
      "Step 5 : loss = 0.12428589778656114\n",
      "Step 6 : loss = 0.11724895957277026\n",
      "Step 7 : loss = 0.11121063708556876\n",
      "Step 8 : loss = 0.10623301375867156\n",
      "Step 9 : loss = 0.10205656746898976\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2894940972328186\n",
      "Step1 : loss = 1.0136224925518036\n",
      "Step2 : loss = 0.9458893189827601\n",
      "Step3 : loss = 0.9043504198392233\n",
      "Step4 : loss = 0.8508243461449941\n",
      "Step5 : loss = 0.8254631757736206\n",
      "Step6 : loss = 0.8008410135904948\n",
      "Step7 : loss = 0.777019222577413\n",
      "Step8 : loss = 0.7550935000181198\n",
      "Step9 : loss = 0.7347259124120077\n",
      "Data stream Batch- 5 : loss = 5.29917049407959\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13417288495733362\n",
      "Step 1 : loss = 0.12968329487449096\n",
      "Step 2 : loss = 0.12546018354817798\n",
      "Step 3 : loss = 0.12156742935640279\n",
      "Step 4 : loss = 0.11778972566682178\n",
      "Step 5 : loss = 0.11449076511318768\n",
      "Step 6 : loss = 0.11072191846579656\n",
      "Step 7 : loss = 0.10703791472796692\n",
      "Step 8 : loss = 0.10357867557823036\n",
      "Step 9 : loss = 0.10017924360351323\n",
      "Update Procedure\n",
      "Step0 : loss = 1.187473258801869\n",
      "Step1 : loss = 0.9502080721514565\n",
      "Step2 : loss = 0.9276961556502751\n",
      "Step3 : loss = 0.8812689057418278\n",
      "Step4 : loss = 0.845232122710773\n",
      "Step5 : loss = 0.8197330960205623\n",
      "Step6 : loss = 0.7968180860791888\n",
      "Step7 : loss = 0.7810170820781163\n",
      "Step8 : loss = 0.7673982275383813\n",
      "Step9 : loss = 0.7538379962955203\n",
      "Data stream Batch- 6 : loss = 5.2247538566589355\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1525921803598532\n",
      "Step 1 : loss = 0.14702967278907983\n",
      "Step 2 : loss = 0.1431261040966392\n",
      "Step 3 : loss = 0.139384631194167\n",
      "Step 4 : loss = 0.13584072490039523\n",
      "Step 5 : loss = 0.1322191432703181\n",
      "Step 6 : loss = 0.1296821454935742\n",
      "Step 7 : loss = 0.12615161584839002\n",
      "Step 8 : loss = 0.12377439163352359\n",
      "Step 9 : loss = 0.12119842602898125\n",
      "Update Procedure\n",
      "Step0 : loss = 1.345352977514267\n",
      "Step1 : loss = 1.2008624710142612\n",
      "Step2 : loss = 1.1774260997772217\n",
      "Step3 : loss = 1.1291344836354256\n",
      "Step4 : loss = 1.0954136066138744\n",
      "Step5 : loss = 1.066613346338272\n",
      "Step6 : loss = 1.039498696103692\n",
      "Step7 : loss = 1.0166320744901896\n",
      "Step8 : loss = 0.9932379554957151\n",
      "Step9 : loss = 0.975587323307991\n",
      "Data stream Batch- 7 : loss = 3.8064879179000854\n",
      "Task  7\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.10093380889990336\n",
      "Step 1 : loss = 0.09603268066949232\n",
      "Step 2 : loss = 0.09160835768273536\n",
      "Step 3 : loss = 0.08762874451537019\n",
      "Step 4 : loss = 0.0839150404281824\n",
      "Step 5 : loss = 0.08034550657749708\n",
      "Step 6 : loss = 0.0769569531586233\n",
      "Step 7 : loss = 0.07367765424162324\n",
      "Step 8 : loss = 0.07044892803028734\n",
      "Step 9 : loss = 0.06736811799774824\n",
      "Update Procedure\n",
      "Step0 : loss = 10.221674919128418\n",
      "Step1 : loss = 10.045153617858887\n",
      "Step2 : loss = 9.874370574951172\n",
      "Step3 : loss = 9.707515716552734\n",
      "Step4 : loss = 9.540094375610352\n",
      "Step5 : loss = 9.371377944946289\n",
      "Step6 : loss = 9.201030731201172\n",
      "Step7 : loss = 9.029828071594238\n",
      "Step8 : loss = 8.85657024383545\n",
      "Step9 : loss = 8.682318687438965\n",
      "Data stream Batch- 0 : loss = 2.5467050075531006\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.06996566421710164\n",
      "Step 1 : loss = 0.06675037270631269\n",
      "Step 2 : loss = 0.06370087022124803\n",
      "Step 3 : loss = 0.06121494336921717\n",
      "Step 4 : loss = 0.05924342768168676\n",
      "Step 5 : loss = 0.057580005453125326\n",
      "Step 6 : loss = 0.056151069191389576\n",
      "Step 7 : loss = 0.0548208696635973\n",
      "Step 8 : loss = 0.053544988447050364\n",
      "Step 9 : loss = 0.0523165834797066\n",
      "Update Procedure\n",
      "Step0 : loss = 7.6278276443481445\n",
      "Step1 : loss = 7.30728554725647\n",
      "Step2 : loss = 6.983565092086792\n",
      "Step3 : loss = 6.655679941177368\n",
      "Step4 : loss = 6.320790529251099\n",
      "Step5 : loss = 5.976544618606567\n",
      "Step6 : loss = 5.610094785690308\n",
      "Step7 : loss = 5.203570365905762\n",
      "Step8 : loss = 4.770616769790649\n",
      "Step9 : loss = 4.323938488960266\n",
      "Data stream Batch- 1 : loss = 2.876585006713867\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.07523001869555669\n",
      "Step 1 : loss = 0.06965891977693263\n",
      "Step 2 : loss = 0.06456757598132627\n",
      "Step 3 : loss = 0.06020255080576731\n",
      "Step 4 : loss = 0.05651938730917804\n",
      "Step 5 : loss = 0.05350220914874682\n",
      "Step 6 : loss = 0.051440406877873365\n",
      "Step 7 : loss = 0.04997801615213134\n",
      "Step 8 : loss = 0.04878384440346943\n",
      "Step 9 : loss = 0.04771263953441955\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9129857222239175\n",
      "Step1 : loss = 3.346552928288778\n",
      "Step2 : loss = 2.8203152815500894\n",
      "Step3 : loss = 2.3311284383138022\n",
      "Step4 : loss = 1.902845859527588\n",
      "Step5 : loss = 1.600681185722351\n",
      "Step6 : loss = 1.4721049865086873\n",
      "Step7 : loss = 1.4327717224756877\n",
      "Step8 : loss = 1.414012889067332\n",
      "Step9 : loss = 1.407700498898824\n",
      "Data stream Batch- 2 : loss = 3.731712818145752\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.06418138371129853\n",
      "Step 1 : loss = 0.05979821329870049\n",
      "Step 2 : loss = 0.05619868718295378\n",
      "Step 3 : loss = 0.05286393225194171\n",
      "Step 4 : loss = 0.04969389413037077\n",
      "Step 5 : loss = 0.04721482925964434\n",
      "Step 6 : loss = 0.04525628601509224\n",
      "Step 7 : loss = 0.04384269052884602\n",
      "Step 8 : loss = 0.04279634070324518\n",
      "Step 9 : loss = 0.04176024069074929\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4314910769462585\n",
      "Step1 : loss = 1.2974330484867096\n",
      "Step2 : loss = 1.2080391943454742\n",
      "Step3 : loss = 1.1531827449798584\n",
      "Step4 : loss = 1.114699348807335\n",
      "Step5 : loss = 1.0799447298049927\n",
      "Step6 : loss = 1.0422678589820862\n",
      "Step7 : loss = 0.9987611621618271\n",
      "Step8 : loss = 0.9515068382024765\n",
      "Step9 : loss = 0.9018737226724625\n",
      "Data stream Batch- 3 : loss = 3.1628620624542236\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04437238426191748\n",
      "Step 1 : loss = 0.041528276071907906\n",
      "Step 2 : loss = 0.03960375785515159\n",
      "Step 3 : loss = 0.0385548985787666\n",
      "Step 4 : loss = 0.03772334261657022\n",
      "Step 5 : loss = 0.03676447795211192\n",
      "Step 6 : loss = 0.036011412128655336\n",
      "Step 7 : loss = 0.03512220746561227\n",
      "Step 8 : loss = 0.034431423253763416\n",
      "Step 9 : loss = 0.03354735667348733\n",
      "Update Procedure\n",
      "Step0 : loss = 1.0998615741729736\n",
      "Step1 : loss = 0.9757087111473084\n",
      "Step2 : loss = 0.8848309278488159\n",
      "Step3 : loss = 0.8231079339981079\n",
      "Step4 : loss = 0.770304161310196\n",
      "Step5 : loss = 0.7240472316741944\n",
      "Step6 : loss = 0.6789391756057739\n",
      "Step7 : loss = 0.6417282432317734\n",
      "Step8 : loss = 0.6142020285129547\n",
      "Step9 : loss = 0.5894285529851914\n",
      "Data stream Batch- 4 : loss = 3.040033459663391\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04813351703547915\n",
      "Step 1 : loss = 0.04373165222267101\n",
      "Step 2 : loss = 0.03966228335966417\n",
      "Step 3 : loss = 0.036564661895338794\n",
      "Step 4 : loss = 0.03370832365090433\n",
      "Step 5 : loss = 0.031214539021534402\n",
      "Step 6 : loss = 0.029958787304287887\n",
      "Step 7 : loss = 0.0292999218818232\n",
      "Step 8 : loss = 0.028456505608636527\n",
      "Step 9 : loss = 0.027824460495821945\n",
      "Update Procedure\n",
      "Step0 : loss = 1.1862365752458572\n",
      "Step1 : loss = 1.090358426173528\n",
      "Step2 : loss = 0.9215064595143\n",
      "Step3 : loss = 0.8602328151464462\n",
      "Step4 : loss = 0.7902157654364904\n",
      "Step5 : loss = 0.7328719645738602\n",
      "Step6 : loss = 0.7012478932738304\n",
      "Step7 : loss = 0.6793341040611267\n",
      "Step8 : loss = 0.6593980540831884\n",
      "Step9 : loss = 0.6400265966852506\n",
      "Data stream Batch- 5 : loss = 2.009905695915222\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.053538286965603164\n",
      "Step 1 : loss = 0.04864615423075338\n",
      "Step 2 : loss = 0.04401006753306107\n",
      "Step 3 : loss = 0.04006087789497174\n",
      "Step 4 : loss = 0.036989749035439466\n",
      "Step 5 : loss = 0.034603306780022255\n",
      "Step 6 : loss = 0.03266682119161937\n",
      "Step 7 : loss = 0.031090200944809465\n",
      "Step 8 : loss = 0.02978007524490774\n",
      "Step 9 : loss = 0.028348183057302155\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9551828737769809\n",
      "Step1 : loss = 0.8870824788297925\n",
      "Step2 : loss = 0.6566279573099953\n",
      "Step3 : loss = 0.646038538643292\n",
      "Step4 : loss = 0.6165025127785546\n",
      "Step5 : loss = 0.5984766589743751\n",
      "Step6 : loss = 0.5786964126995632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step7 : loss = 0.5630437795604978\n",
      "Step8 : loss = 0.5524161287716457\n",
      "Step9 : loss = 0.5447477889912469\n",
      "Data stream Batch- 6 : loss = 1.747795820236206\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.041566416974109496\n",
      "Step 1 : loss = 0.03802489331636783\n",
      "Step 2 : loss = 0.03541153165730132\n",
      "Step 3 : loss = 0.03380482931858671\n",
      "Step 4 : loss = 0.03237111353322365\n",
      "Step 5 : loss = 0.031083740647746137\n",
      "Step 6 : loss = 0.030216723845194672\n",
      "Step 7 : loss = 0.0291579260103166\n",
      "Step 8 : loss = 0.028578094606042027\n",
      "Step 9 : loss = 0.027742250918011222\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9037444889545441\n",
      "Step1 : loss = 0.7273624315857887\n",
      "Step2 : loss = 0.7230726294219494\n",
      "Step3 : loss = 0.6191621106117964\n",
      "Step4 : loss = 0.6186477225273848\n",
      "Step5 : loss = 0.6208757571876049\n",
      "Step6 : loss = 0.6006441712379456\n",
      "Step7 : loss = 0.5830461494624615\n",
      "Step8 : loss = 0.5739053543657064\n",
      "Step9 : loss = 0.5676456354558468\n",
      "Data stream Batch- 7 : loss = 1.7054160833358765\n",
      "Task  8\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.028063071676951126\n",
      "Step 1 : loss = 0.02785609023310733\n",
      "Step 2 : loss = 0.027723303826766247\n",
      "Step 3 : loss = 0.027676474535546128\n",
      "Step 4 : loss = 0.027460883720057686\n",
      "Step 5 : loss = 0.02751133810629577\n",
      "Step 6 : loss = 0.02722498657055171\n",
      "Step 7 : loss = 0.027335160944029085\n",
      "Step 8 : loss = 0.026988947254766416\n",
      "Step 9 : loss = 0.027160699762717552\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9100563526153564\n",
      "Step1 : loss = 3.756251811981201\n",
      "Step2 : loss = 3.6070544719696045\n",
      "Step3 : loss = 3.4662585258483887\n",
      "Step4 : loss = 3.335995674133301\n",
      "Step5 : loss = 3.2145867347717285\n",
      "Step6 : loss = 3.1085453033447266\n",
      "Step7 : loss = 3.009645938873291\n",
      "Step8 : loss = 2.914055109024048\n",
      "Step9 : loss = 2.824113368988037\n",
      "Data stream Batch- 0 : loss = 5.220904588699341\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.043389125160296006\n",
      "Step 1 : loss = 0.03791145799150934\n",
      "Step 2 : loss = 0.03352244716718319\n",
      "Step 3 : loss = 0.02998636405629421\n",
      "Step 4 : loss = 0.027323281222734863\n",
      "Step 5 : loss = 0.026529534768813486\n",
      "Step 6 : loss = 0.026812077388060893\n",
      "Step 7 : loss = 0.026441268974230072\n",
      "Step 8 : loss = 0.02644221129316936\n",
      "Step 9 : loss = 0.02634110935618061\n",
      "Update Procedure\n",
      "Step0 : loss = 3.4720441102981567\n",
      "Step1 : loss = 3.2842955589294434\n",
      "Step2 : loss = 3.1287269592285156\n",
      "Step3 : loss = 2.9882975816726685\n",
      "Step4 : loss = 2.859919786453247\n",
      "Step5 : loss = 2.735713839530945\n",
      "Step6 : loss = 2.6080636978149414\n",
      "Step7 : loss = 2.479610025882721\n",
      "Step8 : loss = 2.351376950740814\n",
      "Step9 : loss = 2.2285276055336\n",
      "Data stream Batch- 1 : loss = 4.318482160568237\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04441496041634866\n",
      "Step 1 : loss = 0.03968020219308347\n",
      "Step 2 : loss = 0.035788352882697105\n",
      "Step 3 : loss = 0.03265050541875357\n",
      "Step 4 : loss = 0.030056943823867647\n",
      "Step 5 : loss = 0.027680202377751095\n",
      "Step 6 : loss = 0.026226397115318184\n",
      "Step 7 : loss = 0.02583436300891873\n",
      "Step 8 : loss = 0.026286519922499654\n",
      "Step 9 : loss = 0.025660270577561588\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5835962692896524\n",
      "Step1 : loss = 2.3504475355148315\n",
      "Step2 : loss = 2.145809849103292\n",
      "Step3 : loss = 1.9612448612848918\n",
      "Step4 : loss = 1.7983988920847576\n",
      "Step5 : loss = 1.6531126896540325\n",
      "Step6 : loss = 1.5345304012298584\n",
      "Step7 : loss = 1.45172115166982\n",
      "Step8 : loss = 1.3926595052083333\n",
      "Step9 : loss = 1.337695598602295\n",
      "Data stream Batch- 2 : loss = 3.1861411333084106\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04200297352209743\n",
      "Step 1 : loss = 0.03792064123359205\n",
      "Step 2 : loss = 0.03480611486715225\n",
      "Step 3 : loss = 0.03192545568519828\n",
      "Step 4 : loss = 0.029093599644026292\n",
      "Step 5 : loss = 0.02639451481210232\n",
      "Step 6 : loss = 0.024059773982400307\n",
      "Step 7 : loss = 0.023261221336062583\n",
      "Step 8 : loss = 0.0242962535463107\n",
      "Step 9 : loss = 0.023066682639894382\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5147755444049835\n",
      "Step1 : loss = 1.3885148465633392\n",
      "Step2 : loss = 1.2929478585720062\n",
      "Step3 : loss = 1.2120154947042465\n",
      "Step4 : loss = 1.1399706155061722\n",
      "Step5 : loss = 1.0712421536445618\n",
      "Step6 : loss = 1.0046897381544113\n",
      "Step7 : loss = 0.9424527287483215\n",
      "Step8 : loss = 0.8903661966323853\n",
      "Step9 : loss = 0.85748540610075\n",
      "Data stream Batch- 3 : loss = 2.772695541381836\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04087599407863056\n",
      "Step 1 : loss = 0.034365005483862156\n",
      "Step 2 : loss = 0.031117072667507642\n",
      "Step 3 : loss = 0.028343217843711525\n",
      "Step 4 : loss = 0.025647974691246144\n",
      "Step 5 : loss = 0.02332227559436779\n",
      "Step 6 : loss = 0.02296249980779483\n",
      "Step 7 : loss = 0.02306645174967451\n",
      "Step 8 : loss = 0.022639870843450455\n",
      "Step 9 : loss = 0.022730817746723902\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4215417861938477\n",
      "Step1 : loss = 1.2978019952774047\n",
      "Step2 : loss = 1.2597885012626648\n",
      "Step3 : loss = 1.240857148170471\n",
      "Step4 : loss = 1.2178416013717652\n",
      "Step5 : loss = 1.1907284736633301\n",
      "Step6 : loss = 1.1705495476722718\n",
      "Step7 : loss = 1.1519449293613433\n",
      "Step8 : loss = 1.1359066188335418\n",
      "Step9 : loss = 1.121182668209076\n",
      "Data stream Batch- 4 : loss = 3.052082061767578\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.03339817654983286\n",
      "Step 1 : loss = 0.027678180856385112\n",
      "Step 2 : loss = 0.02388695540973395\n",
      "Step 3 : loss = 0.022855409323362195\n",
      "Step 4 : loss = 0.023939129059880167\n",
      "Step 5 : loss = 0.022609554561076342\n",
      "Step 6 : loss = 0.023570213490503696\n",
      "Step 7 : loss = 0.022409573388563177\n",
      "Step 8 : loss = 0.023210147558858862\n",
      "Step 9 : loss = 0.022252110673071094\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4076035916805267\n",
      "Step1 : loss = 1.214347059528033\n",
      "Step2 : loss = 1.087491199374199\n",
      "Step3 : loss = 1.0327028781175613\n",
      "Step4 : loss = 1.0234981675942738\n",
      "Step5 : loss = 1.0169148991505306\n",
      "Step6 : loss = 0.9961646248896917\n",
      "Step7 : loss = 0.9793125440677007\n",
      "Step8 : loss = 0.974607989192009\n",
      "Step9 : loss = 0.9630219986041387\n",
      "Data stream Batch- 5 : loss = 3.114413261413574\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04659596074337142\n",
      "Step 1 : loss = 0.03850540021551269\n",
      "Step 2 : loss = 0.03184620180271163\n",
      "Step 3 : loss = 0.026747647919744835\n",
      "Step 4 : loss = 0.023640487187943437\n",
      "Step 5 : loss = 0.022061721439899873\n",
      "Step 6 : loss = 0.02342577466074975\n",
      "Step 7 : loss = 0.02220481157754808\n",
      "Step 8 : loss = 0.023079706830598908\n",
      "Step 9 : loss = 0.022101723039149847\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6364694280283791\n",
      "Step1 : loss = 1.4349602460861206\n",
      "Step2 : loss = 1.3650723057133811\n",
      "Step3 : loss = 1.350565948656627\n",
      "Step4 : loss = 1.3122251204081945\n",
      "Step5 : loss = 1.2931694218090601\n",
      "Step6 : loss = 1.2757808523518699\n",
      "Step7 : loss = 1.2581215458256858\n",
      "Step8 : loss = 1.2403817517416817\n",
      "Step9 : loss = 1.2280987245695931\n",
      "Data stream Batch- 6 : loss = 3.0217984914779663\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.039476213336944725\n",
      "Step 1 : loss = 0.03386071884106495\n",
      "Step 2 : loss = 0.028508731258278106\n",
      "Step 3 : loss = 0.025225395685154826\n",
      "Step 4 : loss = 0.02308419623288212\n",
      "Step 5 : loss = 0.022318257750546754\n",
      "Step 6 : loss = 0.022745663868120228\n",
      "Step 7 : loss = 0.022083224093725963\n",
      "Step 8 : loss = 0.022498899409851437\n",
      "Step 9 : loss = 0.02201620409139271\n",
      "Update Procedure\n",
      "Step0 : loss = 1.9364092461764812\n",
      "Step1 : loss = 1.7664731331169605\n",
      "Step2 : loss = 1.6915904730558395\n",
      "Step3 : loss = 1.6580480188131332\n",
      "Step4 : loss = 1.6309759467840195\n",
      "Step5 : loss = 1.6085385978221893\n",
      "Step6 : loss = 1.5828231684863567\n",
      "Step7 : loss = 1.5674539431929588\n",
      "Step8 : loss = 1.545961294323206\n",
      "Step9 : loss = 1.5286574624478817\n",
      "Data stream Batch- 7 : loss = 3.0097347497940063\n",
      "Task  9\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1137040229622239\n",
      "Step 1 : loss = 0.11056045289481423\n",
      "Step 2 : loss = 0.10788292973219478\n",
      "Step 3 : loss = 0.1053395082523017\n",
      "Step 4 : loss = 0.10288022981580275\n",
      "Step 5 : loss = 0.1004634569901168\n",
      "Step 6 : loss = 0.09816978359017205\n",
      "Step 7 : loss = 0.0959032020735331\n",
      "Step 8 : loss = 0.09383717977917265\n",
      "Step 9 : loss = 0.0916986061739766\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9056009650230408\n",
      "Step1 : loss = 0.8166060447692871\n",
      "Step2 : loss = 0.7549296021461487\n",
      "Step3 : loss = 0.7024840712547302\n",
      "Step4 : loss = 0.661454975605011\n",
      "Step5 : loss = 0.6314485669136047\n",
      "Step6 : loss = 0.6314741969108582\n",
      "Step7 : loss = 0.6302666664123535\n",
      "Step8 : loss = 0.6236233711242676\n",
      "Step9 : loss = 0.6126229763031006\n",
      "Data stream Batch- 0 : loss = 3.256013035774231\n",
      "Meta Update\n",
      "Training is starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 0.0964895581769994\n",
      "Step 1 : loss = 0.09375901773012565\n",
      "Step 2 : loss = 0.09143692619915586\n",
      "Step 3 : loss = 0.08957757820609596\n",
      "Step 4 : loss = 0.08793661905298157\n",
      "Step 5 : loss = 0.08635371873477096\n",
      "Step 6 : loss = 0.08472087145794063\n",
      "Step 7 : loss = 0.08314231057093593\n",
      "Step 8 : loss = 0.0817798382211549\n",
      "Step 9 : loss = 0.08050318013477585\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9691202640533447\n",
      "Step1 : loss = 0.8581324517726898\n",
      "Step2 : loss = 0.7791152596473694\n",
      "Step3 : loss = 0.735147625207901\n",
      "Step4 : loss = 0.7082261443138123\n",
      "Step5 : loss = 0.6869545876979828\n",
      "Step6 : loss = 0.6626079976558685\n",
      "Step7 : loss = 0.6356767416000366\n",
      "Step8 : loss = 0.6146220862865448\n",
      "Step9 : loss = 0.6015243232250214\n",
      "Data stream Batch- 1 : loss = 3.1838066577911377\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.09422959528962155\n",
      "Step 1 : loss = 0.09021521653284964\n",
      "Step 2 : loss = 0.08679113936691248\n",
      "Step 3 : loss = 0.0843754602375802\n",
      "Step 4 : loss = 0.08273375389011749\n",
      "Step 5 : loss = 0.08123364582262406\n",
      "Step 6 : loss = 0.07975819401138526\n",
      "Step 7 : loss = 0.07841141616492983\n",
      "Step 8 : loss = 0.07717615470449617\n",
      "Step 9 : loss = 0.07591263634825388\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9111058910687765\n",
      "Step1 : loss = 0.7152787446975708\n",
      "Step2 : loss = 0.6135268211364746\n",
      "Step3 : loss = 0.5779406825701395\n",
      "Step4 : loss = 0.554277241230011\n",
      "Step5 : loss = 0.5358710388342539\n",
      "Step6 : loss = 0.5267696678638458\n",
      "Step7 : loss = 0.5156010091304779\n",
      "Step8 : loss = 0.498289351662\n",
      "Step9 : loss = 0.4814422130584717\n",
      "Data stream Batch- 2 : loss = 3.1729735136032104\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.08895940568629152\n",
      "Step 1 : loss = 0.08505346440074932\n",
      "Step 2 : loss = 0.08241141767409274\n",
      "Step 3 : loss = 0.08030563278092004\n",
      "Step 4 : loss = 0.0786248233627177\n",
      "Step 5 : loss = 0.07723649415367097\n",
      "Step 6 : loss = 0.07584211596504005\n",
      "Step 7 : loss = 0.07468756819834395\n",
      "Step 8 : loss = 0.07336916293369035\n",
      "Step 9 : loss = 0.0721726711800982\n",
      "Update Procedure\n",
      "Step0 : loss = 0.8701737076044083\n",
      "Step1 : loss = 0.646230012178421\n",
      "Step2 : loss = 0.5975457578897476\n",
      "Step3 : loss = 0.6086846999824047\n",
      "Step4 : loss = 0.601049292832613\n",
      "Step5 : loss = 0.5845194235444069\n",
      "Step6 : loss = 0.5657507106661797\n",
      "Step7 : loss = 0.5502070672810078\n",
      "Step8 : loss = 0.540874395519495\n",
      "Step9 : loss = 0.5278412029147148\n",
      "Data stream Batch- 3 : loss = 3.12140429019928\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.0849098052070032\n",
      "Step 1 : loss = 0.08042948220465092\n",
      "Step 2 : loss = 0.07766428864727955\n",
      "Step 3 : loss = 0.07581468297786303\n",
      "Step 4 : loss = 0.07425519329911967\n",
      "Step 5 : loss = 0.07278644246076674\n",
      "Step 6 : loss = 0.07152662395604521\n",
      "Step 7 : loss = 0.07026032215960987\n",
      "Step 8 : loss = 0.06923867318987784\n",
      "Step 9 : loss = 0.06821989626668475\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3461331248283386\n",
      "Step1 : loss = 1.0963899433612823\n",
      "Step2 : loss = 1.022358238697052\n",
      "Step3 : loss = 1.0222026407718658\n",
      "Step4 : loss = 1.0048518121242522\n",
      "Step5 : loss = 0.9797664821147919\n",
      "Step6 : loss = 0.9627573609352111\n",
      "Step7 : loss = 0.9458457410335541\n",
      "Step8 : loss = 0.9304482221603394\n",
      "Step9 : loss = 0.9199847936630249\n",
      "Data stream Batch- 4 : loss = 3.3212006092071533\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.08068325112868273\n",
      "Step 1 : loss = 0.07684425714817128\n",
      "Step 2 : loss = 0.07422212910286548\n",
      "Step 3 : loss = 0.07237161151161531\n",
      "Step 4 : loss = 0.0710668223283688\n",
      "Step 5 : loss = 0.06976385830341783\n",
      "Step 6 : loss = 0.06870166874201901\n",
      "Step 7 : loss = 0.06794900902513208\n",
      "Step 8 : loss = 0.06702987987584358\n",
      "Step 9 : loss = 0.06639235947737361\n",
      "Update Procedure\n",
      "Step0 : loss = 1.578871876001358\n",
      "Step1 : loss = 1.2951505531867344\n",
      "Step2 : loss = 1.1636770019928615\n",
      "Step3 : loss = 1.0498586545387905\n",
      "Step4 : loss = 0.961737796664238\n",
      "Step5 : loss = 0.8664955049753189\n",
      "Step6 : loss = 0.85311159491539\n",
      "Step7 : loss = 0.850327655673027\n",
      "Step8 : loss = 0.8133660107851028\n",
      "Step9 : loss = 0.8103196322917938\n",
      "Data stream Batch- 5 : loss = 3.175045132637024\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.08113738331346401\n",
      "Step 1 : loss = 0.07778800970602213\n",
      "Step 2 : loss = 0.07465762270130935\n",
      "Step 3 : loss = 0.07178489751067463\n",
      "Step 4 : loss = 0.06972425146860588\n",
      "Step 5 : loss = 0.0685723983799592\n",
      "Step 6 : loss = 0.06769174016403262\n",
      "Step 7 : loss = 0.06667706441230853\n",
      "Step 8 : loss = 0.06626180695925349\n",
      "Step 9 : loss = 0.06527582732233919\n",
      "Update Procedure\n",
      "Step0 : loss = 1.384661683014461\n",
      "Step1 : loss = 1.1826261069093431\n",
      "Step2 : loss = 1.118601884160723\n",
      "Step3 : loss = 1.1065053258623396\n",
      "Step4 : loss = 1.0631162311349596\n",
      "Step5 : loss = 1.0523961654731206\n",
      "Step6 : loss = 1.0316274634429388\n",
      "Step7 : loss = 1.0192599977765764\n",
      "Step8 : loss = 1.014012268611363\n",
      "Step9 : loss = 0.9996522750173297\n",
      "Data stream Batch- 6 : loss = 3.0322412252426147\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.08367082398805224\n",
      "Step 1 : loss = 0.07989186013259966\n",
      "Step 2 : loss = 0.07629640154850956\n",
      "Step 3 : loss = 0.07310321872843953\n",
      "Step 4 : loss = 0.07143668688774008\n",
      "Step 5 : loss = 0.06919623510649602\n",
      "Step 6 : loss = 0.06821688552376053\n",
      "Step 7 : loss = 0.06641794536611714\n",
      "Step 8 : loss = 0.06552892744922725\n",
      "Step 9 : loss = 0.06469806253558857\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4152391105890274\n",
      "Step1 : loss = 1.279248796403408\n",
      "Step2 : loss = 1.2460699118673801\n",
      "Step3 : loss = 1.23315853998065\n",
      "Step4 : loss = 1.2004435509443283\n",
      "Step5 : loss = 1.1984399817883968\n",
      "Step6 : loss = 1.1938795372843742\n",
      "Step7 : loss = 1.1794197224080563\n",
      "Step8 : loss = 1.1672857478260994\n",
      "Step9 : loss = 1.160980835556984\n",
      "Data stream Batch- 7 : loss = 3.089043140411377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml1 = []\n",
    "total = []\n",
    "all_eval_loss1 = []\n",
    "all_train_loss1 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval1 = []\n",
    "ftml_time1 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        ftml1, loss = train_maml(ftml1, meta_step, dtrainx, dtraint, dvalx, dvalt)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml1, loss = update_procedure(ftml1,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml1, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time1.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval1.append(eval_loss)\n",
    "    all_train_loss1.append(train_loss)\n",
    "    all_eval_loss1.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval1)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(xtask_buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task  0\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.652232646942139\n",
      "Step 1 : loss = 6.635053634643555\n",
      "Step 2 : loss = 6.619361400604248\n",
      "Step 3 : loss = 6.604067802429199\n",
      "Step 4 : loss = 6.588775157928467\n",
      "Step 5 : loss = 6.572393417358398\n",
      "Step 6 : loss = 6.553576469421387\n",
      "Step 7 : loss = 6.532968521118164\n",
      "Step 8 : loss = 6.5107245445251465\n",
      "Step 9 : loss = 6.487514495849609\n",
      "Update Procedure\n",
      "Step0 : loss = 6.465233325958252\n",
      "Step1 : loss = 6.440613269805908\n",
      "Step2 : loss = 6.415635585784912\n",
      "Step3 : loss = 6.390298366546631\n",
      "Step4 : loss = 6.364742279052734\n",
      "Step5 : loss = 6.3387837409973145\n",
      "Step6 : loss = 6.312447547912598\n",
      "Step7 : loss = 6.285765171051025\n",
      "Step8 : loss = 6.2584099769592285\n",
      "Step9 : loss = 6.230309009552002\n",
      "Data stream Batch- 0 : loss = 4.7089598178863525\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.677560806274414\n",
      "Step 1 : loss = 6.649087429046631\n",
      "Step 2 : loss = 6.620116949081421\n",
      "Step 3 : loss = 6.590567111968994\n",
      "Step 4 : loss = 6.560368061065674\n",
      "Step 5 : loss = 6.529611349105835\n",
      "Step 6 : loss = 6.498349189758301\n",
      "Step 7 : loss = 6.4665703773498535\n",
      "Step 8 : loss = 6.4341418743133545\n",
      "Step 9 : loss = 6.401021718978882\n",
      "Update Procedure\n",
      "Step0 : loss = 6.356923580169678\n",
      "Step1 : loss = 6.288822889328003\n",
      "Step2 : loss = 6.21834921836853\n",
      "Step3 : loss = 6.144758462905884\n",
      "Step4 : loss = 6.06756854057312\n",
      "Step5 : loss = 5.986406326293945\n",
      "Step6 : loss = 5.900831699371338\n",
      "Step7 : loss = 5.810654401779175\n",
      "Step8 : loss = 5.7158379554748535\n",
      "Step9 : loss = 5.6161510944366455\n",
      "Data stream Batch- 1 : loss = 4.450187921524048\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.633552630742391\n",
      "Step 1 : loss = 6.60454781850179\n",
      "Step 2 : loss = 6.57503080368042\n",
      "Step 3 : loss = 6.545136372248332\n",
      "Step 4 : loss = 6.515038013458252\n",
      "Step 5 : loss = 6.484714428583781\n",
      "Step 6 : loss = 6.454310258229573\n",
      "Step 7 : loss = 6.4236683050791425\n",
      "Step 8 : loss = 6.392617225646973\n",
      "Step 9 : loss = 6.3609646161397295\n",
      "Update Procedure\n",
      "Step0 : loss = 7.977070172627767\n",
      "Step1 : loss = 7.838293711344401\n",
      "Step2 : loss = 7.70150089263916\n",
      "Step3 : loss = 7.564437548319499\n",
      "Step4 : loss = 7.428595066070557\n",
      "Step5 : loss = 7.287490288416545\n",
      "Step6 : loss = 7.138605117797852\n",
      "Step7 : loss = 6.985844135284424\n",
      "Step8 : loss = 6.833266099294026\n",
      "Step9 : loss = 6.67754332224528\n",
      "Data stream Batch- 2 : loss = 3.849817633628845\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 2.777953614791234\n",
      "Step 1 : loss = 2.7579557696978254\n",
      "Step 2 : loss = 2.738554944594701\n",
      "Step 3 : loss = 2.7196761667728424\n",
      "Step 4 : loss = 2.701578636964162\n",
      "Step 5 : loss = 2.6837906936804456\n",
      "Step 6 : loss = 2.6666467388470965\n",
      "Step 7 : loss = 2.650843759377797\n",
      "Step 8 : loss = 2.6346045434474945\n",
      "Step 9 : loss = 2.6183877487977343\n",
      "Update Procedure\n",
      "Step0 : loss = 5.9553327560424805\n",
      "Step1 : loss = 5.81277459859848\n",
      "Step2 : loss = 5.688430964946747\n",
      "Step3 : loss = 5.566096007823944\n",
      "Step4 : loss = 5.443434834480286\n",
      "Step5 : loss = 5.323399305343628\n",
      "Step6 : loss = 5.20323371887207\n",
      "Step7 : loss = 5.079855442047119\n",
      "Step8 : loss = 4.951496571302414\n",
      "Step9 : loss = 4.817668259143829\n",
      "Data stream Batch- 3 : loss = 3.0757265090942383\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 2.450887629389763\n",
      "Step 1 : loss = 2.422102338075638\n",
      "Step 2 : loss = 2.3948715150356295\n",
      "Step 3 : loss = 2.3687063246965407\n",
      "Step 4 : loss = 2.343469128012657\n",
      "Step 5 : loss = 2.318985195954641\n",
      "Step 6 : loss = 2.295451225837072\n",
      "Step 7 : loss = 2.2724841793378197\n",
      "Step 8 : loss = 2.249867788950602\n",
      "Step 9 : loss = 2.2273259023825327\n",
      "Update Procedure\n",
      "Step0 : loss = 5.596366262435913\n",
      "Step1 : loss = 5.418223738670349\n",
      "Step2 : loss = 5.277289509773254\n",
      "Step3 : loss = 5.142148208618164\n",
      "Step4 : loss = 5.013060212135315\n",
      "Step5 : loss = 4.888885068893432\n",
      "Step6 : loss = 4.768507552146912\n",
      "Step7 : loss = 4.656547951698303\n",
      "Step8 : loss = 4.551565790176392\n",
      "Step9 : loss = 4.452313947677612\n",
      "Data stream Batch- 4 : loss = 2.5691049098968506\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.7526954677369861\n",
      "Step 1 : loss = 1.7462821079625022\n",
      "Step 2 : loss = 1.7406686660316255\n",
      "Step 3 : loss = 1.735505176915063\n",
      "Step 4 : loss = 1.7308366255627738\n",
      "Step 5 : loss = 1.726643740468555\n",
      "Step 6 : loss = 1.7229056055347123\n",
      "Step 7 : loss = 1.719545541372564\n",
      "Step 8 : loss = 1.7164011451933119\n",
      "Step 9 : loss = 1.7133910703990194\n",
      "Update Procedure\n",
      "Step0 : loss = 5.014322102069855\n",
      "Step1 : loss = 4.881844103336334\n",
      "Step2 : loss = 4.777312397956848\n",
      "Step3 : loss = 4.680848101774852\n",
      "Step4 : loss = 4.58623065551122\n",
      "Step5 : loss = 4.495803614457448\n",
      "Step6 : loss = 4.409434576829274\n",
      "Step7 : loss = 4.32543408870697\n",
      "Step8 : loss = 4.244054605563481\n",
      "Step9 : loss = 4.168025761842728\n",
      "Data stream Batch- 5 : loss = 2.215485095977783\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.0261124500088274\n",
      "Step 1 : loss = 1.0197930837789226\n",
      "Step 2 : loss = 1.0136133665603304\n",
      "Step 3 : loss = 1.0075435086966507\n",
      "Step 4 : loss = 1.001582994536748\n",
      "Step 5 : loss = 0.9957053649520117\n",
      "Step 6 : loss = 0.9899610306298923\n",
      "Step 7 : loss = 0.9845085495521152\n",
      "Step 8 : loss = 0.9793809228591502\n",
      "Step 9 : loss = 0.9745408161410263\n",
      "Update Procedure\n",
      "Step0 : loss = 4.295636687959943\n",
      "Step1 : loss = 4.155122935771942\n",
      "Step2 : loss = 4.069999575614929\n",
      "Step3 : loss = 3.9905839477266585\n",
      "Step4 : loss = 3.9133525575910295\n",
      "Step5 : loss = 3.835015526839665\n",
      "Step6 : loss = 3.7557598182133267\n",
      "Step7 : loss = 3.680406468255179\n",
      "Step8 : loss = 3.6201238802501132\n",
      "Step9 : loss = 3.5754067642348155\n",
      "Data stream Batch- 6 : loss = 2.1930432319641113\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5197316033381318\n",
      "Step 1 : loss = 0.5151296049696468\n",
      "Step 2 : loss = 0.5106357041657681\n",
      "Step 3 : loss = 0.5062525933327537\n",
      "Step 4 : loss = 0.5019767145227109\n",
      "Step 5 : loss = 0.49792130578545823\n",
      "Step 6 : loss = 0.49396320039642944\n",
      "Step 7 : loss = 0.4900722781299717\n",
      "Step 8 : loss = 0.48623750077353584\n",
      "Step 9 : loss = 0.4824409564868325\n",
      "Update Procedure\n",
      "Step0 : loss = 3.6269435435533524\n",
      "Step1 : loss = 3.4957512244582176\n",
      "Step2 : loss = 3.4558783173561096\n",
      "Step3 : loss = 3.429795801639557\n",
      "Step4 : loss = 3.4055270850658417\n",
      "Step5 : loss = 3.384010873734951\n",
      "Step6 : loss = 3.3650945127010345\n",
      "Step7 : loss = 3.3452459052205086\n",
      "Step8 : loss = 3.327837847173214\n",
      "Step9 : loss = 3.310807555913925\n",
      "Data stream Batch- 7 : loss = 2.0917317867279053\n",
      "Task  1\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.7848389744758606\n",
      "Step 1 : loss = 1.775933523972829\n",
      "Step 2 : loss = 1.766222059726715\n",
      "Step 3 : loss = 1.7566062410672505\n",
      "Step 4 : loss = 1.7473117510477703\n",
      "Step 5 : loss = 1.7385160326957703\n",
      "Step 6 : loss = 1.7295153538386028\n",
      "Step 7 : loss = 1.7205997705459595\n",
      "Step 8 : loss = 1.7115323742230732\n",
      "Step 9 : loss = 1.7022537589073181\n",
      "Update Procedure\n",
      "Step0 : loss = 2.900160312652588\n",
      "Step1 : loss = 2.8487069606781006\n",
      "Step2 : loss = 2.798039436340332\n",
      "Step3 : loss = 2.7491300106048584\n",
      "Step4 : loss = 2.701387643814087\n",
      "Step5 : loss = 2.6557180881500244\n",
      "Step6 : loss = 2.612689256668091\n",
      "Step7 : loss = 2.5712735652923584\n",
      "Step8 : loss = 2.5304479598999023\n",
      "Step9 : loss = 2.4896106719970703\n",
      "Data stream Batch- 0 : loss = 12.880237102508545\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.6683090130488079\n",
      "Step 1 : loss = 1.6592070659001668\n",
      "Step 2 : loss = 1.6506258447964985\n",
      "Step 3 : loss = 1.6426793336868286\n",
      "Step 4 : loss = 1.6348799069722493\n",
      "Step 5 : loss = 1.6274634798367817\n",
      "Step 6 : loss = 1.6200107137362163\n",
      "Step 7 : loss = 1.6122945547103882\n",
      "Step 8 : loss = 1.604474623998006\n",
      "Step 9 : loss = 1.596124251683553\n",
      "Update Procedure\n",
      "Step0 : loss = 3.6237579584121704\n",
      "Step1 : loss = 3.5396300554275513\n",
      "Step2 : loss = 3.471769332885742\n",
      "Step3 : loss = 3.411046266555786\n",
      "Step4 : loss = 3.3555238246917725\n",
      "Step5 : loss = 3.3040857315063477\n",
      "Step6 : loss = 3.2572821378707886\n",
      "Step7 : loss = 3.214040517807007\n",
      "Step8 : loss = 3.1734498739242554\n",
      "Step9 : loss = 3.135580062866211\n",
      "Data stream Batch- 1 : loss = 12.818163871765137\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.5799558957417805\n",
      "Step 1 : loss = 1.5697214603424072\n",
      "Step 2 : loss = 1.559324343999227\n",
      "Step 3 : loss = 1.549446483453115\n",
      "Step 4 : loss = 1.5396793882052102\n",
      "Step 5 : loss = 1.5301502148310342\n",
      "Step 6 : loss = 1.5204876263936362\n",
      "Step 7 : loss = 1.5103033383687339\n",
      "Step 8 : loss = 1.5002359946568808\n",
      "Step 9 : loss = 1.4898733894030252\n",
      "Update Procedure\n",
      "Step0 : loss = 3.6099168062210083\n",
      "Step1 : loss = 3.5036552349726358\n",
      "Step2 : loss = 3.4167539278666177\n",
      "Step3 : loss = 3.3378357887268066\n",
      "Step4 : loss = 3.2636934916178384\n",
      "Step5 : loss = 3.195202390352885\n",
      "Step6 : loss = 3.1339669624964395\n",
      "Step7 : loss = 3.0797579685846963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step8 : loss = 3.0324775775273642\n",
      "Step9 : loss = 2.9888864358266196\n",
      "Data stream Batch- 2 : loss = 12.763559818267822\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.512903869152069\n",
      "Step 1 : loss = 1.500520865122477\n",
      "Step 2 : loss = 1.4879589279492698\n",
      "Step 3 : loss = 1.4749947686990104\n",
      "Step 4 : loss = 1.462694058815638\n",
      "Step 5 : loss = 1.449986924727758\n",
      "Step 6 : loss = 1.4371740221977234\n",
      "Step 7 : loss = 1.4243022600809732\n",
      "Step 8 : loss = 1.4120129545529685\n",
      "Step 9 : loss = 1.4000807205835977\n",
      "Update Procedure\n",
      "Step0 : loss = 2.7272541522979736\n",
      "Step1 : loss = 2.6285266280174255\n",
      "Step2 : loss = 2.555410087108612\n",
      "Step3 : loss = 2.493780493736267\n",
      "Step4 : loss = 2.43995064496994\n",
      "Step5 : loss = 2.392886310815811\n",
      "Step6 : loss = 2.349571079015732\n",
      "Step7 : loss = 2.3069184720516205\n",
      "Step8 : loss = 2.264019012451172\n",
      "Step9 : loss = 2.220149874687195\n",
      "Data stream Batch- 3 : loss = 12.626328945159912\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.372816115617752\n",
      "Step 1 : loss = 1.3609284857908883\n",
      "Step 2 : loss = 1.3499630888303122\n",
      "Step 3 : loss = 1.3391792376836142\n",
      "Step 4 : loss = 1.328450302282969\n",
      "Step 5 : loss = 1.3172690769036612\n",
      "Step 6 : loss = 1.3061313331127167\n",
      "Step 7 : loss = 1.2947645286719003\n",
      "Step 8 : loss = 1.283119191726049\n",
      "Step 9 : loss = 1.271400511264801\n",
      "Update Procedure\n",
      "Step0 : loss = 2.8465899229049683\n",
      "Step1 : loss = 2.700938034057617\n",
      "Step2 : loss = 2.5979806900024416\n",
      "Step3 : loss = 2.5158741950988768\n",
      "Step4 : loss = 2.4466118574142457\n",
      "Step5 : loss = 2.3849504709243776\n",
      "Step6 : loss = 2.3278665781021117\n",
      "Step7 : loss = 2.273417901992798\n",
      "Step8 : loss = 2.219988965988159\n",
      "Step9 : loss = 2.1675618648529054\n",
      "Data stream Batch- 4 : loss = 12.543281555175781\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.290901949008306\n",
      "Step 1 : loss = 1.2776986857255301\n",
      "Step 2 : loss = 1.2642943263053894\n",
      "Step 3 : loss = 1.2507810493310294\n",
      "Step 4 : loss = 1.2370058596134186\n",
      "Step 5 : loss = 1.2230739990870156\n",
      "Step 6 : loss = 1.2091635962327323\n",
      "Step 7 : loss = 1.1951707104841867\n",
      "Step 8 : loss = 1.1810530424118042\n",
      "Step 9 : loss = 1.1673184533913932\n",
      "Update Procedure\n",
      "Step0 : loss = 4.350624879201253\n",
      "Step1 : loss = 4.196061134338379\n",
      "Step2 : loss = 4.130705038706462\n",
      "Step3 : loss = 4.091171562671661\n",
      "Step4 : loss = 4.053234299023946\n",
      "Step5 : loss = 4.011246502399445\n",
      "Step6 : loss = 3.968335211277008\n",
      "Step7 : loss = 3.9305507938067117\n",
      "Step8 : loss = 3.896803935368856\n",
      "Step9 : loss = 3.8642956217130027\n",
      "Data stream Batch- 5 : loss = 12.350977420806885\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.1935792863368988\n",
      "Step 1 : loss = 1.1786379516124725\n",
      "Step 2 : loss = 1.1638419032096863\n",
      "Step 3 : loss = 1.1491619249184928\n",
      "Step 4 : loss = 1.134626398483912\n",
      "Step 5 : loss = 1.1207597255706787\n",
      "Step 6 : loss = 1.1072478890419006\n",
      "Step 7 : loss = 1.094263732433319\n",
      "Step 8 : loss = 1.0832572281360626\n",
      "Step 9 : loss = 1.073201229174932\n",
      "Update Procedure\n",
      "Step0 : loss = 5.314809679985046\n",
      "Step1 : loss = 5.148475800241743\n",
      "Step2 : loss = 5.10220422063555\n",
      "Step3 : loss = 5.065163680485317\n",
      "Step4 : loss = 5.020433289664132\n",
      "Step5 : loss = 4.975071770804269\n",
      "Step6 : loss = 4.931709681238447\n",
      "Step7 : loss = 4.887100866862705\n",
      "Step8 : loss = 4.842283470290048\n",
      "Step9 : loss = 4.797437684876578\n",
      "Data stream Batch- 6 : loss = 11.769232273101807\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.0530481239159903\n",
      "Step 1 : loss = 1.0389734307924905\n",
      "Step 2 : loss = 1.0251799623171487\n",
      "Step 3 : loss = 1.011497656504313\n",
      "Step 4 : loss = 0.9981888631979624\n",
      "Step 5 : loss = 0.9857924580574036\n",
      "Step 6 : loss = 0.9747573335965475\n",
      "Step 7 : loss = 0.9647777527570724\n",
      "Step 8 : loss = 0.955976997812589\n",
      "Step 9 : loss = 0.9472153733174006\n",
      "Update Procedure\n",
      "Step0 : loss = 5.765324652194977\n",
      "Step1 : loss = 5.618119776248932\n",
      "Step2 : loss = 5.55620077252388\n",
      "Step3 : loss = 5.485220357775688\n",
      "Step4 : loss = 5.411847218871117\n",
      "Step5 : loss = 5.3354367688298225\n",
      "Step6 : loss = 5.254758641123772\n",
      "Step7 : loss = 5.17060799151659\n",
      "Step8 : loss = 5.081087052822113\n",
      "Step9 : loss = 4.985697530210018\n",
      "Data stream Batch- 7 : loss = 10.3606595993042\n",
      "Task  2\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.5659054987812562\n",
      "Step 1 : loss = 1.5588109684102829\n",
      "Step 2 : loss = 1.551943625086948\n",
      "Step 3 : loss = 1.5450966173989906\n",
      "Step 4 : loss = 1.5385209497552188\n",
      "Step 5 : loss = 1.5322392809441283\n",
      "Step 6 : loss = 1.526220504883381\n",
      "Step 7 : loss = 1.520548670511279\n",
      "Step 8 : loss = 1.5148449551166288\n",
      "Step 9 : loss = 1.5091169390295234\n",
      "Update Procedure\n",
      "Step0 : loss = 4.492917537689209\n",
      "Step1 : loss = 4.362217903137207\n",
      "Step2 : loss = 4.238276481628418\n",
      "Step3 : loss = 4.1211934089660645\n",
      "Step4 : loss = 4.00694465637207\n",
      "Step5 : loss = 3.893970251083374\n",
      "Step6 : loss = 3.7819485664367676\n",
      "Step7 : loss = 3.670666456222534\n",
      "Step8 : loss = 3.56052827835083\n",
      "Step9 : loss = 3.454416513442993\n",
      "Data stream Batch- 0 : loss = 3.293476104736328\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.5024538935768226\n",
      "Step 1 : loss = 1.496702170717929\n",
      "Step 2 : loss = 1.4908925827563047\n",
      "Step 3 : loss = 1.485051969462444\n",
      "Step 4 : loss = 1.4791681853876937\n",
      "Step 5 : loss = 1.4730975119130951\n",
      "Step 6 : loss = 1.4670080606515208\n",
      "Step 7 : loss = 1.4608197472723468\n",
      "Step 8 : loss = 1.454556488567993\n",
      "Step 9 : loss = 1.4482634319465548\n",
      "Update Procedure\n",
      "Step0 : loss = 7.156572103500366\n",
      "Step1 : loss = 6.9933165311813354\n",
      "Step2 : loss = 6.858830690383911\n",
      "Step3 : loss = 6.7321600914001465\n",
      "Step4 : loss = 6.609039068222046\n",
      "Step5 : loss = 6.489289879798889\n",
      "Step6 : loss = 6.37156617641449\n",
      "Step7 : loss = 6.257915139198303\n",
      "Step8 : loss = 6.147284626960754\n",
      "Step9 : loss = 6.039398670196533\n",
      "Data stream Batch- 1 : loss = 3.3274976015090942\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.418335310186422\n",
      "Step 1 : loss = 1.4114940976398804\n",
      "Step 2 : loss = 1.404512642513192\n",
      "Step 3 : loss = 1.3975382512583145\n",
      "Step 4 : loss = 1.3904447483992766\n",
      "Step 5 : loss = 1.3833154082860029\n",
      "Step 6 : loss = 1.3759842198164691\n",
      "Step 7 : loss = 1.3687332413735844\n",
      "Step 8 : loss = 1.3612611838453819\n",
      "Step 9 : loss = 1.3537117322788588\n",
      "Update Procedure\n",
      "Step0 : loss = 6.699108521143596\n",
      "Step1 : loss = 6.471778313318889\n",
      "Step2 : loss = 6.314722220102946\n",
      "Step3 : loss = 6.181101083755493\n",
      "Step4 : loss = 6.044063250223796\n",
      "Step5 : loss = 5.899338165918986\n",
      "Step6 : loss = 5.755234400431315\n",
      "Step7 : loss = 5.612686316172282\n",
      "Step8 : loss = 5.469473282496135\n",
      "Step9 : loss = 5.32508111000061\n",
      "Data stream Batch- 2 : loss = 3.428323745727539\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.3037835931908044\n",
      "Step 1 : loss = 1.2958156746235632\n",
      "Step 2 : loss = 1.287764382930029\n",
      "Step 3 : loss = 1.2796007569524503\n",
      "Step 4 : loss = 1.2712631628715567\n",
      "Step 5 : loss = 1.2628687768731088\n",
      "Step 6 : loss = 1.2543651221408731\n",
      "Step 7 : loss = 1.2458112156462102\n",
      "Step 8 : loss = 1.237126301707966\n",
      "Step 9 : loss = 1.2283354249413287\n",
      "Update Procedure\n",
      "Step0 : loss = 5.580103635787964\n",
      "Step1 : loss = 5.211437940597534\n",
      "Step2 : loss = 5.000372648239136\n",
      "Step3 : loss = 4.800509989261627\n",
      "Step4 : loss = 4.600810647010803\n",
      "Step5 : loss = 4.412380516529083\n",
      "Step6 : loss = 4.233322411775589\n",
      "Step7 : loss = 4.053843289613724\n",
      "Step8 : loss = 3.8649486303329468\n",
      "Step9 : loss = 3.669449359178543\n",
      "Data stream Batch- 3 : loss = 3.6101537942886353\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.1806509451822393\n",
      "Step 1 : loss = 1.1706534593617395\n",
      "Step 2 : loss = 1.1606973324946703\n",
      "Step 3 : loss = 1.1507490385589856\n",
      "Step 4 : loss = 1.1409130150186164\n",
      "Step 5 : loss = 1.1311402304630194\n",
      "Step 6 : loss = 1.121275021860169\n",
      "Step 7 : loss = 1.1112966897586982\n",
      "Step 8 : loss = 1.1012729181213274\n",
      "Step 9 : loss = 1.0910474198175564\n",
      "Update Procedure\n",
      "Step0 : loss = 3.2022687911987306\n",
      "Step1 : loss = 2.8033161401748656\n",
      "Step2 : loss = 2.589590048789978\n",
      "Step3 : loss = 2.392485189437866\n",
      "Step4 : loss = 2.226255679130554\n",
      "Step5 : loss = 2.0816645860671996\n",
      "Step6 : loss = 1.935939359664917\n",
      "Step7 : loss = 1.7999490737915038\n",
      "Step8 : loss = 1.6819294929504394\n",
      "Step9 : loss = 1.5764119625091553\n",
      "Data stream Batch- 4 : loss = 3.7723296880722046\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.0264329424334897\n",
      "Step 1 : loss = 1.0152874012048991\n",
      "Step 2 : loss = 1.0042821364388579\n",
      "Step 3 : loss = 0.9931327590038852\n",
      "Step 4 : loss = 0.9820870948984983\n",
      "Step 5 : loss = 0.9706482257634874\n",
      "Step 6 : loss = 0.9591084387596873\n",
      "Step 7 : loss = 0.9474695480413853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 : loss = 0.9359228281185977\n",
      "Step 9 : loss = 0.9239362562784836\n",
      "Update Procedure\n",
      "Step0 : loss = 2.2151395082473755\n",
      "Step1 : loss = 1.8714922666549683\n",
      "Step2 : loss = 1.7672821680704753\n",
      "Step3 : loss = 1.6901763379573822\n",
      "Step4 : loss = 1.6428823173046112\n",
      "Step5 : loss = 1.58732674519221\n",
      "Step6 : loss = 1.545095056295395\n",
      "Step7 : loss = 1.489867091178894\n",
      "Step8 : loss = 1.4436808129151661\n",
      "Step9 : loss = 1.3940082987149556\n",
      "Data stream Batch- 5 : loss = 3.1513538360595703\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.9124918493486586\n",
      "Step 1 : loss = 0.900096839234706\n",
      "Step 2 : loss = 0.8876820002549461\n",
      "Step 3 : loss = 0.8752335038923083\n",
      "Step 4 : loss = 0.8626112210253875\n",
      "Step 5 : loss = 0.8500697324229848\n",
      "Step 6 : loss = 0.837235728272843\n",
      "Step 7 : loss = 0.8243603533813878\n",
      "Step 8 : loss = 0.8114462833201128\n",
      "Step 9 : loss = 0.7981805407043014\n",
      "Update Procedure\n",
      "Step0 : loss = 2.2819411073412215\n",
      "Step1 : loss = 1.817826850073678\n",
      "Step2 : loss = 1.7169927528926305\n",
      "Step3 : loss = 1.6218874880245753\n",
      "Step4 : loss = 1.5581643411091395\n",
      "Step5 : loss = 1.4941901224000114\n",
      "Step6 : loss = 1.4290056654385157\n",
      "Step7 : loss = 1.3656574998583113\n",
      "Step8 : loss = 1.3050008927072798\n",
      "Step9 : loss = 1.2510863201958793\n",
      "Data stream Batch- 6 : loss = 2.0056780576705933\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.8238540222306573\n",
      "Step 1 : loss = 0.8109475406034599\n",
      "Step 2 : loss = 0.797558330750418\n",
      "Step 3 : loss = 0.7844305700312059\n",
      "Step 4 : loss = 0.7709200179913924\n",
      "Step 5 : loss = 0.7573129585958899\n",
      "Step 6 : loss = 0.7435058019286583\n",
      "Step 7 : loss = 0.7296422320196316\n",
      "Step 8 : loss = 0.7158581288856647\n",
      "Step 9 : loss = 0.701729015562506\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8936380743980408\n",
      "Step1 : loss = 1.4856532365083694\n",
      "Step2 : loss = 1.3413769453763962\n",
      "Step3 : loss = 1.2303108498454094\n",
      "Step4 : loss = 1.142906166613102\n",
      "Step5 : loss = 1.0660149604082108\n",
      "Step6 : loss = 0.9883406981825829\n",
      "Step7 : loss = 0.9210735484957695\n",
      "Step8 : loss = 0.8636169284582138\n",
      "Step9 : loss = 0.8122029602527618\n",
      "Data stream Batch- 7 : loss = 0.7021274268627167\n",
      "Task  3\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.10294987720895618\n",
      "Step 1 : loss = 0.09648478112760045\n",
      "Step 2 : loss = 0.09130075414561563\n",
      "Step 3 : loss = 0.08735897682814135\n",
      "Step 4 : loss = 0.08458331212815311\n",
      "Step 5 : loss = 0.0830073486215302\n",
      "Step 6 : loss = 0.08244350645543327\n",
      "Step 7 : loss = 0.0811860045891196\n",
      "Step 8 : loss = 0.08081878554519444\n",
      "Step 9 : loss = 0.0794378675535203\n",
      "Update Procedure\n",
      "Step0 : loss = 9.96432113647461\n",
      "Step1 : loss = 9.697854042053223\n",
      "Step2 : loss = 9.436979293823242\n",
      "Step3 : loss = 9.196844100952148\n",
      "Step4 : loss = 8.97179126739502\n",
      "Step5 : loss = 8.761959075927734\n",
      "Step6 : loss = 8.570703506469727\n",
      "Step7 : loss = 8.386848449707031\n",
      "Step8 : loss = 8.203865051269531\n",
      "Step9 : loss = 8.023076057434082\n",
      "Data stream Batch- 0 : loss = 4.054800927639008\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1250878606405523\n",
      "Step 1 : loss = 0.11386978323793127\n",
      "Step 2 : loss = 0.1035542706751989\n",
      "Step 3 : loss = 0.09549067654011269\n",
      "Step 4 : loss = 0.08918052475662931\n",
      "Step 5 : loss = 0.08419037671789291\n",
      "Step 6 : loss = 0.08024495547666909\n",
      "Step 7 : loss = 0.07686364438591732\n",
      "Step 8 : loss = 0.0743446636545871\n",
      "Step 9 : loss = 0.07326511595368622\n",
      "Update Procedure\n",
      "Step0 : loss = 8.028388500213623\n",
      "Step1 : loss = 7.692096471786499\n",
      "Step2 : loss = 7.402799367904663\n",
      "Step3 : loss = 7.149028062820435\n",
      "Step4 : loss = 6.915506601333618\n",
      "Step5 : loss = 6.697074890136719\n",
      "Step6 : loss = 6.497297525405884\n",
      "Step7 : loss = 6.318824291229248\n",
      "Step8 : loss = 6.153261661529541\n",
      "Step9 : loss = 5.9982898235321045\n",
      "Data stream Batch- 1 : loss = 3.5449634790420532\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.14452537474119\n",
      "Step 1 : loss = 0.13160153132464206\n",
      "Step 2 : loss = 0.11924894065670077\n",
      "Step 3 : loss = 0.10834559083635371\n",
      "Step 4 : loss = 0.09937969199012196\n",
      "Step 5 : loss = 0.09181954549507253\n",
      "Step 6 : loss = 0.08545288887347967\n",
      "Step 7 : loss = 0.08033615688364658\n",
      "Step 8 : loss = 0.07607729562395622\n",
      "Step 9 : loss = 0.07274245661757295\n",
      "Update Procedure\n",
      "Step0 : loss = 4.756224552790324\n",
      "Step1 : loss = 4.504974563916524\n",
      "Step2 : loss = 4.372695446014404\n",
      "Step3 : loss = 4.270998239517212\n",
      "Step4 : loss = 4.173118789990743\n",
      "Step5 : loss = 4.069411476453145\n",
      "Step6 : loss = 3.9708301226298013\n",
      "Step7 : loss = 3.879066308339437\n",
      "Step8 : loss = 3.7904650370279946\n",
      "Step9 : loss = 3.704879323641459\n",
      "Data stream Batch- 2 : loss = 3.267323136329651\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13785822086686653\n",
      "Step 1 : loss = 0.12641726554563595\n",
      "Step 2 : loss = 0.1160785543599299\n",
      "Step 3 : loss = 0.10644904955157211\n",
      "Step 4 : loss = 0.0980035082451881\n",
      "Step 5 : loss = 0.09078659738694864\n",
      "Step 6 : loss = 0.08439999371175728\n",
      "Step 7 : loss = 0.07905311238257184\n",
      "Step 8 : loss = 0.07484819567392743\n",
      "Step 9 : loss = 0.07180477055824465\n",
      "Update Procedure\n",
      "Step0 : loss = 3.2355993539094925\n",
      "Step1 : loss = 2.9517397955060005\n",
      "Step2 : loss = 2.9016392678022385\n",
      "Step3 : loss = 2.8429144993424416\n",
      "Step4 : loss = 2.7731529623270035\n",
      "Step5 : loss = 2.712959185242653\n",
      "Step6 : loss = 2.6669564098119736\n",
      "Step7 : loss = 2.6261032596230507\n",
      "Step8 : loss = 2.581658259034157\n",
      "Step9 : loss = 2.540748156607151\n",
      "Data stream Batch- 3 : loss = 3.1362712383270264\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13868234605484064\n",
      "Step 1 : loss = 0.12538640714353985\n",
      "Step 2 : loss = 0.11346468009823371\n",
      "Step 3 : loss = 0.10347432242262931\n",
      "Step 4 : loss = 0.09511594888236788\n",
      "Step 5 : loss = 0.08800779849231716\n",
      "Step 6 : loss = 0.08234644840279269\n",
      "Step 7 : loss = 0.07811000418686677\n",
      "Step 8 : loss = 0.07522038627888948\n",
      "Step 9 : loss = 0.07387335609112468\n",
      "Update Procedure\n",
      "Step0 : loss = 3.034895694255829\n",
      "Step1 : loss = 2.840938913822174\n",
      "Step2 : loss = 2.765344512462616\n",
      "Step3 : loss = 2.6970156610012053\n",
      "Step4 : loss = 2.6530863285064696\n",
      "Step5 : loss = 2.6138182818889617\n",
      "Step6 : loss = 2.5597558498382567\n",
      "Step7 : loss = 2.5194817066192625\n",
      "Step8 : loss = 2.4843863964080812\n",
      "Step9 : loss = 2.4500227093696596\n",
      "Data stream Batch- 4 : loss = 3.0161197185516357\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.12749128083861064\n",
      "Step 1 : loss = 0.11570619784059033\n",
      "Step 2 : loss = 0.10545355973853951\n",
      "Step 3 : loss = 0.09700960947998932\n",
      "Step 4 : loss = 0.09009492677592096\n",
      "Step 5 : loss = 0.08452160731844958\n",
      "Step 6 : loss = 0.08075160592617024\n",
      "Step 7 : loss = 0.07906318954413845\n",
      "Step 8 : loss = 0.07860428301824464\n",
      "Step 9 : loss = 0.07740005870896673\n",
      "Update Procedure\n",
      "Step0 : loss = 3.1344275176525116\n",
      "Step1 : loss = 2.8774373630682626\n",
      "Step2 : loss = 2.786224593718847\n",
      "Step3 : loss = 2.7263236145178475\n",
      "Step4 : loss = 2.6421629190444946\n",
      "Step5 : loss = 2.5855643649895987\n",
      "Step6 : loss = 2.5186232924461365\n",
      "Step7 : loss = 2.479115163286527\n",
      "Step8 : loss = 2.439165030916532\n",
      "Step9 : loss = 2.3921975642442703\n",
      "Data stream Batch- 5 : loss = 2.7534669637680054\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.24633874377560994\n",
      "Step 1 : loss = 0.23105384424801856\n",
      "Step 2 : loss = 0.21649451379383367\n",
      "Step 3 : loss = 0.20255231302054155\n",
      "Step 4 : loss = 0.18914694805585203\n",
      "Step 5 : loss = 0.17614560722417774\n",
      "Step 6 : loss = 0.16354627270724564\n",
      "Step 7 : loss = 0.15114669226228244\n",
      "Step 8 : loss = 0.13907928210461423\n",
      "Step 9 : loss = 0.127265319384871\n",
      "Update Procedure\n",
      "Step0 : loss = 2.9436187658991133\n",
      "Step1 : loss = 2.632268786430359\n",
      "Step2 : loss = 2.4947016664913724\n",
      "Step3 : loss = 2.3797977226121083\n",
      "Step4 : loss = 2.2620660747800554\n",
      "Step5 : loss = 2.165233782359532\n",
      "Step6 : loss = 2.086277974503381\n",
      "Step7 : loss = 2.0338934872831618\n",
      "Step8 : loss = 1.989343328135354\n",
      "Step9 : loss = 1.951680907181331\n",
      "Data stream Batch- 6 : loss = 2.4436376094818115\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.3804237383343871\n",
      "Step 1 : loss = 0.3620610756060434\n",
      "Step 2 : loss = 0.34411515612450855\n",
      "Step 3 : loss = 0.3265800421850549\n",
      "Step 4 : loss = 0.30947964132896494\n",
      "Step 5 : loss = 0.2927039502218129\n",
      "Step 6 : loss = 0.2764797968464711\n",
      "Step 7 : loss = 0.26137325973619546\n",
      "Step 8 : loss = 0.2469084543220344\n",
      "Step 9 : loss = 0.23287919466457668\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3034451380372047\n",
      "Step1 : loss = 1.888344645500183\n",
      "Step2 : loss = 1.84940205514431\n",
      "Step3 : loss = 1.7978480122983456\n",
      "Step4 : loss = 1.7509875148534775\n",
      "Step5 : loss = 1.7285389825701714\n",
      "Step6 : loss = 1.6975598596036434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step7 : loss = 1.6716776639223099\n",
      "Step8 : loss = 1.650334857404232\n",
      "Step9 : loss = 1.6315617859363556\n",
      "Data stream Batch- 7 : loss = 2.244759440422058\n",
      "Task  4\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.11162400453957537\n",
      "Step 1 : loss = 0.10370090284665662\n",
      "Step 2 : loss = 0.09828527220007446\n",
      "Step 3 : loss = 0.1020537987854036\n",
      "Step 4 : loss = 0.0975968214491057\n",
      "Step 5 : loss = 0.1010156099314964\n",
      "Step 6 : loss = 0.09672214361646819\n",
      "Step 7 : loss = 0.0998813767370487\n",
      "Step 8 : loss = 0.09580796747690155\n",
      "Step 9 : loss = 0.098769276674896\n",
      "Update Procedure\n",
      "Step0 : loss = 4.515081405639648\n",
      "Step1 : loss = 4.366633892059326\n",
      "Step2 : loss = 4.2199835777282715\n",
      "Step3 : loss = 4.075153350830078\n",
      "Step4 : loss = 3.932405948638916\n",
      "Step5 : loss = 3.791297674179077\n",
      "Step6 : loss = 3.651804208755493\n",
      "Step7 : loss = 3.5143120288848877\n",
      "Step8 : loss = 3.3793768882751465\n",
      "Step9 : loss = 3.2461490631103516\n",
      "Data stream Batch- 0 : loss = 3.0928651094436646\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.24103774204850198\n",
      "Step 1 : loss = 0.21184773713586824\n",
      "Step 2 : loss = 0.1841504506796362\n",
      "Step 3 : loss = 0.15936074844665\n",
      "Step 4 : loss = 0.1377791219642238\n",
      "Step 5 : loss = 0.11998538293594879\n",
      "Step 6 : loss = 0.10562825814362556\n",
      "Step 7 : loss = 0.09626201284487569\n",
      "Step 8 : loss = 0.096856584136803\n",
      "Step 9 : loss = 0.09510409428723274\n",
      "Update Procedure\n",
      "Step0 : loss = 5.357302188873291\n",
      "Step1 : loss = 5.049569010734558\n",
      "Step2 : loss = 4.752828240394592\n",
      "Step3 : loss = 4.4633190631866455\n",
      "Step4 : loss = 4.1790452003479\n",
      "Step5 : loss = 3.8973820209503174\n",
      "Step6 : loss = 3.621428966522217\n",
      "Step7 : loss = 3.3559794425964355\n",
      "Step8 : loss = 3.101232886314392\n",
      "Step9 : loss = 2.8579759001731873\n",
      "Data stream Batch- 1 : loss = 2.9442399740219116\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4640856019561253\n",
      "Step 1 : loss = 0.4330693094739838\n",
      "Step 2 : loss = 0.40289550567903215\n",
      "Step 3 : loss = 0.37349485064901056\n",
      "Step 4 : loss = 0.3446561679539699\n",
      "Step 5 : loss = 0.31616300831120164\n",
      "Step 6 : loss = 0.2880777144952426\n",
      "Step 7 : loss = 0.2614501400303746\n",
      "Step 8 : loss = 0.23580045640054675\n",
      "Step 9 : loss = 0.2134441375141106\n",
      "Update Procedure\n",
      "Step0 : loss = 5.249934196472168\n",
      "Step1 : loss = 4.772036790847778\n",
      "Step2 : loss = 4.324803749720256\n",
      "Step3 : loss = 3.896222392717997\n",
      "Step4 : loss = 3.4896748463312783\n",
      "Step5 : loss = 3.1165706713994346\n",
      "Step6 : loss = 2.805068055788676\n",
      "Step7 : loss = 2.584146042664846\n",
      "Step8 : loss = 2.434317111968994\n",
      "Step9 : loss = 2.3227233290672302\n",
      "Data stream Batch- 2 : loss = 3.166786551475525\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6773286580329849\n",
      "Step 1 : loss = 0.6502652318349906\n",
      "Step 2 : loss = 0.6218488490652471\n",
      "Step 3 : loss = 0.5934711863952024\n",
      "Step 4 : loss = 0.5649229302765831\n",
      "Step 5 : loss = 0.5369448673393992\n",
      "Step 6 : loss = 0.509934400175772\n",
      "Step 7 : loss = 0.4823833578399249\n",
      "Step 8 : loss = 0.45500336512331924\n",
      "Step 9 : loss = 0.4283258696870198\n",
      "Update Procedure\n",
      "Step0 : loss = 2.9187785983085632\n",
      "Step1 : loss = 2.4291854947805405\n",
      "Step2 : loss = 2.136332228779793\n",
      "Step3 : loss = 1.9572090059518814\n",
      "Step4 : loss = 1.8469290435314178\n",
      "Step5 : loss = 1.770662561058998\n",
      "Step6 : loss = 1.7024638056755066\n",
      "Step7 : loss = 1.632517471909523\n",
      "Step8 : loss = 1.5677436888217926\n",
      "Step9 : loss = 1.519838199019432\n",
      "Data stream Batch- 3 : loss = 3.029752016067505\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6116711286088777\n",
      "Step 1 : loss = 0.589347192053757\n",
      "Step 2 : loss = 0.5698689175148804\n",
      "Step 3 : loss = 0.549960393801568\n",
      "Step 4 : loss = 0.5303090519493534\n",
      "Step 5 : loss = 0.5104481309061013\n",
      "Step 6 : loss = 0.49160464487615085\n",
      "Step 7 : loss = 0.47196635710932905\n",
      "Step 8 : loss = 0.45230986085084696\n",
      "Step 9 : loss = 0.4337623226618956\n",
      "Update Procedure\n",
      "Step0 : loss = 3.0198153257369995\n",
      "Step1 : loss = 2.438339281082153\n",
      "Step2 : loss = 2.171090841293335\n",
      "Step3 : loss = 2.0757922649383547\n",
      "Step4 : loss = 2.0110936403274535\n",
      "Step5 : loss = 1.9432075262069701\n",
      "Step6 : loss = 1.8637518286705017\n",
      "Step7 : loss = 1.7893463253974915\n",
      "Step8 : loss = 1.725072968006134\n",
      "Step9 : loss = 1.6649065494537354\n",
      "Data stream Batch- 4 : loss = 2.618605136871338\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6501902889401193\n",
      "Step 1 : loss = 0.620887576682227\n",
      "Step 2 : loss = 0.5980595109363397\n",
      "Step 3 : loss = 0.5796195067110516\n",
      "Step 4 : loss = 0.5610706595319604\n",
      "Step 5 : loss = 0.5416435391183884\n",
      "Step 6 : loss = 0.5223285229669676\n",
      "Step 7 : loss = 0.5037212475188195\n",
      "Step 8 : loss = 0.48610043571227124\n",
      "Step 9 : loss = 0.46793830114461127\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5745779474576316\n",
      "Step1 : loss = 1.9896965722242992\n",
      "Step2 : loss = 1.7768755853176117\n",
      "Step3 : loss = 1.7235538562138875\n",
      "Step4 : loss = 1.6441538731257122\n",
      "Step5 : loss = 1.5588437219460805\n",
      "Step6 : loss = 1.4857396980126698\n",
      "Step7 : loss = 1.420038640499115\n",
      "Step8 : loss = 1.362706075112025\n",
      "Step9 : loss = 1.3117468158404033\n",
      "Data stream Batch- 5 : loss = 2.459255576133728\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6463041209512287\n",
      "Step 1 : loss = 0.6212018445488953\n",
      "Step 2 : loss = 0.6029656058975629\n",
      "Step 3 : loss = 0.5842732440029818\n",
      "Step 4 : loss = 0.5651965991017365\n",
      "Step 5 : loss = 0.5470592628040957\n",
      "Step 6 : loss = 0.5304748711427526\n",
      "Step 7 : loss = 0.513363918656158\n",
      "Step 8 : loss = 0.49409087264821644\n",
      "Step 9 : loss = 0.4744789946706049\n",
      "Update Procedure\n",
      "Step0 : loss = 1.983352814401899\n",
      "Step1 : loss = 1.467153889792306\n",
      "Step2 : loss = 1.3373913637229375\n",
      "Step3 : loss = 1.305613739149911\n",
      "Step4 : loss = 1.2253248861857824\n",
      "Step5 : loss = 1.1769420887742723\n",
      "Step6 : loss = 1.1381884046963282\n",
      "Step7 : loss = 1.1006991948400224\n",
      "Step8 : loss = 1.0707806859697615\n",
      "Step9 : loss = 1.04559754048075\n",
      "Data stream Batch- 6 : loss = 1.721893846988678\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6262996107339859\n",
      "Step 1 : loss = 0.6035322238528539\n",
      "Step 2 : loss = 0.5859652818313666\n",
      "Step 3 : loss = 0.5675720803084827\n",
      "Step 4 : loss = 0.5514094907021712\n",
      "Step 5 : loss = 0.5352249976129286\n",
      "Step 6 : loss = 0.516483175784113\n",
      "Step 7 : loss = 0.497210753306983\n",
      "Step 8 : loss = 0.4778189745687303\n",
      "Step 9 : loss = 0.459388094762015\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6491654813289642\n",
      "Step1 : loss = 1.1448158733546734\n",
      "Step2 : loss = 1.0517544150352478\n",
      "Step3 : loss = 1.012569461017847\n",
      "Step4 : loss = 0.950328640639782\n",
      "Step5 : loss = 0.943048320710659\n",
      "Step6 : loss = 0.9142221957445145\n",
      "Step7 : loss = 0.8707121573388577\n",
      "Step8 : loss = 0.8428316339850426\n",
      "Step9 : loss = 0.8290436007082462\n",
      "Data stream Batch- 7 : loss = 1.2607274055480957\n",
      "Task  5\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.09521019600760487\n",
      "Step 1 : loss = 0.08958595013098111\n",
      "Step 2 : loss = 0.08575924417403127\n",
      "Step 3 : loss = 0.08440380278856507\n",
      "Step 4 : loss = 0.08249937106249115\n",
      "Step 5 : loss = 0.08037208161494207\n",
      "Step 6 : loss = 0.07944434148052501\n",
      "Step 7 : loss = 0.07734704496087655\n",
      "Step 8 : loss = 0.07607589516315669\n",
      "Step 9 : loss = 0.07411445852605597\n",
      "Update Procedure\n",
      "Step0 : loss = 2.8059792518615723\n",
      "Step1 : loss = 2.5261895656585693\n",
      "Step2 : loss = 2.2469303607940674\n",
      "Step3 : loss = 1.9683690071105957\n",
      "Step4 : loss = 1.7668706178665161\n",
      "Step5 : loss = 1.6521039009094238\n",
      "Step6 : loss = 1.5988084077835083\n",
      "Step7 : loss = 1.5542831420898438\n",
      "Step8 : loss = 1.5024189949035645\n",
      "Step9 : loss = 1.4371647834777832\n",
      "Data stream Batch- 0 : loss = 3.305278778076172\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.11923814725929073\n",
      "Step 1 : loss = 0.10196502695067061\n",
      "Step 2 : loss = 0.08690513434213779\n",
      "Step 3 : loss = 0.07585023021369817\n",
      "Step 4 : loss = 0.07062552132170707\n",
      "Step 5 : loss = 0.06772059704591002\n",
      "Step 6 : loss = 0.0689101452783992\n",
      "Step 7 : loss = 0.06572179455709244\n",
      "Step 8 : loss = 0.0664086368851482\n",
      "Step 9 : loss = 0.06390375240691124\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5749827027320862\n",
      "Step1 : loss = 1.390828549861908\n",
      "Step2 : loss = 1.1834863722324371\n",
      "Step3 : loss = 1.0394040644168854\n",
      "Step4 : loss = 0.9641468226909637\n",
      "Step5 : loss = 0.8268133252859116\n",
      "Step6 : loss = 0.7628240585327148\n",
      "Step7 : loss = 0.7361839190125465\n",
      "Step8 : loss = 0.725637897849083\n",
      "Step9 : loss = 0.7070882469415665\n",
      "Data stream Batch- 1 : loss = 3.7069257497787476\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.11788814147816054\n",
      "Step 1 : loss = 0.10014300583935683\n",
      "Step 2 : loss = 0.08661854860801546\n",
      "Step 3 : loss = 0.07761632196368679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 : loss = 0.07190067800027983\n",
      "Step 5 : loss = 0.06942852585029508\n",
      "Step 6 : loss = 0.06794351427963684\n",
      "Step 7 : loss = 0.06567908577428805\n",
      "Step 8 : loss = 0.06599035012417487\n",
      "Step 9 : loss = 0.06340324044271949\n",
      "Update Procedure\n",
      "Step0 : loss = 2.1386035084724426\n",
      "Step1 : loss = 1.9000410437583923\n",
      "Step2 : loss = 1.8475023706754048\n",
      "Step3 : loss = 1.7333744168281555\n",
      "Step4 : loss = 1.6530247231324513\n",
      "Step5 : loss = 1.5635549078385036\n",
      "Step6 : loss = 1.5240739385286968\n",
      "Step7 : loss = 1.4658331374327342\n",
      "Step8 : loss = 1.419701099395752\n",
      "Step9 : loss = 1.3745531340440114\n",
      "Data stream Batch- 2 : loss = 3.2605490684509277\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1466245130487969\n",
      "Step 1 : loss = 0.13015710796259106\n",
      "Step 2 : loss = 0.11454362448763161\n",
      "Step 3 : loss = 0.10064427457262008\n",
      "Step 4 : loss = 0.08996835188304503\n",
      "Step 5 : loss = 0.08323923756797162\n",
      "Step 6 : loss = 0.07790192132963547\n",
      "Step 7 : loss = 0.07473354086220738\n",
      "Step 8 : loss = 0.07158971903476095\n",
      "Step 9 : loss = 0.06905849389805799\n",
      "Update Procedure\n",
      "Step0 : loss = 1.93572399020195\n",
      "Step1 : loss = 1.8378047049045563\n",
      "Step2 : loss = 1.677025929093361\n",
      "Step3 : loss = 1.5072611272335052\n",
      "Step4 : loss = 1.4983913004398346\n",
      "Step5 : loss = 1.41440911591053\n",
      "Step6 : loss = 1.3729889541864395\n",
      "Step7 : loss = 1.3143442571163177\n",
      "Step8 : loss = 1.267367735505104\n",
      "Step9 : loss = 1.2285473495721817\n",
      "Data stream Batch- 3 : loss = 3.2102158069610596\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13120559583166763\n",
      "Step 1 : loss = 0.11948315679199166\n",
      "Step 2 : loss = 0.1087370941592824\n",
      "Step 3 : loss = 0.09915907690005879\n",
      "Step 4 : loss = 0.09080969513290459\n",
      "Step 5 : loss = 0.08473935835359116\n",
      "Step 6 : loss = 0.0808384059011818\n",
      "Step 7 : loss = 0.07892858165626725\n",
      "Step 8 : loss = 0.07641990030154822\n",
      "Step 9 : loss = 0.07512039116746377\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5990973174571992\n",
      "Step1 : loss = 1.5210226058959961\n",
      "Step2 : loss = 1.3593993306159973\n",
      "Step3 : loss = 1.1831680834293365\n",
      "Step4 : loss = 1.220118796825409\n",
      "Step5 : loss = 1.0807287454605103\n",
      "Step6 : loss = 1.0456926703453064\n",
      "Step7 : loss = 0.9910556256771088\n",
      "Step8 : loss = 0.905011647939682\n",
      "Step9 : loss = 0.8846456289291382\n",
      "Data stream Batch- 4 : loss = 3.1324844360351562\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.14912487448060086\n",
      "Step 1 : loss = 0.1373005743862854\n",
      "Step 2 : loss = 0.1268145131996818\n",
      "Step 3 : loss = 0.11733710728142233\n",
      "Step 4 : loss = 0.10917751001016725\n",
      "Step 5 : loss = 0.10265342466651448\n",
      "Step 6 : loss = 0.09803376473811648\n",
      "Step 7 : loss = 0.09484390163321108\n",
      "Step 8 : loss = 0.09185495949572041\n",
      "Step 9 : loss = 0.08871302536230474\n",
      "Update Procedure\n",
      "Step0 : loss = 1.849707543849945\n",
      "Step1 : loss = 1.6243449052174885\n",
      "Step2 : loss = 1.5025618771711986\n",
      "Step3 : loss = 1.413786143064499\n",
      "Step4 : loss = 1.3739849378665288\n",
      "Step5 : loss = 1.3143349538246791\n",
      "Step6 : loss = 1.2831330051024754\n",
      "Step7 : loss = 1.2512595454851787\n",
      "Step8 : loss = 1.2207940965890884\n",
      "Step9 : loss = 1.190836710234483\n",
      "Data stream Batch- 5 : loss = 2.7686532735824585\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.22998160461466463\n",
      "Step 1 : loss = 0.20884882353009687\n",
      "Step 2 : loss = 0.18826059207379345\n",
      "Step 3 : loss = 0.1684916255300835\n",
      "Step 4 : loss = 0.15200393033317394\n",
      "Step 5 : loss = 0.13828294185389367\n",
      "Step 6 : loss = 0.1268635845107455\n",
      "Step 7 : loss = 0.11694790784506098\n",
      "Step 8 : loss = 0.10838594834157636\n",
      "Step 9 : loss = 0.10084813613858488\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8292630740574427\n",
      "Step1 : loss = 1.5210277949060713\n",
      "Step2 : loss = 1.3958906722920281\n",
      "Step3 : loss = 1.2765506378241949\n",
      "Step4 : loss = 1.2828115693160467\n",
      "Step5 : loss = 1.2159670421055384\n",
      "Step6 : loss = 1.1766936012676783\n",
      "Step7 : loss = 1.1399786812918526\n",
      "Step8 : loss = 1.1207224556377955\n",
      "Step9 : loss = 1.0988332203456335\n",
      "Data stream Batch- 6 : loss = 2.401145279407501\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.24665741315259349\n",
      "Step 1 : loss = 0.22596838511970072\n",
      "Step 2 : loss = 0.20617276975618942\n",
      "Step 3 : loss = 0.18758954478959952\n",
      "Step 4 : loss = 0.16956810944137118\n",
      "Step 5 : loss = 0.15268749599271114\n",
      "Step 6 : loss = 0.1394540008586196\n",
      "Step 7 : loss = 0.12760647542272058\n",
      "Step 8 : loss = 0.11724190265975065\n",
      "Step 9 : loss = 0.10868261523308262\n",
      "Update Procedure\n",
      "Step0 : loss = 1.858678862452507\n",
      "Step1 : loss = 1.2752215713262558\n",
      "Step2 : loss = 1.3290090709924698\n",
      "Step3 : loss = 1.24917509034276\n",
      "Step4 : loss = 1.184012996032834\n",
      "Step5 : loss = 1.156637977808714\n",
      "Step6 : loss = 1.1229394786059856\n",
      "Step7 : loss = 1.1056203283369541\n",
      "Step8 : loss = 1.1045853085815907\n",
      "Step9 : loss = 1.086400793865323\n",
      "Data stream Batch- 7 : loss = 2.0650975108146667\n",
      "Task  6\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.23915359982259807\n",
      "Step 1 : loss = 0.21575915156937545\n",
      "Step 2 : loss = 0.19974712885117957\n",
      "Step 3 : loss = 0.192501495958912\n",
      "Step 4 : loss = 0.1871801339607272\n",
      "Step 5 : loss = 0.185403757951858\n",
      "Step 6 : loss = 0.18360524076436247\n",
      "Step 7 : loss = 0.18211719229639994\n",
      "Step 8 : loss = 0.1817687937102857\n",
      "Step 9 : loss = 0.18117018163884208\n",
      "Update Procedure\n",
      "Step0 : loss = 3.1258795261383057\n",
      "Step1 : loss = 3.033724784851074\n",
      "Step2 : loss = 2.9419522285461426\n",
      "Step3 : loss = 2.8505630493164062\n",
      "Step4 : loss = 2.759707450866699\n",
      "Step5 : loss = 2.6694204807281494\n",
      "Step6 : loss = 2.579396963119507\n",
      "Step7 : loss = 2.489630699157715\n",
      "Step8 : loss = 2.400308847427368\n",
      "Step9 : loss = 2.311429977416992\n",
      "Data stream Batch- 0 : loss = 8.337891578674316\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.40308841406589463\n",
      "Step 1 : loss = 0.36308618610103927\n",
      "Step 2 : loss = 0.3233486186062533\n",
      "Step 3 : loss = 0.28567094595895876\n",
      "Step 4 : loss = 0.252305257355883\n",
      "Step 5 : loss = 0.22462710239702746\n",
      "Step 6 : loss = 0.2043293951581868\n",
      "Step 7 : loss = 0.1919414730713008\n",
      "Step 8 : loss = 0.18434442416247393\n",
      "Step 9 : loss = 0.17960918703604312\n",
      "Update Procedure\n",
      "Step0 : loss = 3.246112823486328\n",
      "Step1 : loss = 3.0643157958984375\n",
      "Step2 : loss = 2.884450674057007\n",
      "Step3 : loss = 2.705366611480713\n",
      "Step4 : loss = 2.5265530347824097\n",
      "Step5 : loss = 2.3460261821746826\n",
      "Step6 : loss = 2.1633594036102295\n",
      "Step7 : loss = 1.9784335494041443\n",
      "Step8 : loss = 1.79836106300354\n",
      "Step9 : loss = 1.6474315524101257\n",
      "Data stream Batch- 1 : loss = 7.2458860874176025\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6231628837093475\n",
      "Step 1 : loss = 0.580236387158197\n",
      "Step 2 : loss = 0.537479069491937\n",
      "Step 3 : loss = 0.49616460719160616\n",
      "Step 4 : loss = 0.455133361428503\n",
      "Step 5 : loss = 0.41527938175177764\n",
      "Step 6 : loss = 0.37565273856005027\n",
      "Step 7 : loss = 0.33586082697387726\n",
      "Step 8 : loss = 0.3004683175375537\n",
      "Step 9 : loss = 0.2736697947222089\n",
      "Update Procedure\n",
      "Step0 : loss = 2.814678351084391\n",
      "Step1 : loss = 2.565083702405294\n",
      "Step2 : loss = 2.322501540184021\n",
      "Step3 : loss = 2.1238308350245156\n",
      "Step4 : loss = 1.9683813452720642\n",
      "Step5 : loss = 1.834172209103902\n",
      "Step6 : loss = 1.7141879796981812\n",
      "Step7 : loss = 1.6063290238380432\n",
      "Step8 : loss = 1.5103994409243267\n",
      "Step9 : loss = 1.4298545519510906\n",
      "Data stream Batch- 2 : loss = 6.642467498779297\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7843465075488129\n",
      "Step 1 : loss = 0.7376961967656537\n",
      "Step 2 : loss = 0.6921897398160091\n",
      "Step 3 : loss = 0.6485234298639827\n",
      "Step 4 : loss = 0.6030963259320411\n",
      "Step 5 : loss = 0.558659316037619\n",
      "Step 6 : loss = 0.5156435898608631\n",
      "Step 7 : loss = 0.474354739776916\n",
      "Step 8 : loss = 0.4390710189524624\n",
      "Step 9 : loss = 0.4098155555093572\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8916774839162827\n",
      "Step1 : loss = 1.6963775902986526\n",
      "Step2 : loss = 1.540817677974701\n",
      "Step3 : loss = 1.4223704934120178\n",
      "Step4 : loss = 1.3461330235004425\n",
      "Step5 : loss = 1.2880803495645523\n",
      "Step6 : loss = 1.237875536084175\n",
      "Step7 : loss = 1.1864170283079147\n",
      "Step8 : loss = 1.1298107206821442\n",
      "Step9 : loss = 1.0685175061225891\n",
      "Data stream Batch- 3 : loss = 6.340604305267334\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5763287819034997\n",
      "Step 1 : loss = 0.5382223097577927\n",
      "Step 2 : loss = 0.5031963217412195\n",
      "Step 3 : loss = 0.4733338268148521\n",
      "Step 4 : loss = 0.4444978553387854\n",
      "Step 5 : loss = 0.41674154695892146\n",
      "Step 6 : loss = 0.3925251476111866\n",
      "Step 7 : loss = 0.3691963449652706\n",
      "Step 8 : loss = 0.34730324218907055\n",
      "Step 9 : loss = 0.3257718222600127\n",
      "Update Procedure\n",
      "Step0 : loss = 1.1527345180511475\n",
      "Step1 : loss = 0.9933610260486603\n",
      "Step2 : loss = 0.9046269178390502\n",
      "Step3 : loss = 0.8208230614662171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step4 : loss = 0.7347316145896912\n",
      "Step5 : loss = 0.6417457461357117\n",
      "Step6 : loss = 0.5555661022663116\n",
      "Step7 : loss = 0.47429537773132324\n",
      "Step8 : loss = 0.40712917149066924\n",
      "Step9 : loss = 0.3827869683504105\n",
      "Data stream Batch- 4 : loss = 4.850382328033447\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.31798741294751093\n",
      "Step 1 : loss = 0.2925848575338485\n",
      "Step 2 : loss = 0.271945321820085\n",
      "Step 3 : loss = 0.2516631868446157\n",
      "Step 4 : loss = 0.23543081063008497\n",
      "Step 5 : loss = 0.2236631292317595\n",
      "Step 6 : loss = 0.21595456499665502\n",
      "Step 7 : loss = 0.20894955232857712\n",
      "Step 8 : loss = 0.20301639955668221\n",
      "Step 9 : loss = 0.19851321484006587\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9578079382578532\n",
      "Step1 : loss = 0.87446295718352\n",
      "Step2 : loss = 0.8007190898060799\n",
      "Step3 : loss = 0.7575278828541437\n",
      "Step4 : loss = 0.707312323153019\n",
      "Step5 : loss = 0.6640640497207642\n",
      "Step6 : loss = 0.631916863222917\n",
      "Step7 : loss = 0.6028404509027799\n",
      "Step8 : loss = 0.5864113320906957\n",
      "Step9 : loss = 0.5747838293512663\n",
      "Data stream Batch- 5 : loss = 4.811143398284912\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4926263738364454\n",
      "Step 1 : loss = 0.45918656247002737\n",
      "Step 2 : loss = 0.42676451409619953\n",
      "Step 3 : loss = 0.39552376129561\n",
      "Step 4 : loss = 0.3674547619526348\n",
      "Step 5 : loss = 0.3409609751154979\n",
      "Step 6 : loss = 0.317729299970799\n",
      "Step 7 : loss = 0.2956919010669466\n",
      "Step 8 : loss = 0.27491297508397744\n",
      "Step 9 : loss = 0.2552899347233867\n",
      "Update Procedure\n",
      "Step0 : loss = 1.0676527108464922\n",
      "Step1 : loss = 0.8826972033296313\n",
      "Step2 : loss = 0.8120952929769244\n",
      "Step3 : loss = 0.7574135256665093\n",
      "Step4 : loss = 0.7483133290495191\n",
      "Step5 : loss = 0.7311911497797284\n",
      "Step6 : loss = 0.7159762914691653\n",
      "Step7 : loss = 0.7024007907935551\n",
      "Step8 : loss = 0.6904178751366479\n",
      "Step9 : loss = 0.6811851837805339\n",
      "Data stream Batch- 6 : loss = 4.880183696746826\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4954646166354891\n",
      "Step 1 : loss = 0.4663067600201993\n",
      "Step 2 : loss = 0.4389857997556054\n",
      "Step 3 : loss = 0.4125023438462189\n",
      "Step 4 : loss = 0.3888611430804881\n",
      "Step 5 : loss = 0.36615059073600503\n",
      "Step 6 : loss = 0.34408428200653624\n",
      "Step 7 : loss = 0.32219912486062163\n",
      "Step 8 : loss = 0.3020897835847877\n",
      "Step 9 : loss = 0.28250666254214823\n",
      "Update Procedure\n",
      "Step0 : loss = 1.354425948113203\n",
      "Step1 : loss = 1.1650113351643085\n",
      "Step2 : loss = 1.1085328795015812\n",
      "Step3 : loss = 1.0657395720481873\n",
      "Step4 : loss = 1.0385778825730085\n",
      "Step5 : loss = 1.0147788859903812\n",
      "Step6 : loss = 0.9971183389425278\n",
      "Step7 : loss = 0.9817444644868374\n",
      "Step8 : loss = 0.9703653957694769\n",
      "Step9 : loss = 0.9600374456495047\n",
      "Data stream Batch- 7 : loss = 4.244242906570435\n",
      "Task  7\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.40185735860676874\n",
      "Step 1 : loss = 0.38614460982840565\n",
      "Step 2 : loss = 0.3718195716621325\n",
      "Step 3 : loss = 0.3584512408423637\n",
      "Step 4 : loss = 0.3468321119242954\n",
      "Step 5 : loss = 0.33586841918794175\n",
      "Step 6 : loss = 0.32552215258280437\n",
      "Step 7 : loss = 0.3157940847488741\n",
      "Step 8 : loss = 0.3066923511022377\n",
      "Step 9 : loss = 0.2971729570497123\n",
      "Update Procedure\n",
      "Step0 : loss = 7.941171169281006\n",
      "Step1 : loss = 7.7367844581604\n",
      "Step2 : loss = 7.537604808807373\n",
      "Step3 : loss = 7.344417572021484\n",
      "Step4 : loss = 7.156801223754883\n",
      "Step5 : loss = 6.972664833068848\n",
      "Step6 : loss = 6.79161262512207\n",
      "Step7 : loss = 6.6128950119018555\n",
      "Step8 : loss = 6.436644077301025\n",
      "Step9 : loss = 6.262840747833252\n",
      "Data stream Batch- 0 : loss = 5.563223838806152\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2847348676447476\n",
      "Step 1 : loss = 0.2742157932784822\n",
      "Step 2 : loss = 0.26440651359716577\n",
      "Step 3 : loss = 0.2553087239227598\n",
      "Step 4 : loss = 0.24641418950336558\n",
      "Step 5 : loss = 0.23855307082394286\n",
      "Step 6 : loss = 0.23108558545983027\n",
      "Step 7 : loss = 0.22437521355108372\n",
      "Step 8 : loss = 0.21687384461984038\n",
      "Step 9 : loss = 0.20974935746441284\n",
      "Update Procedure\n",
      "Step0 : loss = 4.812269926071167\n",
      "Step1 : loss = 4.522985577583313\n",
      "Step2 : loss = 4.24829363822937\n",
      "Step3 : loss = 3.9878969192504883\n",
      "Step4 : loss = 3.744637966156006\n",
      "Step5 : loss = 3.5241081714630127\n",
      "Step6 : loss = 3.3237223625183105\n",
      "Step7 : loss = 3.1400370597839355\n",
      "Step8 : loss = 2.973280429840088\n",
      "Step9 : loss = 2.815518617630005\n",
      "Data stream Batch- 1 : loss = 4.6977455615997314\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2694913262841366\n",
      "Step 1 : loss = 0.25463358027830957\n",
      "Step 2 : loss = 0.24160855658470637\n",
      "Step 3 : loss = 0.2296649432386316\n",
      "Step 4 : loss = 0.21992086178608355\n",
      "Step 5 : loss = 0.21009082022522177\n",
      "Step 6 : loss = 0.20143717382517126\n",
      "Step 7 : loss = 0.1931189942986719\n",
      "Step 8 : loss = 0.18633611010949291\n",
      "Step 9 : loss = 0.17946814274681466\n",
      "Update Procedure\n",
      "Step0 : loss = 2.4501975377400718\n",
      "Step1 : loss = 2.2884405851364136\n",
      "Step2 : loss = 2.1559454997380576\n",
      "Step3 : loss = 2.0362735191980996\n",
      "Step4 : loss = 1.9122577905654907\n",
      "Step5 : loss = 1.7777161200841267\n",
      "Step6 : loss = 1.6400800943374634\n",
      "Step7 : loss = 1.502852161725362\n",
      "Step8 : loss = 1.3638849059740703\n",
      "Step9 : loss = 1.2264809012413025\n",
      "Data stream Batch- 2 : loss = 4.2440489530563354\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2945893938254033\n",
      "Step 1 : loss = 0.2752686799932567\n",
      "Step 2 : loss = 0.2579766272463732\n",
      "Step 3 : loss = 0.24040710369923285\n",
      "Step 4 : loss = 0.2250755145347544\n",
      "Step 5 : loss = 0.21568987996332228\n",
      "Step 6 : loss = 0.20548814457974263\n",
      "Step 7 : loss = 0.19712847629414193\n",
      "Step 8 : loss = 0.18708084421971488\n",
      "Step 9 : loss = 0.17718166106986621\n",
      "Update Procedure\n",
      "Step0 : loss = 1.280745193362236\n",
      "Step1 : loss = 1.0107808411121368\n",
      "Step2 : loss = 0.8620776161551476\n",
      "Step3 : loss = 0.7393684014678001\n",
      "Step4 : loss = 0.6740296930074692\n",
      "Step5 : loss = 0.6647613570094109\n",
      "Step6 : loss = 0.6473656520247459\n",
      "Step7 : loss = 0.6265532225370407\n",
      "Step8 : loss = 0.6054044775664806\n",
      "Step9 : loss = 0.5802061818540096\n",
      "Data stream Batch- 3 : loss = 4.0374835729599\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.24162290811775222\n",
      "Step 1 : loss = 0.2239576952502368\n",
      "Step 2 : loss = 0.20885354564007785\n",
      "Step 3 : loss = 0.19885934243599573\n",
      "Step 4 : loss = 0.18938599353626606\n",
      "Step 5 : loss = 0.1810177974757694\n",
      "Step 6 : loss = 0.17619472874831113\n",
      "Step 7 : loss = 0.17257985938636083\n",
      "Step 8 : loss = 0.16510423919747746\n",
      "Step 9 : loss = 0.16027809811076002\n",
      "Update Procedure\n",
      "Step0 : loss = 0.833132404088974\n",
      "Step1 : loss = 0.6586262434720993\n",
      "Step2 : loss = 0.6449190139770508\n",
      "Step3 : loss = 0.6121786326169968\n",
      "Step4 : loss = 0.6031174749135971\n",
      "Step5 : loss = 0.5836967632174492\n",
      "Step6 : loss = 0.5737934648990631\n",
      "Step7 : loss = 0.5630522519350052\n",
      "Step8 : loss = 0.5600563585758209\n",
      "Step9 : loss = 0.5518918812274933\n",
      "Data stream Batch- 4 : loss = 4.187556028366089\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.18207149092581065\n",
      "Step 1 : loss = 0.17330559929684985\n",
      "Step 2 : loss = 0.1664577610731598\n",
      "Step 3 : loss = 0.16061870095630487\n",
      "Step 4 : loss = 0.1552443424210189\n",
      "Step 5 : loss = 0.1509915713457361\n",
      "Step 6 : loss = 0.14671137733828454\n",
      "Step 7 : loss = 0.14329135550688657\n",
      "Step 8 : loss = 0.13945433993247291\n",
      "Step 9 : loss = 0.13635998799923865\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2970555573701859\n",
      "Step1 : loss = 1.1480149949590366\n",
      "Step2 : loss = 1.050566350420316\n",
      "Step3 : loss = 0.9757947226365408\n",
      "Step4 : loss = 0.8940012951691946\n",
      "Step5 : loss = 0.8437481559813023\n",
      "Step6 : loss = 0.7996718486150106\n",
      "Step7 : loss = 0.7546354619165262\n",
      "Step8 : loss = 0.719060925145944\n",
      "Step9 : loss = 0.6908223479986191\n",
      "Data stream Batch- 5 : loss = 1.4588292837142944\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.29387654821196246\n",
      "Step 1 : loss = 0.2721902823666968\n",
      "Step 2 : loss = 0.2512367439323238\n",
      "Step 3 : loss = 0.2322623163313856\n",
      "Step 4 : loss = 0.213206373858783\n",
      "Step 5 : loss = 0.19483905580367833\n",
      "Step 6 : loss = 0.17958406416019276\n",
      "Step 7 : loss = 0.16684318576599397\n",
      "Step 8 : loss = 0.15544957428993214\n",
      "Step 9 : loss = 0.1461368839714735\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9882410594395229\n",
      "Step1 : loss = 0.816006920167378\n",
      "Step2 : loss = 0.7211910294634956\n",
      "Step3 : loss = 0.6506614621196475\n",
      "Step4 : loss = 0.6058264353445598\n",
      "Step5 : loss = 0.6014046221971512\n",
      "Step6 : loss = 0.5856508995805468\n",
      "Step7 : loss = 0.577726851616587\n",
      "Step8 : loss = 0.5665887264268739\n",
      "Step9 : loss = 0.5624255261250904\n",
      "Data stream Batch- 6 : loss = 1.2571541666984558\n",
      "Meta Update\n",
      "Training is starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 0.2757422821744094\n",
      "Step 1 : loss = 0.25787563948108566\n",
      "Step 2 : loss = 0.24049756593174404\n",
      "Step 3 : loss = 0.2245218215953736\n",
      "Step 4 : loss = 0.2093549196090963\n",
      "Step 5 : loss = 0.19475015918354666\n",
      "Step 6 : loss = 0.18132524739596106\n",
      "Step 7 : loss = 0.16876300076939282\n",
      "Step 8 : loss = 0.15839190204879122\n",
      "Step 9 : loss = 0.1497256402783687\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9736798405647278\n",
      "Step1 : loss = 0.728033360093832\n",
      "Step2 : loss = 0.671519422903657\n",
      "Step3 : loss = 0.6155049242079258\n",
      "Step4 : loss = 0.6120950728654861\n",
      "Step5 : loss = 0.5948522035032511\n",
      "Step6 : loss = 0.5958202313631773\n",
      "Step7 : loss = 0.5941518768668175\n",
      "Step8 : loss = 0.5989803746342659\n",
      "Step9 : loss = 0.602681452408433\n",
      "Data stream Batch- 7 : loss = 1.2190878093242645\n",
      "Task  8\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.12417623749860222\n",
      "Step 1 : loss = 0.11565122455099805\n",
      "Step 2 : loss = 0.11606436191858457\n",
      "Step 3 : loss = 0.11677090138204337\n",
      "Step 4 : loss = 0.11540094670314816\n",
      "Step 5 : loss = 0.11562972362485847\n",
      "Step 6 : loss = 0.11483874295261644\n",
      "Step 7 : loss = 0.11474479646569798\n",
      "Step 8 : loss = 0.11420129194101762\n",
      "Step 9 : loss = 0.11356350419237204\n",
      "Update Procedure\n",
      "Step0 : loss = 2.835843086242676\n",
      "Step1 : loss = 2.708510160446167\n",
      "Step2 : loss = 2.5836400985717773\n",
      "Step3 : loss = 2.462663173675537\n",
      "Step4 : loss = 2.347874879837036\n",
      "Step5 : loss = 2.2375311851501465\n",
      "Step6 : loss = 2.1291961669921875\n",
      "Step7 : loss = 2.0270652770996094\n",
      "Step8 : loss = 1.931486964225769\n",
      "Step9 : loss = 1.8491320610046387\n",
      "Data stream Batch- 0 : loss = 3.204349994659424\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.16135920107601182\n",
      "Step 1 : loss = 0.13247542615447724\n",
      "Step 2 : loss = 0.1159668346748702\n",
      "Step 3 : loss = 0.11034783635672832\n",
      "Step 4 : loss = 0.1120273008085196\n",
      "Step 5 : loss = 0.11135285522286144\n",
      "Step 6 : loss = 0.11054690086711494\n",
      "Step 7 : loss = 0.11032613091141222\n",
      "Step 8 : loss = 0.11021986267721606\n",
      "Step 9 : loss = 0.10932355062548249\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3112691044807434\n",
      "Step1 : loss = 2.1120084524154663\n",
      "Step2 : loss = 1.9435292482376099\n",
      "Step3 : loss = 1.7955315709114075\n",
      "Step4 : loss = 1.6751434803009033\n",
      "Step5 : loss = 1.5707931518554688\n",
      "Step6 : loss = 1.4793330430984497\n",
      "Step7 : loss = 1.401440143585205\n",
      "Step8 : loss = 1.3343506455421448\n",
      "Step9 : loss = 1.2776844501495361\n",
      "Data stream Batch- 1 : loss = 2.20704448223114\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.11036795578483079\n",
      "Step 1 : loss = 0.10483216386702325\n",
      "Step 2 : loss = 0.11056025100960618\n",
      "Step 3 : loss = 0.10430982069127144\n",
      "Step 4 : loss = 0.10975447640059487\n",
      "Step 5 : loss = 0.10370198777980275\n",
      "Step 6 : loss = 0.10870322457085999\n",
      "Step 7 : loss = 0.10325898853914132\n",
      "Step 8 : loss = 0.10807572940867098\n",
      "Step 9 : loss = 0.1029006532969929\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4801781177520752\n",
      "Step1 : loss = 1.334901253382365\n",
      "Step2 : loss = 1.2251784801483154\n",
      "Step3 : loss = 1.1376146872838337\n",
      "Step4 : loss = 1.063905119895935\n",
      "Step5 : loss = 1.0001958807309468\n",
      "Step6 : loss = 0.9414026538530985\n",
      "Step7 : loss = 0.8875739773114523\n",
      "Step8 : loss = 0.83876633644104\n",
      "Step9 : loss = 0.7946486175060272\n",
      "Data stream Batch- 2 : loss = 1.674979418516159\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.23996580521620456\n",
      "Step 1 : loss = 0.19228200497667466\n",
      "Step 2 : loss = 0.15453524769002955\n",
      "Step 3 : loss = 0.1295669656897348\n",
      "Step 4 : loss = 0.11118105660296149\n",
      "Step 5 : loss = 0.10304125540904582\n",
      "Step 6 : loss = 0.10776226728385876\n",
      "Step 7 : loss = 0.10328205734313954\n",
      "Step 8 : loss = 0.10696110200018637\n",
      "Step 9 : loss = 0.10360871580621553\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9991562366485596\n",
      "Step1 : loss = 0.8875414431095123\n",
      "Step2 : loss = 0.8000501021742821\n",
      "Step3 : loss = 0.791669525206089\n",
      "Step4 : loss = 0.7928515002131462\n",
      "Step5 : loss = 0.7694040648639202\n",
      "Step6 : loss = 0.7498170249164104\n",
      "Step7 : loss = 0.7320759370923042\n",
      "Step8 : loss = 0.7090743333101273\n",
      "Step9 : loss = 0.6945233643054962\n",
      "Data stream Batch- 3 : loss = 1.8612937331199646\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.22474066907510398\n",
      "Step 1 : loss = 0.18264466721623662\n",
      "Step 2 : loss = 0.14761439863119333\n",
      "Step 3 : loss = 0.1168282338787639\n",
      "Step 4 : loss = 0.10488067562322295\n",
      "Step 5 : loss = 0.10397497428255895\n",
      "Step 6 : loss = 0.10485160393374307\n",
      "Step 7 : loss = 0.10365882326094877\n",
      "Step 8 : loss = 0.10407753783677305\n",
      "Step 9 : loss = 0.10334908702957725\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2687107801437378\n",
      "Step1 : loss = 1.1558626651763917\n",
      "Step2 : loss = 1.1354660928249358\n",
      "Step3 : loss = 1.1085730731487273\n",
      "Step4 : loss = 1.0878740578889847\n",
      "Step5 : loss = 1.0647843390703202\n",
      "Step6 : loss = 1.0500419408082962\n",
      "Step7 : loss = 1.0392934799194335\n",
      "Step8 : loss = 1.0260681003332137\n",
      "Step9 : loss = 1.0144233345985412\n",
      "Data stream Batch- 4 : loss = 1.9408360719680786\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.14278443334772\n",
      "Step 1 : loss = 0.1160977072806822\n",
      "Step 2 : loss = 0.10640324352989121\n",
      "Step 3 : loss = 0.1053272696064105\n",
      "Step 4 : loss = 0.10511955207302456\n",
      "Step 5 : loss = 0.10438341343745826\n",
      "Step 6 : loss = 0.10453732325325883\n",
      "Step 7 : loss = 0.10363387278177671\n",
      "Step 8 : loss = 0.10398142308528935\n",
      "Step 9 : loss = 0.1030173744400224\n",
      "Update Procedure\n",
      "Step0 : loss = 1.235947459936142\n",
      "Step1 : loss = 1.0502668594320614\n",
      "Step2 : loss = 0.9734582354625066\n",
      "Step3 : loss = 0.9198009396592776\n",
      "Step4 : loss = 0.9219628497958183\n",
      "Step5 : loss = 0.9081178605556488\n",
      "Step6 : loss = 0.8929020240902901\n",
      "Step7 : loss = 0.884125883380572\n",
      "Step8 : loss = 0.875108835597833\n",
      "Step9 : loss = 0.8669022669394811\n",
      "Data stream Batch- 5 : loss = 1.9784057438373566\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.21199492813634968\n",
      "Step 1 : loss = 0.18158499165068542\n",
      "Step 2 : loss = 0.15249598993520652\n",
      "Step 3 : loss = 0.13062826972750444\n",
      "Step 4 : loss = 0.1197865803799932\n",
      "Step 5 : loss = 0.11443999214541345\n",
      "Step 6 : loss = 0.10780273894114153\n",
      "Step 7 : loss = 0.10098601465098678\n",
      "Step 8 : loss = 0.10280345352957883\n",
      "Step 9 : loss = 0.10019631875856291\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6125171950885229\n",
      "Step1 : loss = 1.345428547688893\n",
      "Step2 : loss = 1.3444766785417284\n",
      "Step3 : loss = 1.285774371453694\n",
      "Step4 : loss = 1.2530771110739027\n",
      "Step5 : loss = 1.2379042293344225\n",
      "Step6 : loss = 1.2131489195993967\n",
      "Step7 : loss = 1.1895717680454254\n",
      "Step8 : loss = 1.171434223651886\n",
      "Step9 : loss = 1.1574710926839284\n",
      "Data stream Batch- 6 : loss = 1.8449980914592743\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2471803426683422\n",
      "Step 1 : loss = 0.20979480363192066\n",
      "Step 2 : loss = 0.17951292951133044\n",
      "Step 3 : loss = 0.15248917518331417\n",
      "Step 4 : loss = 0.13464154411876011\n",
      "Step 5 : loss = 0.12534630033113653\n",
      "Step 6 : loss = 0.11972464344331196\n",
      "Step 7 : loss = 0.11004898591292282\n",
      "Step 8 : loss = 0.1035444216418361\n",
      "Step 9 : loss = 0.0992837697031006\n",
      "Update Procedure\n",
      "Step0 : loss = 1.9478935077786446\n",
      "Step1 : loss = 1.7206154484301805\n",
      "Step2 : loss = 1.656040795147419\n",
      "Step3 : loss = 1.6185316480696201\n",
      "Step4 : loss = 1.5856756009161472\n",
      "Step5 : loss = 1.5642800144851208\n",
      "Step6 : loss = 1.5458758175373077\n",
      "Step7 : loss = 1.5311316400766373\n",
      "Step8 : loss = 1.5152217000722885\n",
      "Step9 : loss = 1.5002401508390903\n",
      "Data stream Batch- 7 : loss = 1.9381945431232452\n",
      "Task  9\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.581861202933249\n",
      "Step 1 : loss = 0.5641673812539213\n",
      "Step 2 : loss = 0.548569702337836\n",
      "Step 3 : loss = 0.5348238591385621\n",
      "Step 4 : loss = 0.5227152270353621\n",
      "Step 5 : loss = 0.5119958114618111\n",
      "Step 6 : loss = 0.501013808248062\n",
      "Step 7 : loss = 0.4897073166651858\n",
      "Step 8 : loss = 0.47945666187516756\n",
      "Step 9 : loss = 0.47413143742652164\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3629406690597534\n",
      "Step1 : loss = 1.2309751510620117\n",
      "Step2 : loss = 1.1254165172576904\n",
      "Step3 : loss = 1.039177656173706\n",
      "Step4 : loss = 0.9650934338569641\n",
      "Step5 : loss = 0.8974807262420654\n",
      "Step6 : loss = 0.8391784429550171\n",
      "Step7 : loss = 0.7935986518859863\n",
      "Step8 : loss = 0.7630772590637207\n",
      "Step9 : loss = 0.7437809705734253\n",
      "Data stream Batch- 0 : loss = 1.9764418303966522\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5702501417847261\n",
      "Step 1 : loss = 0.548985293696797\n",
      "Step 2 : loss = 0.5289389539332617\n",
      "Step 3 : loss = 0.5094558654146062\n",
      "Step 4 : loss = 0.49330393134335443\n",
      "Step 5 : loss = 0.48100299650418854\n",
      "Step 6 : loss = 0.4707785994302304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 : loss = 0.4625818371802332\n",
      "Step 8 : loss = 0.45509572825024996\n",
      "Step 9 : loss = 0.4490714547623481\n",
      "Update Procedure\n",
      "Step0 : loss = 1.383564829826355\n",
      "Step1 : loss = 1.1684663593769073\n",
      "Step2 : loss = 0.9819625020027161\n",
      "Step3 : loss = 0.836415559053421\n",
      "Step4 : loss = 0.7360074818134308\n",
      "Step5 : loss = 0.6721525490283966\n",
      "Step6 : loss = 0.6409808397293091\n",
      "Step7 : loss = 0.6474188268184662\n",
      "Step8 : loss = 0.65519118309021\n",
      "Step9 : loss = 0.6495430767536163\n",
      "Data stream Batch- 1 : loss = 1.837805837392807\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.584972095081494\n",
      "Step 1 : loss = 0.5627722612670845\n",
      "Step 2 : loss = 0.5419285779951939\n",
      "Step 3 : loss = 0.5219636083802297\n",
      "Step 4 : loss = 0.5054513093024965\n",
      "Step 5 : loss = 0.4925502183462774\n",
      "Step 6 : loss = 0.47950356129911686\n",
      "Step 7 : loss = 0.4693215039987413\n",
      "Step 8 : loss = 0.45811097741954854\n",
      "Step 9 : loss = 0.4509428987486495\n",
      "Update Procedure\n",
      "Step0 : loss = 1.0971779823303223\n",
      "Step1 : loss = 0.7811175584793091\n",
      "Step2 : loss = 0.5559567511081696\n",
      "Step3 : loss = 0.4912507434686025\n",
      "Step4 : loss = 0.5510072509447733\n",
      "Step5 : loss = 0.5492279628912607\n",
      "Step6 : loss = 0.4875878095626831\n",
      "Step7 : loss = 0.47356758018334705\n",
      "Step8 : loss = 0.4758274555206299\n",
      "Step9 : loss = 0.46190227071444195\n",
      "Data stream Batch- 2 : loss = 2.1221593022346497\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5284841901970111\n",
      "Step 1 : loss = 0.5091480712598515\n",
      "Step 2 : loss = 0.4939633113701665\n",
      "Step 3 : loss = 0.4813179978938211\n",
      "Step 4 : loss = 0.4707455915664988\n",
      "Step 5 : loss = 0.4616656670243376\n",
      "Step 6 : loss = 0.45516781581950094\n",
      "Step 7 : loss = 0.4483736340577404\n",
      "Step 8 : loss = 0.440451332716833\n",
      "Step 9 : loss = 0.43356722593011837\n",
      "Update Procedure\n",
      "Step0 : loss = 1.10916168987751\n",
      "Step1 : loss = 0.728080041706562\n",
      "Step2 : loss = 0.5745160356163979\n",
      "Step3 : loss = 0.6485543698072433\n",
      "Step4 : loss = 0.6158752143383026\n",
      "Step5 : loss = 0.572529561817646\n",
      "Step6 : loss = 0.5705297850072384\n",
      "Step7 : loss = 0.553560197353363\n",
      "Step8 : loss = 0.5328356474637985\n",
      "Step9 : loss = 0.5359492897987366\n",
      "Data stream Batch- 3 : loss = 2.1534513235092163\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5288949274635386\n",
      "Step 1 : loss = 0.5070103132653804\n",
      "Step 2 : loss = 0.4875442797768979\n",
      "Step 3 : loss = 0.47230604471165744\n",
      "Step 4 : loss = 0.4607935446802349\n",
      "Step 5 : loss = 0.4508967231722578\n",
      "Step 6 : loss = 0.442679229321047\n",
      "Step 7 : loss = 0.4353180576633248\n",
      "Step 8 : loss = 0.42955286312582236\n",
      "Step 9 : loss = 0.4242510666390733\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3983722567558288\n",
      "Step1 : loss = 0.9875468254089356\n",
      "Step2 : loss = 0.9940153121948242\n",
      "Step3 : loss = 1.0024757981300354\n",
      "Step4 : loss = 0.9837838292121888\n",
      "Step5 : loss = 0.9447348058223725\n",
      "Step6 : loss = 0.919151109457016\n",
      "Step7 : loss = 0.905230262875557\n",
      "Step8 : loss = 0.8873071223497391\n",
      "Step9 : loss = 0.8690139770507812\n",
      "Data stream Batch- 4 : loss = 2.265940308570862\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5327704817426229\n",
      "Step 1 : loss = 0.5115123862252822\n",
      "Step 2 : loss = 0.4911343813356426\n",
      "Step 3 : loss = 0.47333400867701997\n",
      "Step 4 : loss = 0.46154734420604887\n",
      "Step 5 : loss = 0.4498730802302441\n",
      "Step 6 : loss = 0.4399276125850895\n",
      "Step 7 : loss = 0.43146245111785236\n",
      "Step 8 : loss = 0.4233489682336175\n",
      "Step 9 : loss = 0.4172930118524366\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6328725914160411\n",
      "Step1 : loss = 1.1618553549051285\n",
      "Step2 : loss = 1.0359148532152176\n",
      "Step3 : loss = 0.9389544973770777\n",
      "Step4 : loss = 0.8265585054953893\n",
      "Step5 : loss = 0.798012355963389\n",
      "Step6 : loss = 0.7788544123371443\n",
      "Step7 : loss = 0.7550343871116638\n",
      "Step8 : loss = 0.7432060837745667\n",
      "Step9 : loss = 0.7468185126781464\n",
      "Data stream Batch- 5 : loss = 2.2241976857185364\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5324914624493214\n",
      "Step 1 : loss = 0.5111417144086093\n",
      "Step 2 : loss = 0.49086183144651824\n",
      "Step 3 : loss = 0.47296119989413354\n",
      "Step 4 : loss = 0.4599632542713412\n",
      "Step 5 : loss = 0.4490562663812723\n",
      "Step 6 : loss = 0.43955506345789347\n",
      "Step 7 : loss = 0.4313447478981245\n",
      "Step 8 : loss = 0.42518969444439764\n",
      "Step 9 : loss = 0.41822249129237166\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5280378546033586\n",
      "Step1 : loss = 1.203430371625083\n",
      "Step2 : loss = 1.1239133988107954\n",
      "Step3 : loss = 1.0652352103165217\n",
      "Step4 : loss = 1.033393817288535\n",
      "Step5 : loss = 1.0200172407286507\n",
      "Step6 : loss = 1.0047308845179421\n",
      "Step7 : loss = 0.9941237909453255\n",
      "Step8 : loss = 0.9845256954431534\n",
      "Step9 : loss = 0.9762631569589887\n",
      "Data stream Batch- 6 : loss = 2.07733553647995\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5113253286463164\n",
      "Step 1 : loss = 0.4896014698086277\n",
      "Step 2 : loss = 0.4711190975951179\n",
      "Step 3 : loss = 0.4588637111531127\n",
      "Step 4 : loss = 0.4466991591622077\n",
      "Step 5 : loss = 0.4372009835117275\n",
      "Step 6 : loss = 0.4263981695700851\n",
      "Step 7 : loss = 0.4195641145080565\n",
      "Step 8 : loss = 0.41200240969746593\n",
      "Step 9 : loss = 0.40586991242413956\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7114003524184227\n",
      "Step1 : loss = 1.4243672862648964\n",
      "Step2 : loss = 1.3350380510091782\n",
      "Step3 : loss = 1.2856679297983646\n",
      "Step4 : loss = 1.2593206856399775\n",
      "Step5 : loss = 1.2433776296675205\n",
      "Step6 : loss = 1.2367788013070822\n",
      "Step7 : loss = 1.2242712546139956\n",
      "Step8 : loss = 1.2166789583861828\n",
      "Step9 : loss = 1.2099787704646587\n",
      "Data stream Batch- 7 : loss = 2.076237976551056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml2 = []\n",
    "total = []\n",
    "all_eval_loss2 = []\n",
    "all_train_loss2 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval2 = []\n",
    "ftml_time2 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "    if len(xtask_buffer) >= 24:\n",
    "        xtask_buffer = xtask_buffer[8:]\n",
    "        ttask_buffer = ttask_buffer[8:] \n",
    "\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        ftml2, loss = train_maml(ftml2, meta_step, dtrainx, dtraint, dvalx, dvalt)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml2, loss = update_procedure(ftml2,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml2, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time2.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval2.append(eval_loss)\n",
    "    all_train_loss2.append(train_loss)\n",
    "    all_eval_loss2.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval2)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(xtask_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task  0\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 6.794506072998047\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 6.734601974487305\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 6.678582191467285\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 6.629990100860596\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 6.5940775871276855\n",
      "0.0005\n",
      "Step 5 : loss = 6.569159030914307\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 6.551370620727539\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 6.539508819580078\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 6.532509803771973\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 6.5293097496032715\n",
      "Update Procedure\n",
      "Step0 : loss = 6.531161308288574\n",
      "Step1 : loss = 6.4991960525512695\n",
      "Step2 : loss = 6.470890522003174\n",
      "Step3 : loss = 6.443951606750488\n",
      "Step4 : loss = 6.41750955581665\n",
      "Step5 : loss = 6.391589164733887\n",
      "Step6 : loss = 6.365701198577881\n",
      "Step7 : loss = 6.34036922454834\n",
      "Step8 : loss = 6.316097259521484\n",
      "Step9 : loss = 6.2918243408203125\n",
      "Data stream Batch- 0 : loss = 4.715235233306885\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 6.703449726104736\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 6.6764562129974365\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 6.649909496307373\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 6.626047134399414\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 6.604222297668457\n",
      "0.0005\n",
      "Step 5 : loss = 6.586294889450073\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 6.572530269622803\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 6.562727689743042\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 6.556861877441406\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 6.55413818359375\n",
      "Update Procedure\n",
      "Step0 : loss = 6.544977188110352\n",
      "Step1 : loss = 6.488017320632935\n",
      "Step2 : loss = 6.429309844970703\n",
      "Step3 : loss = 6.368526935577393\n",
      "Step4 : loss = 6.305107831954956\n",
      "Step5 : loss = 6.239043235778809\n",
      "Step6 : loss = 6.169896125793457\n",
      "Step7 : loss = 6.097455263137817\n",
      "Step8 : loss = 6.0214807987213135\n",
      "Step9 : loss = 5.941791534423828\n",
      "Data stream Batch- 1 : loss = 4.523996472358704\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 6.739015102386475\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 6.707339604695638\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 6.675759951273601\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 6.645769913991292\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 6.618729114532471\n",
      "0.0005\n",
      "Step 5 : loss = 6.595805724461873\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 6.577816963195801\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 6.565206209818522\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 6.557605266571045\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 6.554063479105632\n",
      "Update Procedure\n",
      "Step0 : loss = 8.419134616851807\n",
      "Step1 : loss = 8.291539192199707\n",
      "Step2 : loss = 8.162446816762289\n",
      "Step3 : loss = 8.026959896087646\n",
      "Step4 : loss = 7.884428024291992\n",
      "Step5 : loss = 7.733734289805095\n",
      "Step6 : loss = 7.57487694422404\n",
      "Step7 : loss = 7.407872994740804\n",
      "Step8 : loss = 7.231120904286702\n",
      "Step9 : loss = 7.043879111607869\n",
      "Data stream Batch- 2 : loss = 3.9885365962982178\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 3.2855107684930163\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 3.260895262161891\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 3.236797859271367\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 3.2143938541412354\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 3.194948772589366\n",
      "0.0005\n",
      "Step 5 : loss = 3.1789083182811737\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 3.1666331191857653\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 3.1581742266813917\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 3.1531255145867663\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 3.1508601506551104\n",
      "Update Procedure\n",
      "Step0 : loss = 6.82785964012146\n",
      "Step1 : loss = 6.630963206291199\n",
      "Step2 : loss = 6.447665512561798\n",
      "Step3 : loss = 6.259222090244293\n",
      "Step4 : loss = 6.062961101531982\n",
      "Step5 : loss = 5.865234911441803\n",
      "Step6 : loss = 5.673451542854309\n",
      "Step7 : loss = 5.482932806015015\n",
      "Step8 : loss = 5.292613506317139\n",
      "Step9 : loss = 5.109678745269775\n",
      "Data stream Batch- 3 : loss = 3.130429267883301\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 2.7812271237373354\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 2.7495446622371675\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 2.7195067803064985\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 2.692188447713852\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 2.6685212651888532\n",
      "0.0005\n",
      "Step 5 : loss = 2.6491411924362183\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 2.634441121419271\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 2.6242672204971313\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 2.6182139297326406\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 2.615404748916626\n",
      "Update Procedure\n",
      "Step0 : loss = 5.968295764923096\n",
      "Step1 : loss = 5.724769115447998\n",
      "Step2 : loss = 5.5051854133605955\n",
      "Step3 : loss = 5.287071609497071\n",
      "Step4 : loss = 5.0705029487609865\n",
      "Step5 : loss = 4.854212832450867\n",
      "Step6 : loss = 4.651916742324829\n",
      "Step7 : loss = 4.470846128463745\n",
      "Step8 : loss = 4.305089998245239\n",
      "Step9 : loss = 4.151684904098511\n",
      "Data stream Batch- 4 : loss = 2.3638936281204224\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.7243608246246973\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.718387497464816\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.7127522698707052\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.7077142669094931\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.7034894973039627\n",
      "0.0005\n",
      "Step 5 : loss = 1.700186767180761\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.6977565609746508\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.6961161515778966\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.6951522467864883\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.694706052210596\n",
      "Update Procedure\n",
      "Step0 : loss = 4.613670905431111\n",
      "Step1 : loss = 4.457334031661351\n",
      "Step2 : loss = 4.325741539398829\n",
      "Step3 : loss = 4.1983736256758375\n",
      "Step4 : loss = 4.076780120531718\n",
      "Step5 : loss = 3.948070893685023\n",
      "Step6 : loss = 3.810793807109197\n",
      "Step7 : loss = 3.6740164260069528\n",
      "Step8 : loss = 3.547379265228907\n",
      "Step9 : loss = 3.431226740280787\n",
      "Data stream Batch- 5 : loss = 2.0515264868736267\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.9514828782824296\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.9468482695992977\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.9424043364349811\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.938394937203044\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.9350410977999369\n",
      "0.0005\n",
      "Step 5 : loss = 0.9323676938338885\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.9303710320166179\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.92901350278703\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.9282122354304033\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.9278474875267536\n",
      "Update Procedure\n",
      "Step0 : loss = 3.5684537206377303\n",
      "Step1 : loss = 3.4562728149550304\n",
      "Step2 : loss = 3.3652415445872714\n",
      "Step3 : loss = 3.2851395436695645\n",
      "Step4 : loss = 3.207117042371205\n",
      "Step5 : loss = 3.128530983413969\n",
      "Step6 : loss = 3.0505776533058713\n",
      "Step7 : loss = 2.9734563997813632\n",
      "Step8 : loss = 2.897077645574297\n",
      "Step9 : loss = 2.825259191649301\n",
      "Data stream Batch- 6 : loss = 2.2314711809158325\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.48639750144267013\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.4811156972488832\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.4760385244316052\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.47140557206723666\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.46738825020572494\n",
      "0.0005\n",
      "Step 5 : loss = 0.46406695493718697\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.4615359063467218\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.4597955469958602\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.45875678511839063\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.45827521416580397\n",
      "Update Procedure\n",
      "Step0 : loss = 2.887936256825924\n",
      "Step1 : loss = 2.730286754667759\n",
      "Step2 : loss = 2.66166552901268\n",
      "Step3 : loss = 2.5941591933369637\n",
      "Step4 : loss = 2.5267509445548058\n",
      "Step5 : loss = 2.4593608379364014\n",
      "Step6 : loss = 2.3994961343705654\n",
      "Step7 : loss = 2.324465971440077\n",
      "Step8 : loss = 2.2553743682801723\n",
      "Step9 : loss = 2.173592336475849\n",
      "Data stream Batch- 7 : loss = 2.1424407958984375\n",
      "Task  1\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.260810136795044\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.2407920062541962\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.221203257640203\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.2040416498978934\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.189502944548925\n",
      "0.0005\n",
      "Step 5 : loss = 1.1775438686211905\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.1690208514531455\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.1635231375694275\n",
      "9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 : loss = 1.1603894929091134\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.1589402258396149\n",
      "Update Procedure\n",
      "Step0 : loss = 2.71284818649292\n",
      "Step1 : loss = 2.5534467697143555\n",
      "Step2 : loss = 2.4062061309814453\n",
      "Step3 : loss = 2.273728370666504\n",
      "Step4 : loss = 2.147636651992798\n",
      "Step5 : loss = 2.026538133621216\n",
      "Step6 : loss = 1.913691520690918\n",
      "Step7 : loss = 1.8165512084960938\n",
      "Step8 : loss = 1.7365942001342773\n",
      "Step9 : loss = 1.6689091920852661\n",
      "Data stream Batch- 0 : loss = 11.63611888885498\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.1381894747416177\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.1238688627878823\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.1102077662944794\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0973077913125358\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.0859736700852713\n",
      "0.0005\n",
      "Step 5 : loss = 1.0765395363171897\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.0693852404753366\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.0644482374191284\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.0615247388680777\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.0601347486178079\n",
      "Update Procedure\n",
      "Step0 : loss = 2.908575654029846\n",
      "Step1 : loss = 2.7548308968544006\n",
      "Step2 : loss = 2.699065625667572\n",
      "Step3 : loss = 2.671800911426544\n",
      "Step4 : loss = 2.638423979282379\n",
      "Step5 : loss = 2.595758318901062\n",
      "Step6 : loss = 2.550525724887848\n",
      "Step7 : loss = 2.512317419052124\n",
      "Step8 : loss = 2.4805644750595093\n",
      "Step9 : loss = 2.4581704139709473\n",
      "Data stream Batch- 1 : loss = 11.552879810333252\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.0802205701669059\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.0656095743179321\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.0514476398626962\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0384232699871063\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.026943564414978\n",
      "0.0005\n",
      "Step 5 : loss = 1.0174971520900726\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.0102694829305015\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.0053104360898337\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.0024276475111642\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.0010694762070975\n",
      "Update Procedure\n",
      "Step0 : loss = 3.065418243408203\n",
      "Step1 : loss = 2.9237558046976724\n",
      "Step2 : loss = 2.8419686555862427\n",
      "Step3 : loss = 2.779333472251892\n",
      "Step4 : loss = 2.719902515411377\n",
      "Step5 : loss = 2.6646827856699624\n",
      "Step6 : loss = 2.6153355836868286\n",
      "Step7 : loss = 2.568809429804484\n",
      "Step8 : loss = 2.5224873622258506\n",
      "Step9 : loss = 2.4792827367782593\n",
      "Data stream Batch- 2 : loss = 11.555121898651123\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.069572945435842\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.052605758110682\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.036302944024404\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0223373274008432\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.010228137175242\n",
      "0.0005\n",
      "Step 5 : loss = 1.0004939138889313\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.9931788345177969\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.988209197918574\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.985303113857905\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.9839690625667572\n",
      "Update Procedure\n",
      "Step0 : loss = 2.4364538490772247\n",
      "Step1 : loss = 2.3032001554965973\n",
      "Step2 : loss = 2.239210456609726\n",
      "Step3 : loss = 2.1777992248535156\n",
      "Step4 : loss = 2.126037120819092\n",
      "Step5 : loss = 2.080959439277649\n",
      "Step6 : loss = 2.036793142557144\n",
      "Step7 : loss = 1.999081939458847\n",
      "Step8 : loss = 1.967204600572586\n",
      "Step9 : loss = 1.9383905231952667\n",
      "Data stream Batch- 3 : loss = 11.591277122497559\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.059378077586492\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.0433763762315116\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.0275609890619912\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0128409961859384\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.0004836916923523\n",
      "0.0005\n",
      "Step 5 : loss = 0.9900819758574168\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.9822215537230173\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.9767980873584747\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.973590075969696\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.9720959961414337\n",
      "Update Procedure\n",
      "Step0 : loss = 2.3233077049255373\n",
      "Step1 : loss = 2.21243577003479\n",
      "Step2 : loss = 2.1640985012054443\n",
      "Step3 : loss = 2.100329613685608\n",
      "Step4 : loss = 2.0519967555999754\n",
      "Step5 : loss = 2.0045718431472777\n",
      "Step6 : loss = 1.9669046640396117\n",
      "Step7 : loss = 1.9387710094451904\n",
      "Step8 : loss = 1.9075672626495361\n",
      "Step9 : loss = 1.8766811847686768\n",
      "Data stream Batch- 4 : loss = 11.617542743682861\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.1071242491404214\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.0892292757829032\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.0721347530682883\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0562543869018555\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.0422803362210593\n",
      "0.0005\n",
      "Step 5 : loss = 1.030687222878138\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.0218972961107888\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.015811582406362\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.0122711459795632\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.0106240510940552\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9923584858576455\n",
      "Step1 : loss = 3.9320332407951355\n",
      "Step2 : loss = 3.8690300782521567\n",
      "Step3 : loss = 3.8297821482022605\n",
      "Step4 : loss = 3.7830853859583535\n",
      "Step5 : loss = 3.7544851899147034\n",
      "Step6 : loss = 3.725762923558553\n",
      "Step7 : loss = 3.695495307445526\n",
      "Step8 : loss = 3.664072851339976\n",
      "Step9 : loss = 3.6368271509806314\n",
      "Data stream Batch- 5 : loss = 11.360066890716553\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.0669960776964822\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.0454582373301187\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.0257595678170524\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.0092016458511353\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.9950243731339773\n",
      "0.0005\n",
      "Step 5 : loss = 0.9834992488225301\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.9747872054576874\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.9687673846880595\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.9651826818784078\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.9635190864404043\n",
      "Update Procedure\n",
      "Step0 : loss = 4.983807069914682\n",
      "Step1 : loss = 4.937022124017988\n",
      "Step2 : loss = 4.839659333229065\n",
      "Step3 : loss = 4.792398912566049\n",
      "Step4 : loss = 4.743797506604876\n",
      "Step5 : loss = 4.700990097863333\n",
      "Step6 : loss = 4.658737625394549\n",
      "Step7 : loss = 4.604742339679173\n",
      "Step8 : loss = 4.5576417446136475\n",
      "Step9 : loss = 4.506258640970502\n",
      "Data stream Batch- 6 : loss = 10.676126956939697\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.9675272206465403\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.9436550935109457\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.9206348558266958\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.900339295466741\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.8848889768123627\n",
      "0.0005\n",
      "Step 5 : loss = 0.8733664552370707\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.8650105396906534\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.8593282004197439\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.8559426863988241\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.8543815612792969\n",
      "Update Procedure\n",
      "Step0 : loss = 5.369797334074974\n",
      "Step1 : loss = 5.293597161769867\n",
      "Step2 : loss = 5.191775396466255\n",
      "Step3 : loss = 5.100896954536438\n",
      "Step4 : loss = 5.022307053208351\n",
      "Step5 : loss = 4.93757189065218\n",
      "Step6 : loss = 4.84209306538105\n",
      "Step7 : loss = 4.746515117585659\n",
      "Step8 : loss = 4.642036385834217\n",
      "Step9 : loss = 4.532757945358753\n",
      "Data stream Batch- 7 : loss = 8.97991132736206\n",
      "Task  2\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.3644441108662813\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.3541438148475238\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.344003150688987\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.3345023109001064\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.3260825007961738\n",
      "0.0005\n",
      "Step 5 : loss = 1.3190912826799803\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.3137201517332522\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.3100262586086515\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.3077972600325232\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.3067631859613198\n",
      "Update Procedure\n",
      "Step0 : loss = 4.382352352142334\n",
      "Step1 : loss = 4.086559295654297\n",
      "Step2 : loss = 3.7976303100585938\n",
      "Step3 : loss = 3.5166571140289307\n",
      "Step4 : loss = 3.242269515991211\n",
      "Step5 : loss = 2.9744741916656494\n",
      "Step6 : loss = 2.7168338298797607\n",
      "Step7 : loss = 2.4737091064453125\n",
      "Step8 : loss = 2.2620813846588135\n",
      "Step9 : loss = 2.0908379554748535\n",
      "Data stream Batch- 0 : loss = 2.6821038722991943\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 1.326944844829776\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.316296955481881\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.3057268001523519\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.295947993316111\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.2871840530178613\n",
      "0.0005\n",
      "Step 5 : loss = 1.2799401379234734\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.274403714761138\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.2705285483852975\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.2682105687550373\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.267149457258601\n",
      "Update Procedure\n",
      "Step0 : loss = 4.493069410324097\n",
      "Step1 : loss = 4.300675868988037\n",
      "Step2 : loss = 4.158586382865906\n",
      "Step3 : loss = 4.063423216342926\n",
      "Step4 : loss = 3.9753854274749756\n",
      "Step5 : loss = 3.8729814291000366\n",
      "Step6 : loss = 3.762380540370941\n",
      "Step7 : loss = 3.659571588039398\n",
      "Step8 : loss = 3.5767518281936646\n",
      "Step9 : loss = 3.4895235300064087\n",
      "Data stream Batch- 1 : loss = 2.7101744413375854\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.212369455805137\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.2005959503411774\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.1889173380439244\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.1780029920565467\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 1.1683202914775364\n",
      "0.0005\n",
      "Step 5 : loss = 1.16030820405909\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 1.1541761296786486\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 1.1498954448257648\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 1.1473348554105514\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 1.146164511566952\n",
      "Update Procedure\n",
      "Step0 : loss = 3.7119139035542807\n",
      "Step1 : loss = 3.456355333328247\n",
      "Step2 : loss = 3.2573179801305137\n",
      "Step3 : loss = 3.082091768582662\n",
      "Step4 : loss = 2.9199323256810508\n",
      "Step5 : loss = 2.75074569384257\n",
      "Step6 : loss = 2.571230411529541\n",
      "Step7 : loss = 2.389076550801595\n",
      "Step8 : loss = 2.2116103967030845\n",
      "Step9 : loss = 2.0323264996210733\n",
      "Data stream Batch- 2 : loss = 2.6519616842269897\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 1.0484987255540632\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 1.0351169022480173\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 1.0218941048615509\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 1.009542274557882\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.9985949216144425\n",
      "0.0005\n",
      "Step 5 : loss = 0.9895889891814145\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.9826414002608213\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.9778088198176452\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.9749186708222306\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.9735775160233653\n",
      "Update Procedure\n",
      "Step0 : loss = 1.9371793568134308\n",
      "Step1 : loss = 1.6876194775104523\n",
      "Step2 : loss = 1.555747613310814\n",
      "Step3 : loss = 1.4836887866258621\n",
      "Step4 : loss = 1.4350672662258148\n",
      "Step5 : loss = 1.3930379152297974\n",
      "Step6 : loss = 1.3489948064088821\n",
      "Step7 : loss = 1.3040702193975449\n",
      "Step8 : loss = 1.2611231058835983\n",
      "Step9 : loss = 1.222392961382866\n",
      "Data stream Batch- 3 : loss = 2.5950742959976196\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.9366178707234443\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.9221882517139117\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.9080325473868658\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.894809804850864\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.8830447575580033\n",
      "0.0005\n",
      "Step 5 : loss = 0.8733020239820083\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.8658272245751014\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.8606290235405877\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.85752062731319\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.8561374867305396\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6016719102859498\n",
      "Step1 : loss = 1.303887629508972\n",
      "Step2 : loss = 1.290633249282837\n",
      "Step3 : loss = 1.2674850940704345\n",
      "Step4 : loss = 1.223840856552124\n",
      "Step5 : loss = 1.1883179426193238\n",
      "Step6 : loss = 1.1646450877189636\n",
      "Step7 : loss = 1.1364970684051514\n",
      "Step8 : loss = 1.112931227684021\n",
      "Step9 : loss = 1.0957378268241882\n",
      "Data stream Batch- 4 : loss = 2.550400733947754\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.8762294269092972\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.8612160124949046\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.8465354636429794\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.8327367458255991\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.8205529903194734\n",
      "0.0005\n",
      "Step 5 : loss = 0.8104478295419424\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.8026594257070905\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.7972750741574499\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.7941789964361796\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.7926827079424309\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7752204338709514\n",
      "Step1 : loss = 1.4652557174364726\n",
      "Step2 : loss = 1.4353496929009755\n",
      "Step3 : loss = 1.3626755972703297\n",
      "Step4 : loss = 1.3179925282796223\n",
      "Step5 : loss = 1.266292542219162\n",
      "Step6 : loss = 1.224658191204071\n",
      "Step7 : loss = 1.1831823388735454\n",
      "Step8 : loss = 1.1437187890211742\n",
      "Step9 : loss = 1.103225847085317\n",
      "Data stream Batch- 5 : loss = 1.1065012216567993\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.8083642538282133\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.7927829052070303\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.7774639632316336\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.7631839839120705\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.7504859790146824\n",
      "0.0005\n",
      "Step 5 : loss = 0.7400430839508771\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.7319907447825822\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.7264368670918638\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.723082479071759\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.7215715922592651\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5223619767597742\n",
      "Step1 : loss = 1.214269825390407\n",
      "Step2 : loss = 1.1540111814226424\n",
      "Step3 : loss = 1.0879509789603097\n",
      "Step4 : loss = 1.0351909143584115\n",
      "Step5 : loss = 0.9924310786383492\n",
      "Step6 : loss = 0.9536769560405186\n",
      "Step7 : loss = 0.9248492462294442\n",
      "Step8 : loss = 0.9048483201435634\n",
      "Step9 : loss = 0.8890541451317924\n",
      "Data stream Batch- 6 : loss = 1.2387288212776184\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.7322288194346049\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.715986063159884\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.699972386965676\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.6849625959341962\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.6716661610596236\n",
      "0.0005\n",
      "Step 5 : loss = 0.6606663232639668\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.652230037689682\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.6463638898872194\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.6428574993437718\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.6412311655720548\n",
      "Update Procedure\n",
      "Step0 : loss = 1.1058630347251892\n",
      "Step1 : loss = 0.9443210884928703\n",
      "Step2 : loss = 0.8857807591557503\n",
      "Step3 : loss = 0.8654221966862679\n",
      "Step4 : loss = 0.8384030312299728\n",
      "Step5 : loss = 0.8214375227689743\n",
      "Step6 : loss = 0.8072564899921417\n",
      "Step7 : loss = 0.7926570102572441\n",
      "Step8 : loss = 0.7785708867013454\n",
      "Step9 : loss = 0.7649920359253883\n",
      "Data stream Batch- 7 : loss = 0.9497717618942261\n",
      "Task  3\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.052074878441818816\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0482565568854205\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.04860697827968693\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.04805134390145887\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.04771499767601516\n",
      "0.0005\n",
      "Step 5 : loss = 0.04702379052990247\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.04689662942314466\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.046449392184855144\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.046376541670960135\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.046273738021604116\n",
      "Update Procedure\n",
      "Step0 : loss = 8.780684471130371\n",
      "Step1 : loss = 8.591390609741211\n",
      "Step2 : loss = 8.404993057250977\n",
      "Step3 : loss = 8.221181869506836\n",
      "Step4 : loss = 8.040597915649414\n",
      "Step5 : loss = 7.8624467849731445\n",
      "Step6 : loss = 7.687089920043945\n",
      "Step7 : loss = 7.514103412628174\n",
      "Step8 : loss = 7.343289375305176\n",
      "Step9 : loss = 7.174072265625\n",
      "Data stream Batch- 0 : loss = 5.335015773773193\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.061189975174840046\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.05556852344025887\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.05219963662194982\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.04983080689296828\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.048361567440820284\n",
      "0.0005\n",
      "Step 5 : loss = 0.047667330742077636\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.04641075580489514\n",
      "0.00020610737385376348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 : loss = 0.045784968904202\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.045480173205914805\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.04530831766575869\n",
      "Update Procedure\n",
      "Step0 : loss = 6.859816312789917\n",
      "Step1 : loss = 6.611696004867554\n",
      "Step2 : loss = 6.3852550983428955\n",
      "Step3 : loss = 6.170490264892578\n",
      "Step4 : loss = 5.966894626617432\n",
      "Step5 : loss = 5.775838851928711\n",
      "Step6 : loss = 5.620682001113892\n",
      "Step7 : loss = 5.484385013580322\n",
      "Step8 : loss = 5.349892854690552\n",
      "Step9 : loss = 5.216134309768677\n",
      "Data stream Batch- 1 : loss = 4.8422651290893555\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.07352636272657258\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.06619874756386497\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.06037861771368161\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.056347693969771795\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.05369771565653252\n",
      "0.0005\n",
      "Step 5 : loss = 0.05172018026317468\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.050295469967876254\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.04935688537852509\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.04881860635556933\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.04856684303520745\n",
      "Update Procedure\n",
      "Step0 : loss = 4.196694533030192\n",
      "Step1 : loss = 3.9943076769510903\n",
      "Step2 : loss = 3.832848072052002\n",
      "Step3 : loss = 3.704342246055603\n",
      "Step4 : loss = 3.600056807200114\n",
      "Step5 : loss = 3.5089009205500283\n",
      "Step6 : loss = 3.428089658419291\n",
      "Step7 : loss = 3.3520992596944175\n",
      "Step8 : loss = 3.2787718772888184\n",
      "Step9 : loss = 3.208757678667704\n",
      "Data stream Batch- 2 : loss = 4.268336534500122\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.08692268480484007\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.07965359627663593\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.07350186033871631\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.06909659315043488\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.06601119437048378\n",
      "0.0005\n",
      "Step 5 : loss = 0.06320832142308629\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.06115338052274829\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.059792547044701876\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.059017520718381324\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05865752735299578\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5946721136569977\n",
      "Step1 : loss = 2.4608466923236847\n",
      "Step2 : loss = 2.419738382101059\n",
      "Step3 : loss = 2.3572301864624023\n",
      "Step4 : loss = 2.310485638678074\n",
      "Step5 : loss = 2.259779579937458\n",
      "Step6 : loss = 2.207158125936985\n",
      "Step7 : loss = 2.1648155599832535\n",
      "Step8 : loss = 2.1214056313037872\n",
      "Step9 : loss = 2.078768730163574\n",
      "Data stream Batch- 3 : loss = 3.9626189470291138\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.07602517801356855\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0706439944044263\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.06608381893521423\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.06244554524553055\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.0593282380789202\n",
      "0.0005\n",
      "Step 5 : loss = 0.056917217887525295\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.055191865153405635\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.053979510307848526\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.053280002033629335\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05295914634330639\n",
      "Update Procedure\n",
      "Step0 : loss = 2.436590552330017\n",
      "Step1 : loss = 2.358026295900345\n",
      "Step2 : loss = 2.2836888313293455\n",
      "Step3 : loss = 2.2221903920173647\n",
      "Step4 : loss = 2.1735301196575163\n",
      "Step5 : loss = 2.1217276751995087\n",
      "Step6 : loss = 2.0817261934280396\n",
      "Step7 : loss = 2.042126566171646\n",
      "Step8 : loss = 2.0046764969825746\n",
      "Step9 : loss = 1.9688695251941681\n",
      "Data stream Batch- 4 : loss = 3.675689220428467\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.061804936184956936\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.05824887578693744\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.05631754156878308\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.053139055363911204\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.05179186774621234\n",
      "0.0005\n",
      "Step 5 : loss = 0.04979302144236459\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.04883775397681022\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.047969863138558395\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.04749044964916638\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.04727176742596237\n",
      "Update Procedure\n",
      "Step0 : loss = 2.4985158940156302\n",
      "Step1 : loss = 2.444086323181788\n",
      "Step2 : loss = 2.357678403457006\n",
      "Step3 : loss = 2.2746852189302444\n",
      "Step4 : loss = 2.220387786626816\n",
      "Step5 : loss = 2.165746053059896\n",
      "Step6 : loss = 2.1280536899964013\n",
      "Step7 : loss = 2.092180540164312\n",
      "Step8 : loss = 2.0563673973083496\n",
      "Step9 : loss = 2.023578479886055\n",
      "Data stream Batch- 5 : loss = 2.9631857872009277\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.13605701426663244\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12330735621133387\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.11116936645808972\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.10017212207369035\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.0908722110439854\n",
      "0.0005\n",
      "Step 5 : loss = 0.08333214233900625\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.07794392921924863\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.0746192634106424\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.07278063648358886\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.07196197661458169\n",
      "Update Procedure\n",
      "Step0 : loss = 2.240149804524013\n",
      "Step1 : loss = 2.121765570981162\n",
      "Step2 : loss = 2.026086845568248\n",
      "Step3 : loss = 1.9617448576859065\n",
      "Step4 : loss = 1.9304892207895006\n",
      "Step5 : loss = 1.8937342252050127\n",
      "Step6 : loss = 1.8578659423760004\n",
      "Step7 : loss = 1.8248920483248574\n",
      "Step8 : loss = 1.794039249420166\n",
      "Step9 : loss = 1.7682084781782967\n",
      "Data stream Batch- 6 : loss = 2.6140140295028687\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.1756881464711287\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.16194298019646186\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.14864341354434454\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.13635742451583432\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.1256380853252226\n",
      "0.0005\n",
      "Step 5 : loss = 0.11689314374533993\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.11026875077677174\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.10574955634614247\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10313351988140329\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.10193021116686969\n",
      "Update Procedure\n",
      "Step0 : loss = 1.9877171851694584\n",
      "Step1 : loss = 1.838091067969799\n",
      "Step2 : loss = 1.7551265768706799\n",
      "Step3 : loss = 1.7278266064822674\n",
      "Step4 : loss = 1.667591106146574\n",
      "Step5 : loss = 1.62570745870471\n",
      "Step6 : loss = 1.5813349522650242\n",
      "Step7 : loss = 1.5459857247769833\n",
      "Step8 : loss = 1.520053006708622\n",
      "Step9 : loss = 1.5034067444503307\n",
      "Data stream Batch- 7 : loss = 2.2930845618247986\n",
      "Task  4\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.05008129639049191\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.04542553521324779\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.04531939180248481\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.045483911035097635\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.04408907066133889\n",
      "0.0005\n",
      "Step 5 : loss = 0.04411632314931803\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.04320848280936819\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.04308005746466411\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.04280359700117573\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.04270917067901236\n",
      "Update Procedure\n",
      "Step0 : loss = 4.219667434692383\n",
      "Step1 : loss = 4.037325382232666\n",
      "Step2 : loss = 3.855027675628662\n",
      "Step3 : loss = 3.6770520210266113\n",
      "Step4 : loss = 3.5025882720947266\n",
      "Step5 : loss = 3.3305068016052246\n",
      "Step6 : loss = 3.1671178340911865\n",
      "Step7 : loss = 3.025139093399048\n",
      "Step8 : loss = 2.900001287460327\n",
      "Step9 : loss = 2.808720588684082\n",
      "Data stream Batch- 0 : loss = 4.504518628120422\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.13403920201708197\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.11786638442486325\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.10260309258928746\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.08899510753153266\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.07736308240488123\n",
      "0.0005\n",
      "Step 5 : loss = 0.06814683176317997\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.06132683259042761\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05744713301498699\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.055511763284780545\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05465986376579193\n",
      "Update Procedure\n",
      "Step0 : loss = 4.433686256408691\n",
      "Step1 : loss = 4.162463068962097\n",
      "Step2 : loss = 3.921043276786804\n",
      "Step3 : loss = 3.692871332168579\n",
      "Step4 : loss = 3.4705997705459595\n",
      "Step5 : loss = 3.2526602745056152\n",
      "Step6 : loss = 3.0358208417892456\n",
      "Step7 : loss = 2.823054075241089\n",
      "Step8 : loss = 2.618395447731018\n",
      "Step9 : loss = 2.4229401350021362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stream Batch- 1 : loss = 4.177316427230835\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.17589329488554328\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.1643648763197474\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.15567894994960216\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.14786934943437666\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.1411244354908553\n",
      "0.0005\n",
      "Step 5 : loss = 0.1353081206744787\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.13091389804422948\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.1278752212491133\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.12605150247277597\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.1252053076116991\n",
      "Update Procedure\n",
      "Step0 : loss = 3.926467021306356\n",
      "Step1 : loss = 3.5519454876581826\n",
      "Step2 : loss = 3.2166204849878945\n",
      "Step3 : loss = 2.9017105102539062\n",
      "Step4 : loss = 2.6131483713785806\n",
      "Step5 : loss = 2.3631317218144736\n",
      "Step6 : loss = 2.1574774980545044\n",
      "Step7 : loss = 1.9787865082422893\n",
      "Step8 : loss = 1.8404443363348644\n",
      "Step9 : loss = 1.7405805389086406\n",
      "Data stream Batch- 2 : loss = 3.990831732749939\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.3041335979635896\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.287481795049715\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.2724482887648541\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.26235951397919477\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.2557354768782494\n",
      "0.0005\n",
      "Step 5 : loss = 0.2505633226448967\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.24651963678000513\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.24373835878438288\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.2420803048666264\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.2413116210720693\n",
      "Update Procedure\n",
      "Step0 : loss = 2.2542016208171844\n",
      "Step1 : loss = 2.0006387010216713\n",
      "Step2 : loss = 1.8345848843455315\n",
      "Step3 : loss = 1.7144000306725502\n",
      "Step4 : loss = 1.6242485418915749\n",
      "Step5 : loss = 1.5545580983161926\n",
      "Step6 : loss = 1.491870030760765\n",
      "Step7 : loss = 1.4274644330143929\n",
      "Step8 : loss = 1.359956257045269\n",
      "Step9 : loss = 1.2990668714046478\n",
      "Data stream Batch- 3 : loss = 3.829619884490967\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.3127102145751836\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.3043561200189219\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.29652221304846604\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.2893459254661643\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.2827653002267382\n",
      "0.0005\n",
      "Step 5 : loss = 0.2774042789284671\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.2732817464149045\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.2704257105598534\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.26872250788917\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.26793282613488745\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5739615678787233\n",
      "Step1 : loss = 2.3065652728080748\n",
      "Step2 : loss = 2.1850849092006683\n",
      "Step3 : loss = 2.104400187730789\n",
      "Step4 : loss = 2.017232429981232\n",
      "Step5 : loss = 1.9458389937877656\n",
      "Step6 : loss = 1.8771476030349732\n",
      "Step7 : loss = 1.8072448194026947\n",
      "Step8 : loss = 1.7356817126274109\n",
      "Step9 : loss = 1.6693261742591858\n",
      "Data stream Batch- 4 : loss = 3.376506209373474\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.33293631761592346\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.32395715303471717\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.31598272878482575\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.30860354603633455\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.3021124351493461\n",
      "0.0005\n",
      "Step 5 : loss = 0.29671725923191333\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.2925714259310123\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.28969773384125314\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.2879811924128127\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.2871854731270813\n",
      "Update Procedure\n",
      "Step0 : loss = 2.1805692265431085\n",
      "Step1 : loss = 1.9384158452351887\n",
      "Step2 : loss = 1.8249301811059315\n",
      "Step3 : loss = 1.7270414034525554\n",
      "Step4 : loss = 1.6220993846654892\n",
      "Step5 : loss = 1.531359260280927\n",
      "Step6 : loss = 1.4562691350777943\n",
      "Step7 : loss = 1.390225241581599\n",
      "Step8 : loss = 1.3358459522326787\n",
      "Step9 : loss = 1.2884504348039627\n",
      "Data stream Batch- 5 : loss = 2.4463255405426025\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.33420559721053833\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.324772144230465\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.31695848460911047\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.3095152249702243\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.30301712500423206\n",
      "0.0005\n",
      "Step 5 : loss = 0.29762396122356577\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.29351412690298495\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.29066989369396057\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.2889651456865858\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.28817408914136355\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5591010068144118\n",
      "Step1 : loss = 1.4024732496057237\n",
      "Step2 : loss = 1.3027229479381017\n",
      "Step3 : loss = 1.2196832256657737\n",
      "Step4 : loss = 1.1603767105511256\n",
      "Step5 : loss = 1.0945299054895128\n",
      "Step6 : loss = 1.0411260170595986\n",
      "Step7 : loss = 0.9923112860747746\n",
      "Step8 : loss = 0.9528096147945949\n",
      "Step9 : loss = 0.9202019444533757\n",
      "Data stream Batch- 6 : loss = 1.4348540902137756\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.3261001439797601\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.31784378290473253\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.3096842938742435\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.30206835793160797\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.2953540019904654\n",
      "0.0005\n",
      "Step 5 : loss = 0.28979980942968586\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.28555339317682865\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.28262488539490355\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.2808732320107322\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.28006142717967764\n",
      "Update Procedure\n",
      "Step0 : loss = 1.0359162837266922\n",
      "Step1 : loss = 0.9157629683613777\n",
      "Step2 : loss = 0.8842247761785984\n",
      "Step3 : loss = 0.8659458830952644\n",
      "Step4 : loss = 0.8694569021463394\n",
      "Step5 : loss = 0.8136443719267845\n",
      "Step6 : loss = 0.7882852293550968\n",
      "Step7 : loss = 0.7629177607595921\n",
      "Step8 : loss = 0.7626826465129852\n",
      "Step9 : loss = 0.7681753523647785\n",
      "Data stream Batch- 7 : loss = 1.1900559067726135\n",
      "Task  5\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.032188851437309304\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.030050430034729386\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.028549556476471262\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.027204629869468623\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.02633698541958619\n",
      "0.0005\n",
      "Step 5 : loss = 0.02539277178554521\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.024787617357294227\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.024363984790845467\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.024110388634014938\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.023994092419996928\n",
      "Update Procedure\n",
      "Step0 : loss = 2.383208751678467\n",
      "Step1 : loss = 2.0865607261657715\n",
      "Step2 : loss = 1.9298700094223022\n",
      "Step3 : loss = 1.80666184425354\n",
      "Step4 : loss = 1.682527780532837\n",
      "Step5 : loss = 1.550119161605835\n",
      "Step6 : loss = 1.4137874841690063\n",
      "Step7 : loss = 1.2838032245635986\n",
      "Step8 : loss = 1.1791192293167114\n",
      "Step9 : loss = 1.105521321296692\n",
      "Data stream Batch- 0 : loss = 3.182874917984009\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.03650714506170249\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.02927990943981775\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.02463030025926732\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.02418816659858037\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.023090916812497104\n",
      "0.0005\n",
      "Step 5 : loss = 0.022817156014755747\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.022103698202854072\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.021668523651547984\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.021420833737783723\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.021306685606437014\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2657327055931091\n",
      "Step1 : loss = 0.9776334464550018\n",
      "Step2 : loss = 0.847493439912796\n",
      "Step3 : loss = 0.7550314366817474\n",
      "Step4 : loss = 0.6576306819915771\n",
      "Step5 : loss = 0.6189299076795578\n",
      "Step6 : loss = 0.5614807456731796\n",
      "Step7 : loss = 0.5202137529850006\n",
      "Step8 : loss = 0.5103098228573799\n",
      "Step9 : loss = 0.5235521048307419\n",
      "Data stream Batch- 1 : loss = 3.637516140937805\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.03338909804871676\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.028467767627740746\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.02594304299696082\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.02412370932393263\n",
      "0.0006545084971874737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 : loss = 0.02312009344066281\n",
      "0.0005\n",
      "Step 5 : loss = 0.02227088735514173\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02193525032266142\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.02130680774097714\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.02101252406091559\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.02087976650007303\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3864308794339497\n",
      "Step1 : loss = 1.336075892051061\n",
      "Step2 : loss = 1.1701506078243256\n",
      "Step3 : loss = 1.1518659989039104\n",
      "Step4 : loss = 1.1089012622833252\n",
      "Step5 : loss = 1.0800241827964783\n",
      "Step6 : loss = 1.0346278448899586\n",
      "Step7 : loss = 0.9810667932033539\n",
      "Step8 : loss = 0.9702766140302023\n",
      "Step9 : loss = 0.9248149991035461\n",
      "Data stream Batch- 2 : loss = 3.3392282724380493\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.0360639611975506\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.03235620866045295\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.029707759776513364\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.027410523710640223\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.02577210954714545\n",
      "0.0005\n",
      "Step 5 : loss = 0.024606945357494105\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02377863134001088\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.02324827384116208\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.022897498810237307\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.022742192956066352\n",
      "Update Procedure\n",
      "Step0 : loss = 1.394941195845604\n",
      "Step1 : loss = 1.4048189669847488\n",
      "Step2 : loss = 1.2088734209537506\n",
      "Step3 : loss = 1.2116464003920555\n",
      "Step4 : loss = 1.15209099650383\n",
      "Step5 : loss = 1.099336102604866\n",
      "Step6 : loss = 1.0502731017768383\n",
      "Step7 : loss = 1.0205628387629986\n",
      "Step8 : loss = 0.9967398121953011\n",
      "Step9 : loss = 0.9659473448991776\n",
      "Data stream Batch- 3 : loss = 3.1640806198120117\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.043557225740594466\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.038328029861162446\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.03424474310349676\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.03139397875372816\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.02932937892054977\n",
      "0.0005\n",
      "Step 5 : loss = 0.02795464690071413\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02699663116772936\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.026404308451060628\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.026038200627260144\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.02588112829259378\n",
      "Update Procedure\n",
      "Step0 : loss = 1.1668551683425903\n",
      "Step1 : loss = 1.0535772025585175\n",
      "Step2 : loss = 1.025372278690338\n",
      "Step3 : loss = 0.965353262424469\n",
      "Step4 : loss = 0.9054168820381164\n",
      "Step5 : loss = 0.8743568599224091\n",
      "Step6 : loss = 0.828778725862503\n",
      "Step7 : loss = 0.7920145273208619\n",
      "Step8 : loss = 0.758785891532898\n",
      "Step9 : loss = 0.7290239006280899\n",
      "Data stream Batch- 4 : loss = 3.0251396894454956\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.05108323841897511\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.04541102683822153\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.04045209244032126\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.03686318981891024\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.034549593951274535\n",
      "0.0005\n",
      "Step 5 : loss = 0.032869885800562264\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.03164784738384182\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.030852521705105097\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.03040356426592857\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.030196077032913014\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5245707680781682\n",
      "Step1 : loss = 1.4235951552788417\n",
      "Step2 : loss = 1.3635849157969158\n",
      "Step3 : loss = 1.3028927743434906\n",
      "Step4 : loss = 1.243759885430336\n",
      "Step5 : loss = 1.192947119474411\n",
      "Step6 : loss = 1.155364880959193\n",
      "Step7 : loss = 1.131780815621217\n",
      "Step8 : loss = 1.1216752529144287\n",
      "Step9 : loss = 1.0823813701669376\n",
      "Data stream Batch- 5 : loss = 2.404399812221527\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.0700382121133416\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.06274115522355131\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.055929826876711164\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.05054126424749359\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.04620863875896782\n",
      "0.0005\n",
      "Step 5 : loss = 0.042986596014968195\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.040787285890585785\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.039419534416506016\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.038672568388086526\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.03833610842230555\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3414064007146018\n",
      "Step1 : loss = 1.2913777913366045\n",
      "Step2 : loss = 1.306589492729732\n",
      "Step3 : loss = 1.1511806079319544\n",
      "Step4 : loss = 1.1442146301269531\n",
      "Step5 : loss = 1.057653056723731\n",
      "Step6 : loss = 1.030345810311181\n",
      "Step7 : loss = 0.9946535761867251\n",
      "Step8 : loss = 0.9806985918964658\n",
      "Step9 : loss = 0.9775700058255877\n",
      "Data stream Batch- 6 : loss = 2.029444992542267\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.08678036743678696\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0795925794821268\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.07272641321915861\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.06661203206845527\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.06151957606553772\n",
      "0.0005\n",
      "Step 5 : loss = 0.05748993901779955\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.05459041834091084\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05262594434564845\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.05146177738598943\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05093241467849376\n",
      "Update Procedure\n",
      "Step0 : loss = 1.225094236433506\n",
      "Step1 : loss = 1.223154503852129\n",
      "Step2 : loss = 1.1537380032241344\n",
      "Step3 : loss = 1.0147557258605957\n",
      "Step4 : loss = 0.9771371185779572\n",
      "Step5 : loss = 0.9613115265965462\n",
      "Step6 : loss = 0.9520770497620106\n",
      "Step7 : loss = 0.9381357915699482\n",
      "Step8 : loss = 0.9649042896926403\n",
      "Step9 : loss = 0.9627892561256886\n",
      "Data stream Batch- 7 : loss = 1.9649096131324768\n",
      "Task  6\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.060684977469320715\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.05787355295929666\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.05685220664497228\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.056467713113562586\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.05573173151658372\n",
      "0.0005\n",
      "Step 5 : loss = 0.05541280120264123\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.05467040193283947\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05443143537804739\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.05415386506706285\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05406558846685047\n",
      "Update Procedure\n",
      "Step0 : loss = 2.937833309173584\n",
      "Step1 : loss = 2.8439011573791504\n",
      "Step2 : loss = 2.7502222061157227\n",
      "Step3 : loss = 2.6568002700805664\n",
      "Step4 : loss = 2.563692331314087\n",
      "Step5 : loss = 2.4706356525421143\n",
      "Step6 : loss = 2.377939462661743\n",
      "Step7 : loss = 2.2852938175201416\n",
      "Step8 : loss = 2.1929116249084473\n",
      "Step9 : loss = 2.1006412506103516\n",
      "Data stream Batch- 0 : loss = 8.847290992736816\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.09777489092348407\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.08881996871845393\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.08041605251986887\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.0728573814564968\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.06723496244156836\n",
      "0.0005\n",
      "Step 5 : loss = 0.06326307779882222\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.06067041031513904\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05920874697703878\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.0584008992893764\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05804453541313257\n",
      "Update Procedure\n",
      "Step0 : loss = 2.895689606666565\n",
      "Step1 : loss = 2.7153232097625732\n",
      "Step2 : loss = 2.5359673500061035\n",
      "Step3 : loss = 2.3640970587730408\n",
      "Step4 : loss = 2.1986128091812134\n",
      "Step5 : loss = 2.0490890741348267\n",
      "Step6 : loss = 1.9308841824531555\n",
      "Step7 : loss = 1.8327937722206116\n",
      "Step8 : loss = 1.749058723449707\n",
      "Step9 : loss = 1.6733103394508362\n",
      "Data stream Batch- 1 : loss = 7.606573581695557\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.12987232619901587\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12061200717689047\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.11160481858043182\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.10332548729393946\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.09621846276290554\n",
      "0.0005\n",
      "Step 5 : loss = 0.09146848324512986\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.08809789113439032\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.08590044517867874\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.08462816022746723\n",
      "2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 : loss = 0.08404731298445899\n",
      "Update Procedure\n",
      "Step0 : loss = 2.428771654764811\n",
      "Step1 : loss = 2.267672300338745\n",
      "Step2 : loss = 2.119287371635437\n",
      "Step3 : loss = 1.9837818543116252\n",
      "Step4 : loss = 1.8585663636525471\n",
      "Step5 : loss = 1.7393829027811687\n",
      "Step6 : loss = 1.6337855458259583\n",
      "Step7 : loss = 1.5459523797035217\n",
      "Step8 : loss = 1.478635589281718\n",
      "Step9 : loss = 1.4138158758481343\n",
      "Data stream Batch- 2 : loss = 6.199278354644775\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.14364657195342187\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.13646968810688928\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.1299694075590359\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.12426302902029589\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.11941072672784385\n",
      "0.0005\n",
      "Step 5 : loss = 0.1154548799308791\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.11266356380066646\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.11078830522372028\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10964641500522616\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.10912779091513629\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6019373834133148\n",
      "Step1 : loss = 1.4590164422988892\n",
      "Step2 : loss = 1.3496547490358353\n",
      "Step3 : loss = 1.2437000572681427\n",
      "Step4 : loss = 1.1417331174015999\n",
      "Step5 : loss = 1.053296945989132\n",
      "Step6 : loss = 0.9868772998452187\n",
      "Step7 : loss = 0.9310693144798279\n",
      "Step8 : loss = 0.8720083385705948\n",
      "Step9 : loss = 0.8076121956110001\n",
      "Data stream Batch- 3 : loss = 5.053233623504639\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.14114027720105007\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.1321523711652742\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.12403541659390128\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.11738087218999947\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.11284125123681399\n",
      "0.0005\n",
      "Step 5 : loss = 0.10942428220926755\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.10691851586600241\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.10521253569511446\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10421577197787685\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.1037544624697685\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9101207494735718\n",
      "Step1 : loss = 0.7586891710758209\n",
      "Step2 : loss = 0.6796533048152924\n",
      "Step3 : loss = 0.5820340037345886\n",
      "Step4 : loss = 0.4874210596084595\n",
      "Step5 : loss = 0.42758831977844236\n",
      "Step6 : loss = 0.4078653514385223\n",
      "Step7 : loss = 0.398527467250824\n",
      "Step8 : loss = 0.395198392868042\n",
      "Step9 : loss = 0.3897873371839523\n",
      "Data stream Batch- 4 : loss = 4.406793117523193\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.12055846157439816\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.11101112200162223\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.10228422494894766\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.0949002629831142\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.08934024657871849\n",
      "0.0005\n",
      "Step 5 : loss = 0.08543702468362285\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.08278330537433952\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.08106532587694977\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.0801168368764396\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.07968573263248101\n",
      "Update Procedure\n",
      "Step0 : loss = 1.0322609568635623\n",
      "Step1 : loss = 0.9290371189514796\n",
      "Step2 : loss = 0.8765205343564352\n",
      "Step3 : loss = 0.8310718586047491\n",
      "Step4 : loss = 0.7921521961688995\n",
      "Step5 : loss = 0.7538877353072166\n",
      "Step6 : loss = 0.7239250764250755\n",
      "Step7 : loss = 0.6896354307730993\n",
      "Step8 : loss = 0.6529328326384226\n",
      "Step9 : loss = 0.6206869135300318\n",
      "Data stream Batch- 5 : loss = 4.408629775047302\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.1518622383503944\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.14387323741546856\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.13607554045468723\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.12889264164974332\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.1229374347284423\n",
      "0.0005\n",
      "Step 5 : loss = 0.11832594034096765\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.11505962045966293\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.11294992978867678\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.11171089308688402\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.1111409631437284\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9189388602972031\n",
      "Step1 : loss = 0.8334803240639823\n",
      "Step2 : loss = 0.7824033860649381\n",
      "Step3 : loss = 0.7482033286775861\n",
      "Step4 : loss = 0.7226842492818832\n",
      "Step5 : loss = 0.703412766967501\n",
      "Step6 : loss = 0.691921055316925\n",
      "Step7 : loss = 0.6828504992382867\n",
      "Step8 : loss = 0.6720059833356312\n",
      "Step9 : loss = 0.6620709108454841\n",
      "Data stream Batch- 6 : loss = 4.362330079078674\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.1664742030667208\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.15936798200733918\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.15299435165276323\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.14738518762952374\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.14250951489422006\n",
      "0.0005\n",
      "Step 5 : loss = 0.13849824918818787\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.13544480933146677\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.13335222265992447\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.13212133165894235\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.13155329954802117\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2066914569586515\n",
      "Step1 : loss = 1.1500670202076435\n",
      "Step2 : loss = 1.0893503334373236\n",
      "Step3 : loss = 1.0533927716314793\n",
      "Step4 : loss = 1.017360957339406\n",
      "Step5 : loss = 0.9925056118518114\n",
      "Step6 : loss = 0.9709547534584999\n",
      "Step7 : loss = 0.9438220616430044\n",
      "Step8 : loss = 0.9296003747731447\n",
      "Step9 : loss = 0.9088865909725428\n",
      "Data stream Batch- 7 : loss = 2.9632257223129272\n",
      "Task  7\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.09794994898185724\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.09270446112317261\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.08784254120917814\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.08367917444702348\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.08023801247643965\n",
      "0.0005\n",
      "Step 5 : loss = 0.07753320610857659\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.07559808855056839\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.07435130936686711\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.07360708107093718\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.07326311033870148\n",
      "Update Procedure\n",
      "Step0 : loss = 9.607645034790039\n",
      "Step1 : loss = 9.266976356506348\n",
      "Step2 : loss = 8.929630279541016\n",
      "Step3 : loss = 8.604170799255371\n",
      "Step4 : loss = 8.293994903564453\n",
      "Step5 : loss = 8.001927375793457\n",
      "Step6 : loss = 7.7254109382629395\n",
      "Step7 : loss = 7.456173896789551\n",
      "Step8 : loss = 7.187267303466797\n",
      "Step9 : loss = 6.918245792388916\n",
      "Data stream Batch- 0 : loss = 6.057497978210449\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.07262799324295399\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0695889197558997\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.06687145757840847\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.0644275190512036\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.06229234385226855\n",
      "0.0005\n",
      "Step 5 : loss = 0.06060465863964926\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.05928140459759958\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05839065864516333\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.05786105486914354\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05761284227226189\n",
      "Update Procedure\n",
      "Step0 : loss = 5.53030800819397\n",
      "Step1 : loss = 5.092941045761108\n",
      "Step2 : loss = 4.674474596977234\n",
      "Step3 : loss = 4.2802814245224\n",
      "Step4 : loss = 3.923220634460449\n",
      "Step5 : loss = 3.6020416021347046\n",
      "Step6 : loss = 3.297510862350464\n",
      "Step7 : loss = 3.0043588876724243\n",
      "Step8 : loss = 2.7243882417678833\n",
      "Step9 : loss = 2.4547828435897827\n",
      "Data stream Batch- 1 : loss = 5.196890115737915\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.07098954809876669\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.06669277732234417\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.0625835746874542\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.0589297785502672\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.056025390918430486\n",
      "0.0005\n",
      "Step 5 : loss = 0.05394077478687088\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.05243540832401442\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.05145147948301352\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.050885627923963075\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05063086367669089\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7452000379562378\n",
      "Step1 : loss = 1.546585500240326\n",
      "Step2 : loss = 1.3989116946856182\n",
      "Step3 : loss = 1.2722824613253276\n",
      "Step4 : loss = 1.1655755440394084\n",
      "Step5 : loss = 1.077524463335673\n",
      "Step6 : loss = 1.0072515209515889\n",
      "Step7 : loss = 0.9585961699485779\n",
      "Step8 : loss = 0.9318589965502421\n",
      "Step9 : loss = 0.9114445845286051\n",
      "Data stream Batch- 2 : loss = 4.60413932800293\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 0.06004441372601354\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.05573472313225674\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.052475110523019834\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.04967618664571143\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.04751216530351859\n",
      "0.0005\n",
      "Step 5 : loss = 0.045902193403155364\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.04473152989792285\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.04394178756682222\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.04346989722239839\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.04325390634118975\n",
      "Update Procedure\n",
      "Step0 : loss = 0.867062896490097\n",
      "Step1 : loss = 0.7428043857216835\n",
      "Step2 : loss = 0.697397343814373\n",
      "Step3 : loss = 0.686150461435318\n",
      "Step4 : loss = 0.6716656424105167\n",
      "Step5 : loss = 0.6579719372093678\n",
      "Step6 : loss = 0.6422815471887589\n",
      "Step7 : loss = 0.6298099905252457\n",
      "Step8 : loss = 0.6227639652788639\n",
      "Step9 : loss = 0.6151264756917953\n",
      "Data stream Batch- 3 : loss = 4.374205708503723\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.051543053228839404\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.047842822602273016\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.045148086791033666\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.04293529620008559\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.04100916626851878\n",
      "0.0005\n",
      "Step 5 : loss = 0.0395827964666021\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.0385285584674297\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.037854439800900634\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.037448062299103295\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.0372630509990527\n",
      "Update Procedure\n",
      "Step0 : loss = 0.7234090149402619\n",
      "Step1 : loss = 0.6477145493030548\n",
      "Step2 : loss = 0.638288602232933\n",
      "Step3 : loss = 0.6050605058670044\n",
      "Step4 : loss = 0.5931208163499833\n",
      "Step5 : loss = 0.5916744932532311\n",
      "Step6 : loss = 0.5802910432219506\n",
      "Step7 : loss = 0.5729873687028885\n",
      "Step8 : loss = 0.5663309961557388\n",
      "Step9 : loss = 0.5554323047399521\n",
      "Data stream Batch- 4 : loss = 4.345492362976074\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.041312303734309\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.03882973836355459\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.03664814972780184\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.03488520631309545\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.033510984132291984\n",
      "0.0005\n",
      "Step 5 : loss = 0.032429820417475726\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.031641664363308335\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.0311218586083114\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.030822183537296995\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.03068698970373054\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3805053755640984\n",
      "Step1 : loss = 1.2581482529640198\n",
      "Step2 : loss = 1.192962760726611\n",
      "Step3 : loss = 1.119477277000745\n",
      "Step4 : loss = 1.0809360804657142\n",
      "Step5 : loss = 1.0360841390987237\n",
      "Step6 : loss = 0.9890136594573656\n",
      "Step7 : loss = 0.9455023755629858\n",
      "Step8 : loss = 0.9034782337645689\n",
      "Step9 : loss = 0.8535561660925547\n",
      "Data stream Batch- 5 : loss = 2.3684126138687134\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.08360419585626104\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0780087936297774\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.07313992638263198\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.06866175061204804\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.06478239877586107\n",
      "0.0005\n",
      "Step 5 : loss = 0.06169480101488454\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.05940241339968583\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.057861886415190064\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.05697546574587059\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.05656641145965196\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2285777160099574\n",
      "Step1 : loss = 1.1232125759124756\n",
      "Step2 : loss = 0.9969297349452972\n",
      "Step3 : loss = 0.864626618368285\n",
      "Step4 : loss = 0.7772076481154987\n",
      "Step5 : loss = 0.693125267113958\n",
      "Step6 : loss = 0.6186575953449521\n",
      "Step7 : loss = 0.5677074257816587\n",
      "Step8 : loss = 0.5622555060046059\n",
      "Step9 : loss = 0.5522222944668361\n",
      "Data stream Batch- 6 : loss = 1.6256779432296753\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.10480564487014178\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.09948702111105445\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.09439216250195077\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.08984843934459755\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.08596945042227301\n",
      "0.0005\n",
      "Step 5 : loss = 0.08290553416264977\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.08064800885251569\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.07913632038200179\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.0783127130858761\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.07792364010143353\n",
      "Update Procedure\n",
      "Step0 : loss = 0.6436400339007378\n",
      "Step1 : loss = 0.7412624806165695\n",
      "Step2 : loss = 0.6660792678594589\n",
      "Step3 : loss = 0.5823351163417101\n",
      "Step4 : loss = 0.5753137543797493\n",
      "Step5 : loss = 0.5617764005437493\n",
      "Step6 : loss = 0.5556904505938292\n",
      "Step7 : loss = 0.5503586074337363\n",
      "Step8 : loss = 0.5456090988591313\n",
      "Step9 : loss = 0.5526449121534824\n",
      "Data stream Batch- 7 : loss = 1.4338626265525818\n",
      "Task  8\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.0269951350132964\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.025912837227442503\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.025703847551974763\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.025902564301642117\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.025438456352246053\n",
      "0.0005\n",
      "Step 5 : loss = 0.02543984685374805\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02510530213908689\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.02510937852877355\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.024972746463261548\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.024943235503311238\n",
      "Update Procedure\n",
      "Step0 : loss = 3.5336573123931885\n",
      "Step1 : loss = 3.4384584426879883\n",
      "Step2 : loss = 3.344400644302368\n",
      "Step3 : loss = 3.2510290145874023\n",
      "Step4 : loss = 3.1577584743499756\n",
      "Step5 : loss = 3.067234992980957\n",
      "Step6 : loss = 2.9780008792877197\n",
      "Step7 : loss = 2.8900301456451416\n",
      "Step8 : loss = 2.8027331829071045\n",
      "Step9 : loss = 2.7152926921844482\n",
      "Data stream Batch- 0 : loss = 4.614766597747803\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.02817866967672395\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.02574727411837017\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.024996996046460492\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.024961295446779965\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.024673902866827073\n",
      "0.0005\n",
      "Step 5 : loss = 0.024537057065248526\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02429406271827941\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.024177325338107514\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.024094682437385665\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.024069550444134714\n",
      "Update Procedure\n",
      "Step0 : loss = 2.949524164199829\n",
      "Step1 : loss = 2.7727975845336914\n",
      "Step2 : loss = 2.613412380218506\n",
      "Step3 : loss = 2.4629698991775513\n",
      "Step4 : loss = 2.3256497383117676\n",
      "Step5 : loss = 2.2010873556137085\n",
      "Step6 : loss = 2.082305371761322\n",
      "Step7 : loss = 1.9672303795814514\n",
      "Step8 : loss = 1.854154884815216\n",
      "Step9 : loss = 1.7436541318893433\n",
      "Data stream Batch- 1 : loss = 3.427625894546509\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.03811659989123227\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.03270126141441498\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.028605620902805034\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.026956042482123667\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.02600362658715897\n",
      "0.0005\n",
      "Step 5 : loss = 0.025149288310356253\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.024723932751979923\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.02431944937039769\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.02409501095191414\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.02399760223322486\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7404286861419678\n",
      "Step1 : loss = 1.5815516710281372\n",
      "Step2 : loss = 1.474526325861613\n",
      "Step3 : loss = 1.3828973770141602\n",
      "Step4 : loss = 1.3059769868850708\n",
      "Step5 : loss = 1.2449150085449219\n",
      "Step6 : loss = 1.19672695795695\n",
      "Step7 : loss = 1.153210957845052\n",
      "Step8 : loss = 1.1116032997767131\n",
      "Step9 : loss = 1.0724132855733235\n",
      "Data stream Batch- 2 : loss = 2.4574005603790283\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.031969825358327916\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.0281407745521481\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.02778820415501925\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.02661309076462092\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.02604998948360286\n",
      "0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 : loss = 0.025160999747971872\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02475888946893981\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.024358843047001963\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.02410249412292988\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.02399346177034683\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2984149158000946\n",
      "Step1 : loss = 1.1909697204828262\n",
      "Step2 : loss = 1.1152792125940323\n",
      "Step3 : loss = 1.0749125331640244\n",
      "Step4 : loss = 1.0411428958177567\n",
      "Step5 : loss = 1.0072913318872452\n",
      "Step6 : loss = 0.972845196723938\n",
      "Step7 : loss = 0.9447311088442802\n",
      "Step8 : loss = 0.9246122166514397\n",
      "Step9 : loss = 0.9059369191527367\n",
      "Data stream Batch- 3 : loss = 2.2066142559051514\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.03206610391637903\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.027913412145468556\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.026790888007310994\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.026229305483806784\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.025505418204585358\n",
      "0.0005\n",
      "Step 5 : loss = 0.024781640656452178\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02439703438333445\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.023970986068876543\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.023795708510028615\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.023718889636950024\n",
      "Update Procedure\n",
      "Step0 : loss = 1.4135891556739808\n",
      "Step1 : loss = 1.3002305388450623\n",
      "Step2 : loss = 1.279387253522873\n",
      "Step3 : loss = 1.2685541570186616\n",
      "Step4 : loss = 1.2470966756343842\n",
      "Step5 : loss = 1.2232963740825653\n",
      "Step6 : loss = 1.2007454335689545\n",
      "Step7 : loss = 1.1788685858249663\n",
      "Step8 : loss = 1.1597434818744659\n",
      "Step9 : loss = 1.143616509437561\n",
      "Data stream Batch- 4 : loss = 2.3974640369415283\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.03640376399552468\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.030471395097670058\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.026054867930431796\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.024882339267909368\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.024287751506233708\n",
      "0.0005\n",
      "Step 5 : loss = 0.023846394858186765\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.02334262735449164\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.02315858649392114\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.02302166271652094\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.022995713821077894\n",
      "Update Procedure\n",
      "Step0 : loss = 1.2553257842858632\n",
      "Step1 : loss = 1.1494993170102437\n",
      "Step2 : loss = 1.0706265072027843\n",
      "Step3 : loss = 1.0462315479914348\n",
      "Step4 : loss = 1.0101766387621562\n",
      "Step5 : loss = 0.9808850884437561\n",
      "Step6 : loss = 0.9612423380215963\n",
      "Step7 : loss = 0.9412626922130585\n",
      "Step8 : loss = 0.9334244827429453\n",
      "Step9 : loss = 0.9236360639333725\n",
      "Data stream Batch- 5 : loss = 2.500146508216858\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.044215124692378746\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.03889396378734957\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.03544098331431692\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.034281602162806485\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.03333733429162084\n",
      "0.0005\n",
      "Step 5 : loss = 0.032530831385068446\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.03189803948003356\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.03141724453232821\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.031127882840888396\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.030991378508925582\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5076921411922999\n",
      "Step1 : loss = 1.4849862541471208\n",
      "Step2 : loss = 1.4207595331328255\n",
      "Step3 : loss = 1.3553992211818695\n",
      "Step4 : loss = 1.3223715467112405\n",
      "Step5 : loss = 1.2841824548585075\n",
      "Step6 : loss = 1.2625255116394587\n",
      "Step7 : loss = 1.225985701595034\n",
      "Step8 : loss = 1.202183255127498\n",
      "Step9 : loss = 1.1884564033576421\n",
      "Data stream Batch- 6 : loss = 2.4346388578414917\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.04470862525868925\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.03963876882665555\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.037332670036224744\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.03597372038831852\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.03478224603540938\n",
      "0.0005\n",
      "Step 5 : loss = 0.033800250105107676\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.03296963717214731\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.03246194768436376\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.03212307366213634\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.03197229406551536\n",
      "Update Procedure\n",
      "Step0 : loss = 1.877920240163803\n",
      "Step1 : loss = 1.826662190258503\n",
      "Step2 : loss = 1.765144471079111\n",
      "Step3 : loss = 1.7173549197614193\n",
      "Step4 : loss = 1.6869233846664429\n",
      "Step5 : loss = 1.65801165625453\n",
      "Step6 : loss = 1.6453234367072582\n",
      "Step7 : loss = 1.6247608624398708\n",
      "Step8 : loss = 1.6071608923375607\n",
      "Step9 : loss = 1.589818101376295\n",
      "Data stream Batch- 7 : loss = 2.3078648447990417\n",
      "Task  9\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.13788054647584674\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.13401477154396998\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.13035539501038074\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.12701279789294992\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.12413286912887227\n",
      "0.0005\n",
      "Step 5 : loss = 0.12186670248065365\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.12017260301117887\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.11901372091508537\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.11833164706904326\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.11801752215388121\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9369801878929138\n",
      "Step1 : loss = 0.8109068274497986\n",
      "Step2 : loss = 0.7365381717681885\n",
      "Step3 : loss = 0.7108781337738037\n",
      "Step4 : loss = 0.6840546131134033\n",
      "Step5 : loss = 0.6650992035865784\n",
      "Step6 : loss = 0.6526573300361633\n",
      "Step7 : loss = 0.6403713226318359\n",
      "Step8 : loss = 0.6270447969436646\n",
      "Step9 : loss = 0.615379810333252\n",
      "Data stream Batch- 0 : loss = 2.5622777342796326\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.13191577975294283\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12768383318788493\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.12398393890841995\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.12066066129915846\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.11788155108772219\n",
      "0.0005\n",
      "Step 5 : loss = 0.11563968042515183\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.113947959884835\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.1127970715744661\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.11212111353411218\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.11181162738597153\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9024003446102142\n",
      "Step1 : loss = 0.7165251672267914\n",
      "Step2 : loss = 0.665713906288147\n",
      "Step3 : loss = 0.6584535837173462\n",
      "Step4 : loss = 0.6471609473228455\n",
      "Step5 : loss = 0.6221254169940948\n",
      "Step6 : loss = 0.5908847153186798\n",
      "Step7 : loss = 0.571984738111496\n",
      "Step8 : loss = 0.5659617781639099\n",
      "Step9 : loss = 0.565936952829361\n",
      "Data stream Batch- 1 : loss = 2.268273890018463\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.13080662343786925\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12693309299489952\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.12329129458140706\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.11996130686647882\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.1171217217466033\n",
      "0.0005\n",
      "Step 5 : loss = 0.11486389144260742\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.1131516574876127\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.11199197248086953\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.11131573219787921\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.11100354949900547\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9004409909248352\n",
      "Step1 : loss = 0.5570565164089203\n",
      "Step2 : loss = 0.5636586646238962\n",
      "Step3 : loss = 0.5833462476730347\n",
      "Step4 : loss = 0.538645476102829\n",
      "Step5 : loss = 0.4958022137482961\n",
      "Step6 : loss = 0.4967585504055023\n",
      "Step7 : loss = 0.4799053867657979\n",
      "Step8 : loss = 0.4501335968573888\n",
      "Step9 : loss = 0.4533645709355672\n",
      "Data stream Batch- 2 : loss = 2.178074836730957\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.1292381190879153\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12529257699598112\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.12167165995967617\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.11842270886326675\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.11560348534746916\n",
      "0.0005\n",
      "Step 5 : loss = 0.11337646364154479\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.11170495023412817\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.11057370284843819\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10990507900103333\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.10959477019477575\n",
      "Update Procedure\n",
      "Step0 : loss = 0.8052236139774323\n",
      "Step1 : loss = 0.6052829548716545\n",
      "Step2 : loss = 0.6052093021571636\n",
      "Step3 : loss = 0.580374252051115\n",
      "Step4 : loss = 0.569597665220499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step5 : loss = 0.5455952845513821\n",
      "Step6 : loss = 0.5433067940175533\n",
      "Step7 : loss = 0.5319165177643299\n",
      "Step8 : loss = 0.5216841213405132\n",
      "Step9 : loss = 0.5136005915701389\n",
      "Data stream Batch- 3 : loss = 2.0988067984580994\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.12431227354177445\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.12024985681557003\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.11665994887731329\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.11355225179993875\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.1109353175634253\n",
      "0.0005\n",
      "Step 5 : loss = 0.1088181917181868\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.10723202380998464\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.10615913565073996\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10553065167245157\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.1052461211572374\n",
      "Update Procedure\n",
      "Step0 : loss = 1.1387983858585358\n",
      "Step1 : loss = 1.003205621242523\n",
      "Step2 : loss = 1.0174963533878327\n",
      "Step3 : loss = 0.9938967168331146\n",
      "Step4 : loss = 0.9567456603050232\n",
      "Step5 : loss = 0.9392931550741196\n",
      "Step6 : loss = 0.9271414041519165\n",
      "Step7 : loss = 0.9153829008340836\n",
      "Step8 : loss = 0.9160137057304383\n",
      "Step9 : loss = 0.9114440351724624\n",
      "Data stream Batch- 4 : loss = 2.233310103416443\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.12174701773115215\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.11784703180995192\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.11438374021149765\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.11131065751648632\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.10871395368756182\n",
      "0.0005\n",
      "Step 5 : loss = 0.10665310718025851\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.10507397076807375\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.10400103350687549\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10336443357458235\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.10307060633142764\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5387735863526661\n",
      "Step1 : loss = 1.3252857675155003\n",
      "Step2 : loss = 1.2310418287913005\n",
      "Step3 : loss = 1.0958904524644215\n",
      "Step4 : loss = 0.9705242216587067\n",
      "Step5 : loss = 0.879776140054067\n",
      "Step6 : loss = 0.803706037501494\n",
      "Step7 : loss = 0.8247006510694822\n",
      "Step8 : loss = 0.7938926940162977\n",
      "Step9 : loss = 0.787557415664196\n",
      "Data stream Batch- 5 : loss = 2.2475786209106445\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.12033446558587883\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.11615378386065339\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.11233392933834141\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.10916526732962573\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.10651067916253461\n",
      "0.0005\n",
      "Step 5 : loss = 0.1044108528283605\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.10283635256396444\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.10176283607498288\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.10112724925634087\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.10083348097467754\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3059905001095362\n",
      "Step1 : loss = 1.1671142961297716\n",
      "Step2 : loss = 1.1118594195161546\n",
      "Step3 : loss = 1.0683284742491586\n",
      "Step4 : loss = 1.0261449558394296\n",
      "Step5 : loss = 1.02283048416887\n",
      "Step6 : loss = 1.0088710146290916\n",
      "Step7 : loss = 1.002357006072998\n",
      "Step8 : loss = 0.9943525727306094\n",
      "Step9 : loss = 0.986747682094574\n",
      "Data stream Batch- 6 : loss = 2.1613430976867676\n",
      "Meta Update\n",
      "Training is starting\n",
      "0.001\n",
      "Step 0 : loss = 0.11541689994326244\n",
      "0.0009755282581475768\n",
      "Step 1 : loss = 0.11107263334256907\n",
      "0.0009045084971874737\n",
      "Step 2 : loss = 0.1073307220065304\n",
      "0.0007938926261462366\n",
      "Step 3 : loss = 0.10429620137898987\n",
      "0.0006545084971874737\n",
      "Step 4 : loss = 0.10178145127600909\n",
      "0.0005\n",
      "Step 5 : loss = 0.09987494355391618\n",
      "0.00034549150281252633\n",
      "Step 6 : loss = 0.09837256575555314\n",
      "0.00020610737385376348\n",
      "Step 7 : loss = 0.09737491752435505\n",
      "9.549150281252633e-05\n",
      "Step 8 : loss = 0.09676282536372892\n",
      "2.4471741852423235e-05\n",
      "Step 9 : loss = 0.09649378212414732\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5833475440740585\n",
      "Step1 : loss = 1.4406149983406067\n",
      "Step2 : loss = 1.4080313667654991\n",
      "Step3 : loss = 1.35553989559412\n",
      "Step4 : loss = 1.3475774861872196\n",
      "Step5 : loss = 1.3299843780696392\n",
      "Step6 : loss = 1.3201789688318968\n",
      "Step7 : loss = 1.3108899630606174\n",
      "Step8 : loss = 1.3030521012842655\n",
      "Step9 : loss = 1.2990259267389774\n",
      "Data stream Batch- 7 : loss = 2.1331812739372253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml3 = []\n",
    "total = []\n",
    "all_eval_loss3 = []\n",
    "all_train_loss3 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval3 = []\n",
    "ftml_time3 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        ftml3, loss = train_maml(ftml3, meta_step, dtrainx, dtraint, dvalx, dvalt, ca=True)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml3, loss = update_procedure(ftml3,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml3, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time3.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval3.append(eval_loss)\n",
    "    all_train_loss3.append(train_loss)\n",
    "    all_eval_loss3.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(xtask_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval3)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task  0\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.508957386016846\n",
      "Step 1 : loss = 6.508957386016846\n",
      "Step 2 : loss = 6.508957386016846\n",
      "Step 3 : loss = 6.508957386016846\n",
      "Step 4 : loss = 6.508957386016846\n",
      "Step 5 : loss = 6.508957386016846\n",
      "Step 6 : loss = 6.508957386016846\n",
      "Step 7 : loss = 6.508957386016846\n",
      "Step 8 : loss = 6.508957386016846\n",
      "Step 9 : loss = 6.508957386016846\n",
      "Update Procedure\n",
      "Step0 : loss = 6.512442588806152\n",
      "Step1 : loss = 6.473971366882324\n",
      "Step2 : loss = 6.436473846435547\n",
      "Step3 : loss = 6.400020122528076\n",
      "Step4 : loss = 6.3647613525390625\n",
      "Step5 : loss = 6.329940319061279\n",
      "Step6 : loss = 6.295263767242432\n",
      "Step7 : loss = 6.260839939117432\n",
      "Step8 : loss = 6.226344108581543\n",
      "Step9 : loss = 6.193546772003174\n",
      "Data stream Batch- 0 : loss = 4.7126452922821045\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.58527946472168\n",
      "Step 1 : loss = 6.58527946472168\n",
      "Step 2 : loss = 6.58527946472168\n",
      "Step 3 : loss = 6.58527946472168\n",
      "Step 4 : loss = 6.58527946472168\n",
      "Step 5 : loss = 6.58527946472168\n",
      "Step 6 : loss = 6.58527946472168\n",
      "Step 7 : loss = 6.58527946472168\n",
      "Step 8 : loss = 6.58527946472168\n",
      "Step 9 : loss = 6.58527946472168\n",
      "Update Procedure\n",
      "Step0 : loss = 6.575343370437622\n",
      "Step1 : loss = 6.519871950149536\n",
      "Step2 : loss = 6.474368572235107\n",
      "Step3 : loss = 6.437036514282227\n",
      "Step4 : loss = 6.403577089309692\n",
      "Step5 : loss = 6.371511220932007\n",
      "Step6 : loss = 6.339781999588013\n",
      "Step7 : loss = 6.307190895080566\n",
      "Step8 : loss = 6.273083448410034\n",
      "Step9 : loss = 6.237393140792847\n",
      "Data stream Batch- 1 : loss = 4.536457777023315\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 6.7453023592631025\n",
      "Step 1 : loss = 6.7453023592631025\n",
      "Step 2 : loss = 6.7453023592631025\n",
      "Step 3 : loss = 6.7453023592631025\n",
      "Step 4 : loss = 6.7453023592631025\n",
      "Step 5 : loss = 6.7453023592631025\n",
      "Step 6 : loss = 6.7453023592631025\n",
      "Step 7 : loss = 6.7453023592631025\n",
      "Step 8 : loss = 6.7453023592631025\n",
      "Step 9 : loss = 6.7453023592631025\n",
      "Update Procedure\n",
      "Step0 : loss = 8.808582464853922\n",
      "Step1 : loss = 8.730385939280191\n",
      "Step2 : loss = 8.655544439951578\n",
      "Step3 : loss = 8.5807785987854\n",
      "Step4 : loss = 8.505273342132568\n",
      "Step5 : loss = 8.42786455154419\n",
      "Step6 : loss = 8.348198413848877\n",
      "Step7 : loss = 8.264741897583008\n",
      "Step8 : loss = 8.176887353261312\n",
      "Step9 : loss = 8.085098107655844\n",
      "Data stream Batch- 2 : loss = 4.27427875995636\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 3.2151248057683306\n",
      "Step 1 : loss = 3.2151248057683306\n",
      "Step 2 : loss = 3.2151248057683306\n",
      "Step 3 : loss = 3.2151248057683306\n",
      "Step 4 : loss = 3.2151248057683306\n",
      "Step 5 : loss = 3.2151248057683306\n",
      "Step 6 : loss = 3.2151248057683306\n",
      "Step 7 : loss = 3.2151248057683306\n",
      "Step 8 : loss = 3.2151248057683306\n",
      "Step 9 : loss = 3.2151248057683306\n",
      "Update Procedure\n",
      "Step0 : loss = 7.678404927253723\n",
      "Step1 : loss = 7.555198311805725\n",
      "Step2 : loss = 7.437477231025696\n",
      "Step3 : loss = 7.31890606880188\n",
      "Step4 : loss = 7.20115065574646\n",
      "Step5 : loss = 7.080683588981628\n",
      "Step6 : loss = 6.955711841583252\n",
      "Step7 : loss = 6.824718236923218\n",
      "Step8 : loss = 6.6900612115859985\n",
      "Step9 : loss = 6.551444411277771\n",
      "Data stream Batch- 3 : loss = 3.863783121109009\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 2.1345581889152525\n",
      "Step 1 : loss = 2.1157729029655457\n",
      "Step 2 : loss = 2.0967169602711997\n",
      "Step 3 : loss = 2.077527769406637\n",
      "Step 4 : loss = 2.0579878211021425\n",
      "Step 5 : loss = 2.0393347342809043\n",
      "Step 6 : loss = 2.0216283043225607\n",
      "Step 7 : loss = 2.004025673866272\n",
      "Step 8 : loss = 1.9884944796562194\n",
      "Step 9 : loss = 1.9741510669390359\n",
      "Update Procedure\n",
      "Step0 : loss = 6.451115131378174\n",
      "Step1 : loss = 6.302103281021118\n",
      "Step2 : loss = 6.183477306365967\n",
      "Step3 : loss = 6.07686333656311\n",
      "Step4 : loss = 5.981736564636231\n",
      "Step5 : loss = 5.893814992904663\n",
      "Step6 : loss = 5.804927968978882\n",
      "Step7 : loss = 5.713677883148193\n",
      "Step8 : loss = 5.621078538894653\n",
      "Step9 : loss = 5.525229740142822\n",
      "Data stream Batch- 4 : loss = 3.257089138031006\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 1.6726424866252476\n",
      "Step 1 : loss = 1.6648471477958893\n",
      "Step 2 : loss = 1.6566555029816097\n",
      "Step 3 : loss = 1.648114557729827\n",
      "Step 4 : loss = 1.6391338106658724\n",
      "Step 5 : loss = 1.6293446123600006\n",
      "Step 6 : loss = 1.6188449422518412\n",
      "Step 7 : loss = 1.6082854400078457\n",
      "Step 8 : loss = 1.5976130548450682\n",
      "Step 9 : loss = 1.586878882182969\n",
      "Update Procedure\n",
      "Step0 : loss = 5.7308277289072675\n",
      "Step1 : loss = 5.574074625968933\n",
      "Step2 : loss = 5.43632443745931\n",
      "Step3 : loss = 5.297173460324605\n",
      "Step4 : loss = 5.15533705552419\n",
      "Step5 : loss = 5.010160644849141\n",
      "Step6 : loss = 4.861936132113139\n",
      "Step7 : loss = 4.711429715156555\n",
      "Step8 : loss = 4.565081755320231\n",
      "Step9 : loss = 4.417194207509358\n",
      "Data stream Batch- 5 : loss = 2.595745086669922\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7884890601275459\n",
      "Step 1 : loss = 0.779738876885838\n",
      "Step 2 : loss = 0.7709221482276917\n",
      "Step 3 : loss = 0.7620247470954108\n",
      "Step 4 : loss = 0.7530205470228951\n",
      "Step 5 : loss = 0.74392062009327\n",
      "Step 6 : loss = 0.7346878695109533\n",
      "Step 7 : loss = 0.7253465448107038\n",
      "Step 8 : loss = 0.7158756178049813\n",
      "Step 9 : loss = 0.706265783404547\n",
      "Update Procedure\n",
      "Step0 : loss = 4.205802645002093\n",
      "Step1 : loss = 4.012598480497088\n",
      "Step2 : loss = 3.8529610633850098\n",
      "Step3 : loss = 3.69018748828343\n",
      "Step4 : loss = 3.5226469380514964\n",
      "Step5 : loss = 3.349240711757115\n",
      "Step6 : loss = 3.168381316321237\n",
      "Step7 : loss = 2.9890405109950473\n",
      "Step8 : loss = 2.811514513833182\n",
      "Step9 : loss = 2.635944434574672\n",
      "Data stream Batch- 6 : loss = 1.9989981055259705\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.33621440397072877\n",
      "Step 1 : loss = 0.3308673114323663\n",
      "Step 2 : loss = 0.32535106552143894\n",
      "Step 3 : loss = 0.31993947207986834\n",
      "Step 4 : loss = 0.3145738036475248\n",
      "Step 5 : loss = 0.30920410511039553\n",
      "Step 6 : loss = 0.3038328923817192\n",
      "Step 7 : loss = 0.2984669894068724\n",
      "Step 8 : loss = 0.2930250514357809\n",
      "Step 9 : loss = 0.2874834886914681\n",
      "Update Procedure\n",
      "Step0 : loss = 2.4985737055540085\n",
      "Step1 : loss = 2.3138504326343536\n",
      "Step2 : loss = 2.1999661177396774\n",
      "Step3 : loss = 2.0850963294506073\n",
      "Step4 : loss = 1.9853902608156204\n",
      "Step5 : loss = 1.8921190351247787\n",
      "Step6 : loss = 1.802182897925377\n",
      "Step7 : loss = 1.7175519913434982\n",
      "Step8 : loss = 1.640337012708187\n",
      "Step9 : loss = 1.5652295798063278\n",
      "Data stream Batch- 7 : loss = 2.0313929319381714\n",
      "Task  1\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7658027485013008\n",
      "Step 1 : loss = 0.7658027485013008\n",
      "Step 2 : loss = 0.7658027485013008\n",
      "Step 3 : loss = 0.7658027485013008\n",
      "Step 4 : loss = 0.7658027485013008\n",
      "Step 5 : loss = 0.7658027485013008\n",
      "Step 6 : loss = 0.7658027485013008\n",
      "Step 7 : loss = 0.7658027485013008\n",
      "Step 8 : loss = 0.7658027485013008\n",
      "Step 9 : loss = 0.7658027485013008\n",
      "Update Procedure\n",
      "Step0 : loss = 3.58390474319458\n",
      "Step1 : loss = 3.456372022628784\n",
      "Step2 : loss = 3.3440258502960205\n",
      "Step3 : loss = 3.247889995574951\n",
      "Step4 : loss = 3.1658124923706055\n",
      "Step5 : loss = 3.0872528553009033\n",
      "Step6 : loss = 3.0119028091430664\n",
      "Step7 : loss = 2.9442577362060547\n",
      "Step8 : loss = 2.8832366466522217\n",
      "Step9 : loss = 2.8304812908172607\n",
      "Data stream Batch- 0 : loss = 9.940898895263672\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7579771727323532\n",
      "Step 1 : loss = 0.7579771727323532\n",
      "Step 2 : loss = 0.7579771727323532\n",
      "Step 3 : loss = 0.7579771727323532\n",
      "Step 4 : loss = 0.7579771727323532\n",
      "Step 5 : loss = 0.7579771727323532\n",
      "Step 6 : loss = 0.7579771727323532\n",
      "Step 7 : loss = 0.7579771727323532\n",
      "Step 8 : loss = 0.7579771727323532\n",
      "Step 9 : loss = 0.7579771727323532\n",
      "Update Procedure\n",
      "Step0 : loss = 3.32547926902771\n",
      "Step1 : loss = 3.213266372680664\n",
      "Step2 : loss = 3.1177574396133423\n",
      "Step3 : loss = 3.0260943174362183\n",
      "Step4 : loss = 2.952802062034607\n",
      "Step5 : loss = 2.900788903236389\n",
      "Step6 : loss = 2.849343180656433\n",
      "Step7 : loss = 2.795105457305908\n",
      "Step8 : loss = 2.737864375114441\n",
      "Step9 : loss = 2.67894446849823\n",
      "Data stream Batch- 1 : loss = 10.257068634033203\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.8057149648666382\n",
      "Step 1 : loss = 0.8057149648666382\n",
      "Step 2 : loss = 0.8057149648666382\n",
      "Step 3 : loss = 0.8057149648666382\n",
      "Step 4 : loss = 0.8057149648666382\n",
      "Step 5 : loss = 0.8057149648666382\n",
      "Step 6 : loss = 0.8057149648666382\n",
      "Step 7 : loss = 0.8057149648666382\n",
      "Step 8 : loss = 0.8057149648666382\n",
      "Step 9 : loss = 0.8057149648666382\n",
      "Update Procedure\n",
      "Step0 : loss = 2.5076727867126465\n",
      "Step1 : loss = 2.4016613165537515\n",
      "Step2 : loss = 2.3171385129292807\n",
      "Step3 : loss = 2.2415868441263833\n",
      "Step4 : loss = 2.187023917833964\n",
      "Step5 : loss = 2.146289269129435\n",
      "Step6 : loss = 2.115392247835795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step7 : loss = 2.09362785021464\n",
      "Step8 : loss = 2.076277414957682\n",
      "Step9 : loss = 2.0579518477121987\n",
      "Data stream Batch- 2 : loss = 10.491040706634521\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.8952142496903737\n",
      "Step 1 : loss = 0.8952142496903737\n",
      "Step 2 : loss = 0.8952142496903737\n",
      "Step 3 : loss = 0.8952142496903737\n",
      "Step 4 : loss = 0.8952142496903737\n",
      "Step 5 : loss = 0.8952142496903737\n",
      "Step 6 : loss = 0.8952142496903737\n",
      "Step 7 : loss = 0.8952142496903737\n",
      "Step 8 : loss = 0.8952142496903737\n",
      "Step 9 : loss = 0.8952142496903737\n",
      "Update Procedure\n",
      "Step0 : loss = 1.9968641102313995\n",
      "Step1 : loss = 1.9063173830509186\n",
      "Step2 : loss = 1.8917694389820099\n",
      "Step3 : loss = 1.8626538813114166\n",
      "Step4 : loss = 1.8373600542545319\n",
      "Step5 : loss = 1.8125607669353485\n",
      "Step6 : loss = 1.7929083108901978\n",
      "Step7 : loss = 1.7774318754673004\n",
      "Step8 : loss = 1.7615001797676086\n",
      "Step9 : loss = 1.7468129396438599\n",
      "Data stream Batch- 3 : loss = 10.470377922058105\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.8879177272319794\n",
      "Step 1 : loss = 0.8625553548336029\n",
      "Step 2 : loss = 0.8368929127852123\n",
      "Step 3 : loss = 0.8111246327559154\n",
      "Step 4 : loss = 0.7853558162848155\n",
      "Step 5 : loss = 0.7595726350943248\n",
      "Step 6 : loss = 0.7342946132024128\n",
      "Step 7 : loss = 0.7090832591056824\n",
      "Step 8 : loss = 0.6837027470270793\n",
      "Step 9 : loss = 0.6583818793296814\n",
      "Update Procedure\n",
      "Step0 : loss = 2.2058094263076784\n",
      "Step1 : loss = 2.0696844100952148\n",
      "Step2 : loss = 2.0063928604125976\n",
      "Step3 : loss = 1.9560553789138795\n",
      "Step4 : loss = 1.914429783821106\n",
      "Step5 : loss = 1.887739109992981\n",
      "Step6 : loss = 1.8666920900344848\n",
      "Step7 : loss = 1.8467127323150634\n",
      "Step8 : loss = 1.8261103868484496\n",
      "Step9 : loss = 1.8076968669891358\n",
      "Data stream Batch- 4 : loss = 10.460296154022217\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.872321754693985\n",
      "Step 1 : loss = 0.8451328178246815\n",
      "Step 2 : loss = 0.8190245727698009\n",
      "Step 3 : loss = 0.7934048573176067\n",
      "Step 4 : loss = 0.7682924071947734\n",
      "Step 5 : loss = 0.7431367139021556\n",
      "Step 6 : loss = 0.7177821695804596\n",
      "Step 7 : loss = 0.6921667158603668\n",
      "Step 8 : loss = 0.666346549987793\n",
      "Step 9 : loss = 0.6404576500256856\n",
      "Update Procedure\n",
      "Step0 : loss = 3.8821428418159485\n",
      "Step1 : loss = 3.7669307589530945\n",
      "Step2 : loss = 3.692435324192047\n",
      "Step3 : loss = 3.6258915066719055\n",
      "Step4 : loss = 3.5772064526875815\n",
      "Step5 : loss = 3.531455377737681\n",
      "Step6 : loss = 3.4893646836280823\n",
      "Step7 : loss = 3.4469276467959085\n",
      "Step8 : loss = 3.402047355969747\n",
      "Step9 : loss = 3.3606660962104797\n",
      "Data stream Batch- 5 : loss = 9.443458557128906\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.7768024702866871\n",
      "Step 1 : loss = 0.7491249044736226\n",
      "Step 2 : loss = 0.7217546304066975\n",
      "Step 3 : loss = 0.694989949464798\n",
      "Step 4 : loss = 0.6695962846279144\n",
      "Step 5 : loss = 0.6444900532563527\n",
      "Step 6 : loss = 0.6198245187600453\n",
      "Step 7 : loss = 0.5957856824000676\n",
      "Step 8 : loss = 0.5723270525534947\n",
      "Step 9 : loss = 0.5493971953789394\n",
      "Update Procedure\n",
      "Step0 : loss = 4.538199118205479\n",
      "Step1 : loss = 4.39955701146807\n",
      "Step2 : loss = 4.282311303274972\n",
      "Step3 : loss = 4.1885225261960715\n",
      "Step4 : loss = 4.095765181950161\n",
      "Step5 : loss = 4.009219033377511\n",
      "Step6 : loss = 3.917872360774449\n",
      "Step7 : loss = 3.8159813029425487\n",
      "Step8 : loss = 3.7125845636640276\n",
      "Step9 : loss = 3.6036249569484164\n",
      "Data stream Batch- 6 : loss = 7.314979553222656\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6274737666050594\n",
      "Step 1 : loss = 0.6047365367412567\n",
      "Step 2 : loss = 0.5829404791196187\n",
      "Step 3 : loss = 0.5627990365028381\n",
      "Step 4 : loss = 0.5435539335012436\n",
      "Step 5 : loss = 0.5248616486787796\n",
      "Step 6 : loss = 0.5075330386559169\n",
      "Step 7 : loss = 0.4920739283164342\n",
      "Step 8 : loss = 0.47846226394176483\n",
      "Step 9 : loss = 0.4657932122548421\n",
      "Update Procedure\n",
      "Step0 : loss = 4.230044633150101\n",
      "Step1 : loss = 4.00290110707283\n",
      "Step2 : loss = 3.8255841434001923\n",
      "Step3 : loss = 3.6621275544166565\n",
      "Step4 : loss = 3.511597752571106\n",
      "Step5 : loss = 3.3555960208177567\n",
      "Step6 : loss = 3.191626325249672\n",
      "Step7 : loss = 3.017725870013237\n",
      "Step8 : loss = 2.833339974284172\n",
      "Step9 : loss = 2.6363429874181747\n",
      "Data stream Batch- 7 : loss = 3.7008213996887207\n",
      "Task  2\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5882852245802208\n",
      "Step 1 : loss = 0.5882852245802208\n",
      "Step 2 : loss = 0.5882852245802208\n",
      "Step 3 : loss = 0.5882852245802208\n",
      "Step 4 : loss = 0.5882852245802208\n",
      "Step 5 : loss = 0.5882852245802208\n",
      "Step 6 : loss = 0.5882852245802208\n",
      "Step 7 : loss = 0.5882852245802208\n",
      "Step 8 : loss = 0.5882852245802208\n",
      "Step 9 : loss = 0.5882852245802208\n",
      "Update Procedure\n",
      "Step0 : loss = 3.3492891788482666\n",
      "Step1 : loss = 2.962137460708618\n",
      "Step2 : loss = 2.6041228771209717\n",
      "Step3 : loss = 2.2927467823028564\n",
      "Step4 : loss = 2.0669431686401367\n",
      "Step5 : loss = 1.896366000175476\n",
      "Step6 : loss = 1.757262110710144\n",
      "Step7 : loss = 1.6516852378845215\n",
      "Step8 : loss = 1.5918949842453003\n",
      "Step9 : loss = 1.5504918098449707\n",
      "Data stream Batch- 0 : loss = 5.381276845932007\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6601939714853726\n",
      "Step 1 : loss = 0.6601939714853726\n",
      "Step 2 : loss = 0.6601939714853726\n",
      "Step 3 : loss = 0.6601939714853726\n",
      "Step 4 : loss = 0.6601939714853726\n",
      "Step 5 : loss = 0.6601939714853726\n",
      "Step 6 : loss = 0.6601939714853726\n",
      "Step 7 : loss = 0.6601939714853726\n",
      "Step 8 : loss = 0.6601939714853726\n",
      "Step 9 : loss = 0.6601939714853726\n",
      "Update Procedure\n",
      "Step0 : loss = 2.364945948123932\n",
      "Step1 : loss = 2.0841885209083557\n",
      "Step2 : loss = 1.9031962156295776\n",
      "Step3 : loss = 1.7638999819755554\n",
      "Step4 : loss = 1.647607147693634\n",
      "Step5 : loss = 1.5262847542762756\n",
      "Step6 : loss = 1.4263619780540466\n",
      "Step7 : loss = 1.3565340638160706\n",
      "Step8 : loss = 1.307483732700348\n",
      "Step9 : loss = 1.2596322298049927\n",
      "Data stream Batch- 1 : loss = 5.334091424942017\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6054534005503805\n",
      "Step 1 : loss = 0.6054534005503805\n",
      "Step 2 : loss = 0.6054534005503805\n",
      "Step 3 : loss = 0.6054534005503805\n",
      "Step 4 : loss = 0.6054534005503805\n",
      "Step 5 : loss = 0.6054534005503805\n",
      "Step 6 : loss = 0.6054534005503805\n",
      "Step 7 : loss = 0.6054534005503805\n",
      "Step 8 : loss = 0.6054534005503805\n",
      "Step 9 : loss = 0.6054534005503805\n",
      "Update Procedure\n",
      "Step0 : loss = 1.285020073254903\n",
      "Step1 : loss = 1.1547722816467285\n",
      "Step2 : loss = 1.0359732309977214\n",
      "Step3 : loss = 0.9767918586730957\n",
      "Step4 : loss = 0.9280574321746826\n",
      "Step5 : loss = 0.8977667689323425\n",
      "Step6 : loss = 0.8699565927187601\n",
      "Step7 : loss = 0.8461813926696777\n",
      "Step8 : loss = 0.8337761958440145\n",
      "Step9 : loss = 0.8157553474108378\n",
      "Data stream Batch- 2 : loss = 5.389403343200684\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6176229064012804\n",
      "Step 1 : loss = 0.6176229064012804\n",
      "Step 2 : loss = 0.6176229064012804\n",
      "Step 3 : loss = 0.6176229064012804\n",
      "Step 4 : loss = 0.6176229064012804\n",
      "Step 5 : loss = 0.6176229064012804\n",
      "Step 6 : loss = 0.6176229064012804\n",
      "Step 7 : loss = 0.6176229064012804\n",
      "Step 8 : loss = 0.6176229064012804\n",
      "Step 9 : loss = 0.6176229064012804\n",
      "Update Procedure\n",
      "Step0 : loss = 0.9453139454126358\n",
      "Step1 : loss = 0.8909474760293961\n",
      "Step2 : loss = 0.866618737578392\n",
      "Step3 : loss = 0.8510081022977829\n",
      "Step4 : loss = 0.8254631906747818\n",
      "Step5 : loss = 0.807502955198288\n",
      "Step6 : loss = 0.7962609827518463\n",
      "Step7 : loss = 0.7820226699113846\n",
      "Step8 : loss = 0.768399715423584\n",
      "Step9 : loss = 0.7536294162273407\n",
      "Data stream Batch- 3 : loss = 5.581311225891113\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.6370248788760768\n",
      "Step 1 : loss = 0.6155980886034076\n",
      "Step 2 : loss = 0.5943742221605683\n",
      "Step 3 : loss = 0.5737087590945146\n",
      "Step 4 : loss = 0.5538502756210547\n",
      "Step 5 : loss = 0.535859677491207\n",
      "Step 6 : loss = 0.5221770292798441\n",
      "Step 7 : loss = 0.5132460409716245\n",
      "Step 8 : loss = 0.5063711351729812\n",
      "Step 9 : loss = 0.4999202461085386\n",
      "Update Procedure\n",
      "Step0 : loss = 2.1977638483047484\n",
      "Step1 : loss = 1.3292186856269836\n",
      "Step2 : loss = 1.3971269845962524\n",
      "Step3 : loss = 1.1416836619377135\n",
      "Step4 : loss = 1.114153552055359\n",
      "Step5 : loss = 1.0684163570404053\n",
      "Step6 : loss = 0.9984172463417054\n",
      "Step7 : loss = 0.9672217607498169\n",
      "Step8 : loss = 0.9322337150573731\n",
      "Step9 : loss = 0.9118778467178345\n",
      "Data stream Batch- 4 : loss = 5.59060263633728\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.5933530601480651\n",
      "Step 1 : loss = 0.5721862186869932\n",
      "Step 2 : loss = 0.5517890657224352\n",
      "Step 3 : loss = 0.5327663063116017\n",
      "Step 4 : loss = 0.5154558451757545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 : loss = 0.5008018543500276\n",
      "Step 6 : loss = 0.49019543010564076\n",
      "Step 7 : loss = 0.48192320397744576\n",
      "Step 8 : loss = 0.47425489588566716\n",
      "Step 9 : loss = 0.4666667250738967\n",
      "Update Procedure\n",
      "Step0 : loss = 2.4508458574612937\n",
      "Step1 : loss = 1.7878702878952026\n",
      "Step2 : loss = 1.7406015694141388\n",
      "Step3 : loss = 1.6300131181875865\n",
      "Step4 : loss = 1.5953895350297291\n",
      "Step5 : loss = 1.5358901619911194\n",
      "Step6 : loss = 1.4685522218545277\n",
      "Step7 : loss = 1.4065919419129689\n",
      "Step8 : loss = 1.3467606405417125\n",
      "Step9 : loss = 1.291442980368932\n",
      "Data stream Batch- 5 : loss = 4.085018634796143\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.547340253291149\n",
      "Step 1 : loss = 0.5265172499631132\n",
      "Step 2 : loss = 0.5068273168352861\n",
      "Step 3 : loss = 0.4879048345935723\n",
      "Step 4 : loss = 0.4708755676294603\n",
      "Step 5 : loss = 0.45495479730150057\n",
      "Step 6 : loss = 0.4428551870058217\n",
      "Step 7 : loss = 0.4335587264289932\n",
      "Step 8 : loss = 0.4254114506736634\n",
      "Step 9 : loss = 0.4178116089146998\n",
      "Update Procedure\n",
      "Step0 : loss = 2.333966016769409\n",
      "Step1 : loss = 1.8020196216447013\n",
      "Step2 : loss = 1.6423232385090418\n",
      "Step3 : loss = 1.5732885343687875\n",
      "Step4 : loss = 1.4698506167956762\n",
      "Step5 : loss = 1.4115578021321977\n",
      "Step6 : loss = 1.3626267995153154\n",
      "Step7 : loss = 1.3093201092311315\n",
      "Step8 : loss = 1.2604787179401942\n",
      "Step9 : loss = 1.2111016597066606\n",
      "Data stream Batch- 6 : loss = 2.487874746322632\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.502208874705765\n",
      "Step 1 : loss = 0.48224749031166236\n",
      "Step 2 : loss = 0.462385063411461\n",
      "Step 3 : loss = 0.44305148120555615\n",
      "Step 4 : loss = 0.42495592348277567\n",
      "Step 5 : loss = 0.4096255492478136\n",
      "Step 6 : loss = 0.3983156571903872\n",
      "Step 7 : loss = 0.3895596870709033\n",
      "Step 8 : loss = 0.38110450690996556\n",
      "Step 9 : loss = 0.3731925557234458\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8486562967300415\n",
      "Step1 : loss = 1.517894260585308\n",
      "Step2 : loss = 1.2994620651006699\n",
      "Step3 : loss = 1.23561692237854\n",
      "Step4 : loss = 1.1481263786554337\n",
      "Step5 : loss = 1.0761129185557365\n",
      "Step6 : loss = 1.020279835909605\n",
      "Step7 : loss = 0.9703935757279396\n",
      "Step8 : loss = 0.9221858084201813\n",
      "Step9 : loss = 0.8755157440900803\n",
      "Data stream Batch- 7 : loss = 1.2864230871200562\n",
      "Task  3\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.09352408413189474\n",
      "Step 1 : loss = 0.09352408413189474\n",
      "Step 2 : loss = 0.09352408413189474\n",
      "Step 3 : loss = 0.09352408413189474\n",
      "Step 4 : loss = 0.09352408413189474\n",
      "Step 5 : loss = 0.09352408413189474\n",
      "Step 6 : loss = 0.09352408413189474\n",
      "Step 7 : loss = 0.09352408413189474\n",
      "Step 8 : loss = 0.09352408413189474\n",
      "Step 9 : loss = 0.09352408413189474\n",
      "Update Procedure\n",
      "Step0 : loss = 8.259700775146484\n",
      "Step1 : loss = 8.105998992919922\n",
      "Step2 : loss = 7.958066940307617\n",
      "Step3 : loss = 7.812530517578125\n",
      "Step4 : loss = 7.668520450592041\n",
      "Step5 : loss = 7.525444984436035\n",
      "Step6 : loss = 7.383749485015869\n",
      "Step7 : loss = 7.243538856506348\n",
      "Step8 : loss = 7.106225490570068\n",
      "Step9 : loss = 6.970974922180176\n",
      "Data stream Batch- 0 : loss = 4.8872246742248535\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.11938757405797272\n",
      "Step 1 : loss = 0.11938757405797272\n",
      "Step 2 : loss = 0.11938757405797272\n",
      "Step 3 : loss = 0.11938757405797272\n",
      "Step 4 : loss = 0.11938757405797272\n",
      "Step 5 : loss = 0.11938757405797272\n",
      "Step 6 : loss = 0.11938757405797272\n",
      "Step 7 : loss = 0.11938757405797272\n",
      "Step 8 : loss = 0.11938757405797272\n",
      "Step 9 : loss = 0.11938757405797272\n",
      "Update Procedure\n",
      "Step0 : loss = 6.95328426361084\n",
      "Step1 : loss = 6.642617225646973\n",
      "Step2 : loss = 6.360761880874634\n",
      "Step3 : loss = 6.098835706710815\n",
      "Step4 : loss = 5.912229061126709\n",
      "Step5 : loss = 5.741392612457275\n",
      "Step6 : loss = 5.566744089126587\n",
      "Step7 : loss = 5.389850616455078\n",
      "Step8 : loss = 5.216773748397827\n",
      "Step9 : loss = 5.050937175750732\n",
      "Data stream Batch- 1 : loss = 4.317631959915161\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.19326992880717161\n",
      "Step 1 : loss = 0.19326992880717161\n",
      "Step 2 : loss = 0.19326992880717161\n",
      "Step 3 : loss = 0.19326992880717161\n",
      "Step 4 : loss = 0.19326992880717161\n",
      "Step 5 : loss = 0.19326992880717161\n",
      "Step 6 : loss = 0.19326992880717161\n",
      "Step 7 : loss = 0.19326992880717161\n",
      "Step 8 : loss = 0.19326992880717161\n",
      "Step 9 : loss = 0.19326992880717161\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9361554781595864\n",
      "Step1 : loss = 3.7267476320266724\n",
      "Step2 : loss = 3.5901376406351724\n",
      "Step3 : loss = 3.49083145459493\n",
      "Step4 : loss = 3.405427098274231\n",
      "Step5 : loss = 3.3300347328186035\n",
      "Step6 : loss = 3.265684445699056\n",
      "Step7 : loss = 3.2080429792404175\n",
      "Step8 : loss = 3.150754690170288\n",
      "Step9 : loss = 3.092747926712036\n",
      "Data stream Batch- 2 : loss = 4.100864410400391\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.2643180455558419\n",
      "Step 1 : loss = 0.2643180455558419\n",
      "Step 2 : loss = 0.2643180455558419\n",
      "Step 3 : loss = 0.2643180455558419\n",
      "Step 4 : loss = 0.2643180455558419\n",
      "Step 5 : loss = 0.2643180455558419\n",
      "Step 6 : loss = 0.2643180455558419\n",
      "Step 7 : loss = 0.2643180455558419\n",
      "Step 8 : loss = 0.2643180455558419\n",
      "Step 9 : loss = 0.2643180455558419\n",
      "Update Procedure\n",
      "Step0 : loss = 2.45828278362751\n",
      "Step1 : loss = 2.33659665286541\n",
      "Step2 : loss = 2.279441259801388\n",
      "Step3 : loss = 2.235115848481655\n",
      "Step4 : loss = 2.1918371096253395\n",
      "Step5 : loss = 2.1466025039553642\n",
      "Step6 : loss = 2.101618282496929\n",
      "Step7 : loss = 2.064024142920971\n",
      "Step8 : loss = 2.0290705636143684\n",
      "Step9 : loss = 1.9986478090286255\n",
      "Data stream Batch- 3 : loss = 4.196430921554565\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.3257396323198508\n",
      "Step 1 : loss = 0.3116106227773184\n",
      "Step 2 : loss = 0.29794900722330625\n",
      "Step 3 : loss = 0.2846327592580736\n",
      "Step 4 : loss = 0.2716277657183243\n",
      "Step 5 : loss = 0.25903898828355776\n",
      "Step 6 : loss = 0.24667515881670612\n",
      "Step 7 : loss = 0.23457567221523504\n",
      "Step 8 : loss = 0.22269864307718779\n",
      "Step 9 : loss = 0.2110750371983029\n",
      "Update Procedure\n",
      "Step0 : loss = 2.504063272476196\n",
      "Step1 : loss = 2.3412234663963316\n",
      "Step2 : loss = 2.292837363481522\n",
      "Step3 : loss = 2.2388810217380524\n",
      "Step4 : loss = 2.1800232946872713\n",
      "Step5 : loss = 2.133892071247101\n",
      "Step6 : loss = 2.088965916633606\n",
      "Step7 : loss = 2.056003975868225\n",
      "Step8 : loss = 2.0239910185337067\n",
      "Step9 : loss = 1.9920306026935577\n",
      "Data stream Batch- 4 : loss = 3.7841949462890625\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.26216993664678584\n",
      "Step 1 : loss = 0.24929666572118078\n",
      "Step 2 : loss = 0.2368092340622405\n",
      "Step 3 : loss = 0.22474010611822526\n",
      "Step 4 : loss = 0.21279286705329795\n",
      "Step 5 : loss = 0.20101259840179642\n",
      "Step 6 : loss = 0.18948894644984637\n",
      "Step 7 : loss = 0.17872445457573846\n",
      "Step 8 : loss = 0.16869736819093764\n",
      "Step 9 : loss = 0.16009210781879088\n",
      "Update Procedure\n",
      "Step0 : loss = 2.344891513387362\n",
      "Step1 : loss = 2.2371755043665567\n",
      "Step2 : loss = 2.1488611698150635\n",
      "Step3 : loss = 2.0922087679306665\n",
      "Step4 : loss = 2.05153127014637\n",
      "Step5 : loss = 1.9990759094556172\n",
      "Step6 : loss = 1.9654329220453899\n",
      "Step7 : loss = 1.9327772756417592\n",
      "Step8 : loss = 1.9003809988498688\n",
      "Step9 : loss = 1.871353084842364\n",
      "Data stream Batch- 5 : loss = 2.640652060508728\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.17034118540249513\n",
      "Step 1 : loss = 0.1595731766224018\n",
      "Step 2 : loss = 0.15121460633829684\n",
      "Step 3 : loss = 0.1458504241915988\n",
      "Step 4 : loss = 0.1408294604550775\n",
      "Step 5 : loss = 0.1357553482365316\n",
      "Step 6 : loss = 0.13057399216731294\n",
      "Step 7 : loss = 0.1255196827053792\n",
      "Step 8 : loss = 0.12032424922890816\n",
      "Step 9 : loss = 0.1152786419748326\n",
      "Update Procedure\n",
      "Step0 : loss = 2.1312204216207777\n",
      "Step1 : loss = 1.9321450591087341\n",
      "Step2 : loss = 1.8347256864820207\n",
      "Step3 : loss = 1.776115140744618\n",
      "Step4 : loss = 1.7371963518006461\n",
      "Step5 : loss = 1.7069603673049383\n",
      "Step6 : loss = 1.6806510559150152\n",
      "Step7 : loss = 1.654949345758983\n",
      "Step8 : loss = 1.6320633717945643\n",
      "Step9 : loss = 1.6121913279805864\n",
      "Data stream Batch- 6 : loss = 2.2124439477920532\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.1875776995145789\n",
      "Step 1 : loss = 0.17087026591635987\n",
      "Step 2 : loss = 0.1546232755186917\n",
      "Step 3 : loss = 0.14179663324227434\n",
      "Step 4 : loss = 0.13614759855666936\n",
      "Step 5 : loss = 0.13139653882906932\n",
      "Step 6 : loss = 0.1251109137643545\n",
      "Step 7 : loss = 0.1202585972763228\n",
      "Step 8 : loss = 0.11454781589162034\n",
      "Step 9 : loss = 0.11053349416016826\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7601582407951355\n",
      "Step1 : loss = 1.6270768865942955\n",
      "Step2 : loss = 1.581209234893322\n",
      "Step3 : loss = 1.5073996484279633\n",
      "Step4 : loss = 1.4747001715004444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step5 : loss = 1.4609079211950302\n",
      "Step6 : loss = 1.4464814402163029\n",
      "Step7 : loss = 1.428313359618187\n",
      "Step8 : loss = 1.4161045476794243\n",
      "Step9 : loss = 1.4010172672569752\n",
      "Data stream Batch- 7 : loss = 2.034505009651184\n",
      "Task  4\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.045542065054222945\n",
      "Step 1 : loss = 0.045542065054222945\n",
      "Step 2 : loss = 0.045542065054222945\n",
      "Step 3 : loss = 0.045542065054222945\n",
      "Step 4 : loss = 0.045542065054222945\n",
      "Step 5 : loss = 0.045542065054222945\n",
      "Step 6 : loss = 0.045542065054222945\n",
      "Step 7 : loss = 0.045542065054222945\n",
      "Step 8 : loss = 0.045542065054222945\n",
      "Step 9 : loss = 0.045542065054222945\n",
      "Update Procedure\n",
      "Step0 : loss = 4.85824728012085\n",
      "Step1 : loss = 4.6004204750061035\n",
      "Step2 : loss = 4.344136714935303\n",
      "Step3 : loss = 4.090167999267578\n",
      "Step4 : loss = 3.8381683826446533\n",
      "Step5 : loss = 3.6107099056243896\n",
      "Step6 : loss = 3.4815855026245117\n",
      "Step7 : loss = 3.4372951984405518\n",
      "Step8 : loss = 3.4001355171203613\n",
      "Step9 : loss = 3.3391594886779785\n",
      "Data stream Batch- 0 : loss = 5.074834108352661\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.12377386768898294\n",
      "Step 1 : loss = 0.12377386768898294\n",
      "Step 2 : loss = 0.12377386768898294\n",
      "Step 3 : loss = 0.12377386768898294\n",
      "Step 4 : loss = 0.12377386768898294\n",
      "Step 5 : loss = 0.12377386768898294\n",
      "Step 6 : loss = 0.12377386768898294\n",
      "Step 7 : loss = 0.12377386768898294\n",
      "Step 8 : loss = 0.12377386768898294\n",
      "Step 9 : loss = 0.12377386768898294\n",
      "Update Procedure\n",
      "Step0 : loss = 4.454900145530701\n",
      "Step1 : loss = 4.057291507720947\n",
      "Step2 : loss = 3.785021424293518\n",
      "Step3 : loss = 3.5323634147644043\n",
      "Step4 : loss = 3.2808724641799927\n",
      "Step5 : loss = 3.029547691345215\n",
      "Step6 : loss = 2.784924268722534\n",
      "Step7 : loss = 2.550747871398926\n",
      "Step8 : loss = 2.3442089557647705\n",
      "Step9 : loss = 2.1548872590065002\n",
      "Data stream Batch- 1 : loss = 4.5706541538238525\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.20013985704204537\n",
      "Step 1 : loss = 0.20013985704204537\n",
      "Step 2 : loss = 0.20013985704204537\n",
      "Step 3 : loss = 0.20013985704204537\n",
      "Step 4 : loss = 0.20013985704204537\n",
      "Step 5 : loss = 0.20013985704204537\n",
      "Step 6 : loss = 0.20013985704204537\n",
      "Step 7 : loss = 0.20013985704204537\n",
      "Step 8 : loss = 0.20013985704204537\n",
      "Step 9 : loss = 0.20013985704204537\n",
      "Update Procedure\n",
      "Step0 : loss = 3.077871561050415\n",
      "Step1 : loss = 2.7182451486587524\n",
      "Step2 : loss = 2.3959058125813804\n",
      "Step3 : loss = 2.1152238647143045\n",
      "Step4 : loss = 1.920584221680959\n",
      "Step5 : loss = 1.8111766576766968\n",
      "Step6 : loss = 1.7349178791046143\n",
      "Step7 : loss = 1.6613298654556274\n",
      "Step8 : loss = 1.5842627882957458\n",
      "Step9 : loss = 1.5050160189469655\n",
      "Data stream Batch- 2 : loss = 4.469029664993286\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.3337646988241677\n",
      "Step 1 : loss = 0.3337646988241677\n",
      "Step 2 : loss = 0.3337646988241677\n",
      "Step 3 : loss = 0.3337646988241677\n",
      "Step 4 : loss = 0.3337646988241677\n",
      "Step 5 : loss = 0.3337646988241677\n",
      "Step 6 : loss = 0.3337646988241677\n",
      "Step 7 : loss = 0.3337646988241677\n",
      "Step 8 : loss = 0.3337646988241677\n",
      "Step 9 : loss = 0.3337646988241677\n",
      "Update Procedure\n",
      "Step0 : loss = 2.61486604064703\n",
      "Step1 : loss = 2.482555776834488\n",
      "Step2 : loss = 2.355870693922043\n",
      "Step3 : loss = 2.237510770559311\n",
      "Step4 : loss = 2.13201180100441\n",
      "Step5 : loss = 2.0324542075395584\n",
      "Step6 : loss = 1.9475294426083565\n",
      "Step7 : loss = 1.8688339665532112\n",
      "Step8 : loss = 1.7873962670564651\n",
      "Step9 : loss = 1.7080881595611572\n",
      "Data stream Batch- 3 : loss = 4.539636135101318\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.34306818739725264\n",
      "Step 1 : loss = 0.3299906994194534\n",
      "Step 2 : loss = 0.3170198120997892\n",
      "Step 3 : loss = 0.30420097781997957\n",
      "Step 4 : loss = 0.29298376211599336\n",
      "Step 5 : loss = 0.28340139945489834\n",
      "Step 6 : loss = 0.27444780241177924\n",
      "Step 7 : loss = 0.26608314833787666\n",
      "Step 8 : loss = 0.25762480735564924\n",
      "Step 9 : loss = 0.24913273156682997\n",
      "Update Procedure\n",
      "Step0 : loss = 3.7291399955749513\n",
      "Step1 : loss = 3.3257627487182617\n",
      "Step2 : loss = 3.0855704963207247\n",
      "Step3 : loss = 2.922736167907715\n",
      "Step4 : loss = 2.813287651538849\n",
      "Step5 : loss = 2.713936817646027\n",
      "Step6 : loss = 2.6095540285110475\n",
      "Step7 : loss = 2.499969798326492\n",
      "Step8 : loss = 2.396110999584198\n",
      "Step9 : loss = 2.302466106414795\n",
      "Data stream Batch- 4 : loss = 4.082184672355652\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.3853453571569896\n",
      "Step 1 : loss = 0.37227950543507043\n",
      "Step 2 : loss = 0.35891269109810336\n",
      "Step 3 : loss = 0.3447708189999597\n",
      "Step 4 : loss = 0.3305563194374405\n",
      "Step 5 : loss = 0.31676322125325274\n",
      "Step 6 : loss = 0.30451620169580496\n",
      "Step 7 : loss = 0.29431206690759487\n",
      "Step 8 : loss = 0.28519765181546886\n",
      "Step 9 : loss = 0.27667889126432577\n",
      "Update Procedure\n",
      "Step0 : loss = 3.0972882509231567\n",
      "Step1 : loss = 2.6472646792729697\n",
      "Step2 : loss = 2.432279755671819\n",
      "Step3 : loss = 2.2768649458885193\n",
      "Step4 : loss = 2.176707297563553\n",
      "Step5 : loss = 2.0679062753915787\n",
      "Step6 : loss = 1.962997908393542\n",
      "Step7 : loss = 1.8710306038459141\n",
      "Step8 : loss = 1.784369985262553\n",
      "Step9 : loss = 1.7063327232996623\n",
      "Data stream Batch- 5 : loss = 2.5961908102035522\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4151777728632739\n",
      "Step 1 : loss = 0.401904696558835\n",
      "Step 2 : loss = 0.3885536325144209\n",
      "Step 3 : loss = 0.37512788224964405\n",
      "Step 4 : loss = 0.36122803598326275\n",
      "Step 5 : loss = 0.3462742234316981\n",
      "Step 6 : loss = 0.332276453888888\n",
      "Step 7 : loss = 0.32085924594747794\n",
      "Step 8 : loss = 0.31124500295641183\n",
      "Step 9 : loss = 0.3026185367529173\n",
      "Update Procedure\n",
      "Step0 : loss = 2.280671102660043\n",
      "Step1 : loss = 1.8226565633501326\n",
      "Step2 : loss = 1.6720696219376154\n",
      "Step3 : loss = 1.5784902700356074\n",
      "Step4 : loss = 1.5160238231931413\n",
      "Step5 : loss = 1.4421714629445757\n",
      "Step6 : loss = 1.3846292538302285\n",
      "Step7 : loss = 1.3346386679581232\n",
      "Step8 : loss = 1.2915706293923515\n",
      "Step9 : loss = 1.2607871804918562\n",
      "Data stream Batch- 6 : loss = 1.6967976689338684\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.4147578066754231\n",
      "Step 1 : loss = 0.40050611908767675\n",
      "Step 2 : loss = 0.3860150557183677\n",
      "Step 3 : loss = 0.3707492491201449\n",
      "Step 4 : loss = 0.3549967099953119\n",
      "Step 5 : loss = 0.3411473566788257\n",
      "Step 6 : loss = 0.3297567696922146\n",
      "Step 7 : loss = 0.3205121032535663\n",
      "Step 8 : loss = 0.311733419808138\n",
      "Step 9 : loss = 0.30281693150488337\n",
      "Update Procedure\n",
      "Step0 : loss = 1.731851726770401\n",
      "Step1 : loss = 1.3724225610494614\n",
      "Step2 : loss = 1.2374538145959377\n",
      "Step3 : loss = 1.1968006826937199\n",
      "Step4 : loss = 1.1559286192059517\n",
      "Step5 : loss = 1.117489978671074\n",
      "Step6 : loss = 1.0862507708370686\n",
      "Step7 : loss = 1.0595851689577103\n",
      "Step8 : loss = 1.038581971079111\n",
      "Step9 : loss = 1.017452698200941\n",
      "Data stream Batch- 7 : loss = 1.261244297027588\n",
      "Task  5\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.0346415443160288\n",
      "Step 1 : loss = 0.0346415443160288\n",
      "Step 2 : loss = 0.0346415443160288\n",
      "Step 3 : loss = 0.0346415443160288\n",
      "Step 4 : loss = 0.0346415443160288\n",
      "Step 5 : loss = 0.0346415443160288\n",
      "Step 6 : loss = 0.0346415443160288\n",
      "Step 7 : loss = 0.0346415443160288\n",
      "Step 8 : loss = 0.0346415443160288\n",
      "Step 9 : loss = 0.0346415443160288\n",
      "Update Procedure\n",
      "Step0 : loss = 3.3826656341552734\n",
      "Step1 : loss = 3.1374311447143555\n",
      "Step2 : loss = 2.8911876678466797\n",
      "Step3 : loss = 2.6429355144500732\n",
      "Step4 : loss = 2.4056272506713867\n",
      "Step5 : loss = 2.1996266841888428\n",
      "Step6 : loss = 2.098050594329834\n",
      "Step7 : loss = 2.060889959335327\n",
      "Step8 : loss = 2.025282144546509\n",
      "Step9 : loss = 1.9841276407241821\n",
      "Data stream Batch- 0 : loss = 3.3088070154190063\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.035405987876022005\n",
      "Step 1 : loss = 0.035405987876022005\n",
      "Step 2 : loss = 0.035405987876022005\n",
      "Step 3 : loss = 0.035405987876022005\n",
      "Step 4 : loss = 0.035405987876022005\n",
      "Step 5 : loss = 0.035405987876022005\n",
      "Step 6 : loss = 0.035405987876022005\n",
      "Step 7 : loss = 0.035405987876022005\n",
      "Step 8 : loss = 0.035405987876022005\n",
      "Step 9 : loss = 0.035405987876022005\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6934558749198914\n",
      "Step1 : loss = 1.4227211475372314\n",
      "Step2 : loss = 1.371452271938324\n",
      "Step3 : loss = 1.3339853882789612\n",
      "Step4 : loss = 1.2286224663257599\n",
      "Step5 : loss = 1.1678279340267181\n",
      "Step6 : loss = 1.1247839033603668\n",
      "Step7 : loss = 1.0805200636386871\n",
      "Step8 : loss = 1.067229151725769\n",
      "Step9 : loss = 1.046541541814804\n",
      "Data stream Batch- 1 : loss = 3.719948649406433\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.05266764035732514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 : loss = 0.05266764035732514\n",
      "Step 2 : loss = 0.05266764035732514\n",
      "Step 3 : loss = 0.05266764035732514\n",
      "Step 4 : loss = 0.05266764035732514\n",
      "Step 5 : loss = 0.05266764035732514\n",
      "Step 6 : loss = 0.05266764035732514\n",
      "Step 7 : loss = 0.05266764035732514\n",
      "Step 8 : loss = 0.05266764035732514\n",
      "Step 9 : loss = 0.05266764035732514\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7498430411020915\n",
      "Step1 : loss = 1.7000245650609334\n",
      "Step2 : loss = 1.6019582152366638\n",
      "Step3 : loss = 1.5349771579106648\n",
      "Step4 : loss = 1.4600135684013367\n",
      "Step5 : loss = 1.4083773295084636\n",
      "Step6 : loss = 1.3523998260498047\n",
      "Step7 : loss = 1.2967971563339233\n",
      "Step8 : loss = 1.2373331983884175\n",
      "Step9 : loss = 1.202855368455251\n",
      "Data stream Batch- 2 : loss = 3.7099231481552124\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.06288182111773744\n",
      "Step 1 : loss = 0.06288182111773744\n",
      "Step 2 : loss = 0.06288182111773744\n",
      "Step 3 : loss = 0.06288182111773744\n",
      "Step 4 : loss = 0.06288182111773744\n",
      "Step 5 : loss = 0.06288182111773744\n",
      "Step 6 : loss = 0.06288182111773744\n",
      "Step 7 : loss = 0.06288182111773744\n",
      "Step 8 : loss = 0.06288182111773744\n",
      "Step 9 : loss = 0.06288182111773744\n",
      "Update Procedure\n",
      "Step0 : loss = 1.8599882274866104\n",
      "Step1 : loss = 1.7971194088459015\n",
      "Step2 : loss = 1.6982537060976028\n",
      "Step3 : loss = 1.6048658415675163\n",
      "Step4 : loss = 1.524234876036644\n",
      "Step5 : loss = 1.447858303785324\n",
      "Step6 : loss = 1.3879401683807373\n",
      "Step7 : loss = 1.353792317211628\n",
      "Step8 : loss = 1.3310110569000244\n",
      "Step9 : loss = 1.3023337423801422\n",
      "Data stream Batch- 3 : loss = 3.6380809545516968\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.03693151139791005\n",
      "Step 1 : loss = 0.03147909523599494\n",
      "Step 2 : loss = 0.02748449418371854\n",
      "Step 3 : loss = 0.024530337307868622\n",
      "Step 4 : loss = 0.022969186708902127\n",
      "Step 5 : loss = 0.021515692018107584\n",
      "Step 6 : loss = 0.02046287277132357\n",
      "Step 7 : loss = 0.01983568737814641\n",
      "Step 8 : loss = 0.019098867979649284\n",
      "Step 9 : loss = 0.01859189457894277\n",
      "Update Procedure\n",
      "Step0 : loss = 1.6052590787410737\n",
      "Step1 : loss = 1.4233253598213196\n",
      "Step2 : loss = 1.3003189742565155\n",
      "Step3 : loss = 1.2677153468132019\n",
      "Step4 : loss = 1.2272293388843536\n",
      "Step5 : loss = 1.1811193108558655\n",
      "Step6 : loss = 1.1561793446540833\n",
      "Step7 : loss = 1.1157620966434478\n",
      "Step8 : loss = 1.089071476459503\n",
      "Step9 : loss = 1.0531992256641387\n",
      "Data stream Batch- 4 : loss = 3.290781855583191\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.03398831697515333\n",
      "Step 1 : loss = 0.030443950541720673\n",
      "Step 2 : loss = 0.02764585814951807\n",
      "Step 3 : loss = 0.024963977853915652\n",
      "Step 4 : loss = 0.02246779538435511\n",
      "Step 5 : loss = 0.020421405127269532\n",
      "Step 6 : loss = 0.019071850855754555\n",
      "Step 7 : loss = 0.018063314207298214\n",
      "Step 8 : loss = 0.017438739340170067\n",
      "Step 9 : loss = 0.016809502851899027\n",
      "Update Procedure\n",
      "Step0 : loss = 1.931200385093689\n",
      "Step1 : loss = 1.6523849964141846\n",
      "Step2 : loss = 1.5843534866968791\n",
      "Step3 : loss = 1.5578743418057759\n",
      "Step4 : loss = 1.483729402224223\n",
      "Step5 : loss = 1.4442333728075027\n",
      "Step6 : loss = 1.394614244500796\n",
      "Step7 : loss = 1.3564386467138927\n",
      "Step8 : loss = 1.3138592739899952\n",
      "Step9 : loss = 1.275259147087733\n",
      "Data stream Batch- 5 : loss = 2.9433592557907104\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.04551604062302627\n",
      "Step 1 : loss = 0.04044023844700945\n",
      "Step 2 : loss = 0.03759039361132063\n",
      "Step 3 : loss = 0.034967882991932084\n",
      "Step 4 : loss = 0.0325255699628215\n",
      "Step 5 : loss = 0.030477287369679952\n",
      "Step 6 : loss = 0.02858609449403935\n",
      "Step 7 : loss = 0.027097960562145362\n",
      "Step 8 : loss = 0.026190414333386303\n",
      "Step 9 : loss = 0.02446566148393112\n",
      "Update Procedure\n",
      "Step0 : loss = 1.7268061126981462\n",
      "Step1 : loss = 1.3928042096751077\n",
      "Step2 : loss = 1.3781390615871973\n",
      "Step3 : loss = 1.3097990495818002\n",
      "Step4 : loss = 1.273281101669584\n",
      "Step5 : loss = 1.2107534664017814\n",
      "Step6 : loss = 1.1553527116775513\n",
      "Step7 : loss = 1.1080709653241294\n",
      "Step8 : loss = 1.0618217502321516\n",
      "Step9 : loss = 1.0212737619876862\n",
      "Data stream Batch- 6 : loss = 2.5467922687530518\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.07724153201962118\n",
      "Step 1 : loss = 0.06884738009536201\n",
      "Step 2 : loss = 0.06078706562595021\n",
      "Step 3 : loss = 0.05436866022942048\n",
      "Step 4 : loss = 0.04973926804711196\n",
      "Step 5 : loss = 0.04641439731881628\n",
      "Step 6 : loss = 0.04413027085734726\n",
      "Step 7 : loss = 0.04317080184433125\n",
      "Step 8 : loss = 0.04091520726292276\n",
      "Step 9 : loss = 0.04023887322816192\n",
      "Update Procedure\n",
      "Step0 : loss = 1.5737688168883324\n",
      "Step1 : loss = 1.2140824273228645\n",
      "Step2 : loss = 1.2212403491139412\n",
      "Step3 : loss = 1.1451672278344631\n",
      "Step4 : loss = 1.0953296199440956\n",
      "Step5 : loss = 1.0630355961620808\n",
      "Step6 : loss = 1.0228620991110802\n",
      "Step7 : loss = 1.0267389323562384\n",
      "Step8 : loss = 0.9956024400889874\n",
      "Step9 : loss = 0.99122922308743\n",
      "Data stream Batch- 7 : loss = 2.199066162109375\n",
      "Task  6\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.07452859797475155\n",
      "Step 1 : loss = 0.07452859797475155\n",
      "Step 2 : loss = 0.07452859797475155\n",
      "Step 3 : loss = 0.07452859797475155\n",
      "Step 4 : loss = 0.07452859797475155\n",
      "Step 5 : loss = 0.07452859797475155\n",
      "Step 6 : loss = 0.07452859797475155\n",
      "Step 7 : loss = 0.07452859797475155\n",
      "Step 8 : loss = 0.07452859797475155\n",
      "Step 9 : loss = 0.07452859797475155\n",
      "Update Procedure\n",
      "Step0 : loss = 3.9062860012054443\n",
      "Step1 : loss = 3.8149051666259766\n",
      "Step2 : loss = 3.723757028579712\n",
      "Step3 : loss = 3.632833242416382\n",
      "Step4 : loss = 3.5421106815338135\n",
      "Step5 : loss = 3.4512109756469727\n",
      "Step6 : loss = 3.3599536418914795\n",
      "Step7 : loss = 3.2682995796203613\n",
      "Step8 : loss = 3.1761505603790283\n",
      "Step9 : loss = 3.083697557449341\n",
      "Data stream Batch- 0 : loss = 11.51829719543457\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.13044343582225618\n",
      "Step 1 : loss = 0.13044343582225618\n",
      "Step 2 : loss = 0.13044343582225618\n",
      "Step 3 : loss = 0.13044343582225618\n",
      "Step 4 : loss = 0.13044343582225618\n",
      "Step 5 : loss = 0.13044343582225618\n",
      "Step 6 : loss = 0.13044343582225618\n",
      "Step 7 : loss = 0.13044343582225618\n",
      "Step 8 : loss = 0.13044343582225618\n",
      "Step 9 : loss = 0.13044343582225618\n",
      "Update Procedure\n",
      "Step0 : loss = 3.7034000158309937\n",
      "Step1 : loss = 3.5164355039596558\n",
      "Step2 : loss = 3.326995849609375\n",
      "Step3 : loss = 3.1349700689315796\n",
      "Step4 : loss = 2.9431360960006714\n",
      "Step5 : loss = 2.7591618299484253\n",
      "Step6 : loss = 2.581540048122406\n",
      "Step7 : loss = 2.442827582359314\n",
      "Step8 : loss = 2.3240848183631897\n",
      "Step9 : loss = 2.2183366417884827\n",
      "Data stream Batch- 1 : loss = 9.83079481124878\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.230832557693173\n",
      "Step 1 : loss = 0.230832557693173\n",
      "Step 2 : loss = 0.230832557693173\n",
      "Step 3 : loss = 0.230832557693173\n",
      "Step 4 : loss = 0.230832557693173\n",
      "Step 5 : loss = 0.230832557693173\n",
      "Step 6 : loss = 0.230832557693173\n",
      "Step 7 : loss = 0.230832557693173\n",
      "Step 8 : loss = 0.230832557693173\n",
      "Step 9 : loss = 0.230832557693173\n",
      "Update Procedure\n",
      "Step0 : loss = 2.7901766300201416\n",
      "Step1 : loss = 2.609220822652181\n",
      "Step2 : loss = 2.444765647252401\n",
      "Step3 : loss = 2.282981355985006\n",
      "Step4 : loss = 2.1184871594111123\n",
      "Step5 : loss = 1.9551533063252766\n",
      "Step6 : loss = 1.7935466766357422\n",
      "Step7 : loss = 1.6315228343009949\n",
      "Step8 : loss = 1.4686504006385803\n",
      "Step9 : loss = 1.3138265013694763\n",
      "Data stream Batch- 2 : loss = 7.3438873291015625\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.3033753494042699\n",
      "Step 1 : loss = 0.3033753494042699\n",
      "Step 2 : loss = 0.3033753494042699\n",
      "Step 3 : loss = 0.3033753494042699\n",
      "Step 4 : loss = 0.3033753494042699\n",
      "Step 5 : loss = 0.3033753494042699\n",
      "Step 6 : loss = 0.3033753494042699\n",
      "Step 7 : loss = 0.3033753494042699\n",
      "Step 8 : loss = 0.3033753494042699\n",
      "Step 9 : loss = 0.3033753494042699\n",
      "Update Procedure\n",
      "Step0 : loss = 1.3852815479040146\n",
      "Step1 : loss = 1.2096281424164772\n",
      "Step2 : loss = 1.0886328220367432\n",
      "Step3 : loss = 0.9859409481287003\n",
      "Step4 : loss = 0.8923199772834778\n",
      "Step5 : loss = 0.811720609664917\n",
      "Step6 : loss = 0.7477070987224579\n",
      "Step7 : loss = 0.7059173136949539\n",
      "Step8 : loss = 0.6694008857011795\n",
      "Step9 : loss = 0.6238924413919449\n",
      "Data stream Batch- 3 : loss = 5.103259086608887\n",
      "Meta Update\n",
      "Training is starting\n",
      "Step 0 : loss = 0.25479085630929943\n",
      "Step 1 : loss = 0.24491652495597335\n",
      "Step 2 : loss = 0.23504598476182956\n",
      "Step 3 : loss = 0.2251631340074075\n",
      "Step 4 : loss = 0.21530346681253876\n",
      "Step 5 : loss = 0.20549046542684923\n",
      "Step 6 : loss = 0.19569442304386997\n",
      "Step 7 : loss = 0.1859208809361682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-89dc6983ce97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mftml4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morderone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mftml4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrainx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdvalx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdvalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mftml4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_maml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mftml4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrainx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdvalx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdvalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mtotal_loss_task\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Update Procedure\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Labwork\\vr_motion_prediction\\research\\maml.py\u001b[0m in \u001b[0;36mtrain_maml\u001b[1;34m(model, epochs, traintaskx, traintaskt, valtaskx, valtaskt, inner_loop, lr_inner, lr_outer_max, log_step, ca)\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[1;31m#step 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minner_tape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minner_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                     \u001b[1;31m#step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                     \u001b[0mgradients2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Labwork\\vr_motion_prediction\\research\\maml.py\u001b[0m in \u001b[0;36mmodel_func\u001b[1;34m(model, x_train, t_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf.2.x\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    141\u001b[0m         y_true, y_pred, sample_weight)\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m       \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[0;32m    145\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[1;32m~\\.conda\\envs\\tf.2.x\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    244\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[0;32m    245\u001b[0m           y_pred, y_true)\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf.2.x\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1228\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m   \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf.2.x\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf.2.x\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  10089\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m  10090\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sub\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10091\u001b[1;33m         x, y)\n\u001b[0m\u001b[0;32m  10092\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10093\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml4 = []\n",
    "total = []\n",
    "all_eval_loss4 = []\n",
    "all_train_loss4 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval4 = []\n",
    "ftml_time4 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        if j < 4:\n",
    "            ftml4, loss = orderone(ftml4, meta_step, dtrainx, dtraint, dvalx, dvalt)\n",
    "        else:\n",
    "            ftml4, loss = train_maml(ftml4, meta_step, dtrainx, dtraint, dvalx, dvalt)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml, loss = update_procedure(ftml4,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml4, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time4.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval4.append(eval_loss)\n",
    "    all_train_loss4.append(train_loss)\n",
    "    all_eval_loss4.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval4)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml5 = []\n",
    "total = []\n",
    "all_eval_loss5 = []\n",
    "all_train_loss5 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval5 = []\n",
    "ftml_time5 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        ftml5, loss = train_maml_msl(ftml5, meta_step, dtrainx, dtraint, dvalx, dvalt)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml5, loss = update_procedure(ftml5,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml5, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time5.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval5.append(eval_loss)\n",
    "    all_train_loss5.append(train_loss)\n",
    "    all_eval_loss5.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval5)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_step = 10\n",
    "loss_ftml6 = []\n",
    "total = []\n",
    "all_eval_loss6 = []\n",
    "all_train_loss6 = []\n",
    "xtask_buffer = []\n",
    "ttask_buffer = []\n",
    "ftml_eval6 = []\n",
    "ftml_time6 = []\n",
    "buffer_length = len(xtask_buffer)\n",
    "for i in range (10):\n",
    "    print(\"Task \", i)\n",
    "    eval_task = []\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "    if len(xtask_buffer) >= 24:\n",
    "        xtask_buffer = xtask_buffer[8:]\n",
    "        ttask_buffer = ttask_buffer[8:] \n",
    "\n",
    "\n",
    "    buffer_length = len(xtask_buffer)\n",
    "    for j in range (8):\n",
    "        \n",
    "        total_loss_task = 0\n",
    "        dtstream_x = traintaskx[i][0:j+1]\n",
    "        dtstream_t = traintaskt[i][0:j+1]\n",
    "        \n",
    "        if len(xtask_buffer) <   1:\n",
    "            dtrainx = dvalx = dtstream_x\n",
    "            dtraint = dvalt = dtstream_t\n",
    "        elif len(xtask_buffer) == 1:\n",
    "            dtrainx = dvalx = xtask_buffer \n",
    "            dtraint = dvalt = ttask_buffer\n",
    "        else :\n",
    "            dtrainx = xtask_buffer[0:buffer_length//2]\n",
    "            dvalx = xtask_buffer[buffer_length//2:]\n",
    "            dtraint = ttask_buffer[0:buffer_length//2]\n",
    "            dvalt = ttask_buffer[buffer_length//2:]\n",
    "\n",
    "        print(\"Meta Update\")\n",
    "        if j < 4:\n",
    "            ftml6, loss = orderone(ftml6, meta_step, dtrainx, dtraint, dvalx, dvalt, ca=True)\n",
    "        else:\n",
    "            ftml6, loss = train_maml_msl(ftml6, meta_step, dtrainx, dtraint, dvalx, dvalt, ca=True)\n",
    "        total_loss_task += sum(loss)/len(loss)\n",
    "        print(\"Update Procedure\")\n",
    "        ftml6, loss = update_procedure(ftml6,dtstream_x, dtstream_t)\n",
    "        total_loss_task = (total_loss_task + sum(loss)/len(loss))/2\n",
    "\n",
    "        tmp_loss = 0\n",
    "        for k in range(len(valtaskx[i])):\n",
    "            _, loss = model_func(ftml6, valtaskx[i][k], valtaskt[i][k])\n",
    "            tmp_loss+=loss\n",
    "\n",
    "        eval_loss = tmp_loss/2\n",
    "        eval_task.append(eval_loss)\n",
    "        train_loss.append(total_loss_task)\n",
    "\n",
    "        print('Data stream Batch- {} : loss = {}'.format(j,eval_loss))\n",
    "        # if eval_loss < threshold or j == 9:\n",
    "        #     print(\"Training Finish\")\n",
    "        #     total.append(j+1)\n",
    "        #     loss_ftml.append(eval_loss)\n",
    "        #     break\n",
    "    curr = time.time() - start\n",
    "    ftml_time6.append(curr)\n",
    "    start = time.time()\n",
    "    xtask_buffer+=dtstream_x\n",
    "    ttask_buffer+=dtstream_t\n",
    "    ftml_eval6.append(eval_loss)\n",
    "    all_train_loss6.append(train_loss)\n",
    "    all_eval_loss6.append(eval_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval6)\n",
    "plt.xlabel('Data Size (index*100)')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval1)\n",
    "plt.plot(ftml_eval2)\n",
    "plt.plot(ftml_eval3)\n",
    "plt.plot(ftml_eval4)\n",
    "plt.plot(ftml_eval5)\n",
    "plt.plot(ftml_eval6)\n",
    "plt.legend([\"Normal\", \"Fixed Buffer\", \"CA\", \"DA\", \"MSL\", \"++\"], loc=(1.05, 0.5))\n",
    "plt.xlabel('Task Index')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_eval1[5:])\n",
    "plt.plot(ftml_eval2[5:])\n",
    "plt.plot(ftml_eval3[5:])\n",
    "plt.plot(ftml_eval4[5:])\n",
    "plt.plot(ftml_eval5[5:])\n",
    "plt.plot(ftml_eval6[5:])\n",
    "plt.legend([\"Normal\", \"Fixed Buffer\", \"CA\", \"DA\", \"MSL\", \"++\"], loc=(1.05, 0.5))\n",
    "plt.xlabel('Task Index')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)  \n",
    "# plt.plot(ftml_eval)\n",
    "\n",
    "# plt.plot(jt_res)\n",
    "# plt.plot(toe_res)\n",
    "# plt.plot(sc_res)\n",
    "\n",
    "\n",
    "# plt.legend([\"Scratch\", \"Joint\", \"TOE\", \"FTML\"], loc=(1.05, 0.5))\n",
    "# plt.xlabel('Task Index')\n",
    "# plt.ylabel('MAE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.title(\"Task \"+ str(i))\n",
    "    plt.plot(all_eval_loss1[i])\n",
    "    plt.plot(all_eval_loss2[i])\n",
    "    plt.plot(all_eval_loss3[i])\n",
    "    plt.plot(all_eval_loss4[i])\n",
    "    plt.plot(all_eval_loss5[i])\n",
    "    plt.plot(all_eval_loss6[i])\n",
    "\n",
    "    plt.legend([\"Normal\", \"Fixed Buffer\", \"CA\", \"DA\", \"MSL\", \"++\"], loc=(1.05, 0.5))\n",
    "    plt.xlabel('Batch index')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)   \n",
    "# plt.plot(sc_time)\n",
    "# plt.plot(jt_time)\n",
    "# plt.plot(toe_time)\n",
    "# plt.plot(ftml_time)\n",
    "\n",
    "# plt.legend([\"Scratch\", \"Joint\", \"TOE\", \"FTML\"], loc=(1.05, 0.5))\n",
    "# plt.xlabel('Task Index')\n",
    "# plt.ylabel('Second')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)   \n",
    "plt.plot(ftml_time1)\n",
    "plt.plot(ftml_time2)\n",
    "plt.plot(ftml_time3)\n",
    "plt.plot(ftml_time4)\n",
    "plt.plot(ftml_time5)\n",
    "plt.plot(ftml_eval6)\n",
    "plt.legend([\"Normal\", \"Fixed Buffer\", \"CA\", \"DA\", \"MSL\", \"++\"], loc=(1.05, 0.5))\n",
    "plt.xlabel('Task Index')\n",
    "plt.ylabel('Second')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
